{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-language processing\n",
    "* we will deal with not only python, but also other languages. \n",
    "* and no script and notebook features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for now we only have the voted kernels' results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "competition = r\"J:\\EECS_6414\\Data\\19-02-24\\competition_split\\competition_stats.csv\"\n",
    "datasets = r\"J:\\EECS_6414\\Data\\19-02-24\\dataset_split\\dataset_stats.csv\"\n",
    "kernel_measure_0 = r\"J:\\EECS_6414\\Data\\19-02-24\\kernel_split\\cleaning_result\\measure_set_0\\kernel_stats_combined.csv\"\n",
    "kernel_measure_1 = r\"J:\\EECS_6414\\Data\\19-02-24\\kernel_split\\cleaning_result\\measure_set_1\\kernel_stats.csv\"\n",
    "\n",
    "def change_column_names(table, table_identifier, exclude_columns = []):\n",
    "    origin_col_name = list(table.columns.values)\n",
    "    new_columns = {old_column: \"{}_{}\".format(table_identifier, old_column) for old_column in origin_col_name if old_column not in exclude_columns}\n",
    "    table.rename(index=str, \n",
    "                    columns=new_columns, \n",
    "                    inplace= True)\n",
    "    \n",
    "def change_id_format(table):\n",
    "    table[\"id\"] = table[\"kernel\"] + table[\"author\"]\n",
    "    table.drop(['kernel', 'author'], axis=1, inplace= True)\n",
    "\n",
    "km0 = pd.read_csv(kernel_measure_0, encoding=\"utf-8\")\n",
    "km1 = pd.read_csv(kernel_measure_1, encoding=\"utf-8\")\n",
    "change_column_names(km0, \"km\", [\"kernel\", \"author\"])\n",
    "change_column_names(km1, \"km\", [\"kernel\", \"author\"])\n",
    "change_id_format(km0)\n",
    "change_id_format(km1)\n",
    "c = pd.merge(km1, km0, on= \"id\")\n",
    "c.to_csv(\"kernel_datasource_first_merged.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the high and low vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    41151.000000\n",
      "mean        11.261160\n",
      "std         58.748355\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          7.000000\n",
      "max       3713.000000\n",
      "Name: km_votes, dtype: float64\n",
      "\n",
      "count    196969.000000\n",
      "mean          2.352695\n",
      "std          27.239849\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max        3713.000000\n",
      "Name: km_votes, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# cvo: code_voted_original\n",
    "# cvp: code_voted_pyscript\n",
    "# km: kernel_measures\n",
    "merged_table = r\"J:\\EECS6414\\process\\Pipeline\\Data_cleaning\\kernel_datasource_first_merged.csv\"\n",
    "mt = pd.read_csv(merged_table, encoding=\"utf-8\")\n",
    "\n",
    "mt_voted = mt[mt[\"km_votes\"] > 0]\n",
    "print(mt_voted[\"km_votes\"].describe())\n",
    "print()\n",
    "print(mt[\"km_votes\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     196969\n",
       "unique         2\n",
       "top        False\n",
       "freq      176731\n",
       "Name: high_voted, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt[\"high_voted\"] = None\n",
    "mt[\"high_voted\"][mt[\"km_votes\"] > 2] = True\n",
    "mt[\"high_voted\"][mt[\"km_votes\"] <= 2] = False\n",
    "mt[\"high_voted\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding and some new features for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many kernels have tags:  12288 \n",
      " how_many_kernels_dont_have_tags:  184681 \n",
      " {'eda': [1644, 801], 'data-visualization': [2726, 1666], 'feature-engineering': [817, 486], 'regression': [115, 107], 'starter-code': [709, 983], '<(no_tags)>': [13826, 170855], 'beginner': [2402, 2296], 'classification': [917, 931], 'time-series': [141, 65], 'twitter': [16, 14], 'tutorial': [1250, 793], 'nlp': [285, 140], 'text-mining': [122, 75], 'healthcare': [149, 44], 'health': [7, 5], 'gradient-boosting': [127, 53], 'binary-classification': [77, 84], 'linear-regression': [120, 168], 'data-cleaning': [586, 568], 'machine-learning': [29, 34], 'tabular-data': [24, 23], 'model-comparison': [85, 67], 'svm': [60, 75], 'multiclass-classification': [74, 61], 'image-processing': [122, 86], 'deep-learning': [519, 429], 'cnn': [203, 136], 'image-data': [106, 59], 'pipeline-code': [47, 23], 'neural-networks': [233, 188], 'optimization': [33, 12], 'naive-bayes': [40, 45], 'xgboost': [200, 100], 'dnn': [3, 6], 'clustering': [110, 71], 'forecasting': [54, 24], 'recommender-systems': [39, 22], 'ensembling': [121, 54], 'learn': [73, 26], 'regression-analysis': [148, 100], 'clinical-research': [2, 0], 'preprocessing': [112, 84], 'random-forest': [186, 214], 'logistic-regression': [168, 182], 'intermediate': [36, 8], 'model-explainability': [15, 0], 'advanced': [46, 6], 'geospatial-analysis': [83, 19], 'learning': [13, 36], 'geophysics': [1, 1], 'object-segmentation': [26, 7], 'linguistics': [68, 24], 'finance': [212, 68], 'dimensionality-reduction': [40, 21], 'pca': [81, 40], 'survey-analysis': [88, 18], 'time-series-analysis': [56, 33], 'crime': [138, 31], 'marketing-analytics': [17, 12], 'text-data': [128, 67], 'statistics': [40, 32], 'business': [55, 22], 'animation': [20, 7], 'geography': [19, 7], 'terrorism': [20, 11], 'databases': [14, 29], 'bigquery': [84, 178], 'dailychallenge': [117, 956], 'animals': [18, 11], 'computer-model': [4, 1], 'statistical-analysis': [48, 29], 'medicine': [25, 20], 'algebra': [1, 0], 'probability': [14, 13], 'banking': [29, 21], 'storytelling': [48, 4], 'customer-value': [3, 2], 'churn-analysis': [19, 11], 'click-prediction': [18, 1], 'crowdfunding': [28, 4], 'rnn': [28, 21], 'libraries': [3, 3], 'k-means': [20, 14], 'model-diagnosis': [8, 6], 'automation': [9, 6], 'decision-tree': [72, 82], 'food-and-drink': [211, 77], 'cricket': [9, 8], 'marketing': [8, 5], 'lstm': [69, 45], 'physics': [9, 1], 'music': [17, 4], 'internet': [127, 24], 'social-groups': [4, 0], 'video-games': [140, 36], 'outlier-analysis': [18, 9], 'categorical-data': [43, 35], 'popular-culture': [10, 4], 'basketball': [18, 18], 'sports': [69, 32], 'demographics': [88, 15], 'covariance-and-correlation': [21, 15], 'countries': [10, 12], 'money': [12, 3], 'education': [29, 19], 'economics': [19, 14], 'multiple-regression': [18, 23], 'object-detection': [11, 2], 'brazil': [6, 8], 'film': [3, 2], 'network-analysis': [24, 3], 'artificial-intelligence': [17, 8], 'reinforcement-learning': [11, 7], 'lending': [15, 2], 'united-states': [27, 9], 'immigration': [2, 1], 'pattern-recognition': [3, 2], 'history': [56, 9], 'visual-arts': [16, 2], 'languages': [21, 9], 'gan': [9, 4], 'object-identification': [2, 0], 'transfer-learning': [31, 15], 'bayesian-statistics': [13, 6], 'universities-and-colleges': [9, 4], 'politics': [95, 22], 'astronomy': [9, 10], 'leisure': [2, 0], 'auto-racing': [1, 0], 'drawing': [1, 1], 'women': [7, 0], 'plants': [5, 3], 'sampling': [10, 7], 'american-football': [13, 2], 'research': [7, 1], 'networks': [5, 3], 'social-sciences': [6, 3], 'telecommunications': [1, 2], 'association-football': [14, 6], 'problem-solving': [2, 0], 'agriculture': [4, 0], 'biology': [25, 8], 'writing': [1, 0], 'mental-health': [3, 4], 'attention': [12, 2], 'signal-processing': [9, 0], 'signal-data': [3, 0], 'pre-trained-model': [8, 14], 'lgbt': [9, 1], 'entertainment': [5, 2], 'memory': [6, 1], 'alternative-medicine': [1, 0], 'botany': [2, 1], 'violence': [7, 6], 'psychology': [3, 0], 'video-data': [1, 1], 'automobiles': [3, 4], 'housing': [22, 21], 'programming-languages': [7, 3], 'stochastic-processes': [3, 4], 'sound-technology': [3, 0], 'object-recognition': [2, 6], 'alcohol': [15, 2], 'companies': [1, 1], 'news-agencies': [11, 3], 'weather': [10, 12], 'shipping': [1, 1], 'classics': [2, 3], 'christianity': [1, 0], 'energy': [11, 3], 'employment': [7, 1], 'games-and-toys': [9, 5], 'india': [42, 13], 'firefighting': [1, 0], 'information': [3, 1], 'emotion': [3, 0], 'adversarial-learning': [2, 2], 'diseases': [6, 1], 'epidemiology': [1, 1], 'environment': [13, 3], 'recommendation': [9, 7], 'puzzles': [3, 2], 'spaCy': [23, 6], 'asia': [4, 3], 'safety': [1, 0], 'multivariate-statistics': [6, 4], 'aviation': [4, 0], 'public-transport': [4, 4], 'climate': [5, 2], 'tennis': [3, 1], 'spaceflight': [2, 0], 'industry': [4, 0], 'public-administration': [6, 3], 'taxi-services': [6, 4], 'africa': [1, 3], 'communities': [2, 0], 'software-engineering': [1, 1], 'grammar': [1, 0], 'mathematics': [8, 5], 'data-journalism': [5, 6], 'cities': [7, 10], 'neuroscience': [2, 2], 'sociology': [4, 0], 'mortality': [3, 1], 'china-': [2, 3], 'summary-statistics': [8, 5], 'pollution': [8, 9], 'health-sciences': [3, 3], 'biotechnology': [3, 0], 'illegal-drugs': [3, 1], 'law': [3, 3], 'olympic-games': [4, 9], 'architecture': [1, 1], 'human-genetics': [7, 2], 'online-education': [1, 0], 'computer-science': [1, 2], 'future-prediction': [20, 26], 'computers': [2, 0], 'electrical-components': [2, 0], 'dictionaries': [1, 1], 'celebrity': [1, 0], 'new-york': [1, 0], 'portfolio': [1, 2], 'mathematical-optimization': [1, 1], 'world': [16, 6], 'market-basket': [7, 4], 'income': [4, 5], 'government-agencies': [4, 0], 'gender': [9, 5], 'people': [1, 0], 'renewable-energy': [4, 4], 'australia': [2, 0], 'photography': [5, 4], 'books': [4, 0], 'consumer-electronics': [1, 0], 'political-science': [1, 0], 'card-games': [2, 0], 'culture-and-humanities': [2, 1], 'cartography': [2, 1], 'product-management': [0, 1], 'public-health': [8, 8], 'tools': [1, 0], 'forestry': [2, 0], 'web-sites': [2, 5], 'nutrition': [1, 2], 'programming': [8, 5], 'cleaning': [4, 1], 'nuclear-technology': [1, 0], 'transport': [3, 5], 'reddit': [2, 3], 'journalism': [7, 3], 'experimental-design': [2, 0], 'computer-security': [1, 1], 'role-playing-games': [1, 0], 'socrata': [1, 1], 'death': [2, 1], 'belief-systems': [1, 0], 'literature': [1, 0], 'oncology-and-cancer': [6, 7], 'manufacturing': [1, 0], 'mining': [3, 3], 'board-games': [2, 2], 'timelines': [3, 2], 'analysis-of-variance': [1, 1], 'survival-analysis': [2, 4], 'acoustics': [3, 1], 'russia': [1, 1], 'exercise': [2, 2], 'society': [1, 2], 'weight-training': [3, 0], 'auto-updating-data': [1, 0], 'science-and-culture': [1, 0], 'space': [4, 2], 'academics': [1, 0], 'cycling': [2, 1], 'comics': [2, 1], 'supply-chain': [1, 0], 'baseball': [2, 11], 'ice-hockey': [2, 0], 'hotels': [1, 2], 'earth-sciences': [2, 2], 'geology': [3, 1], 'international-relations': [1, 2], 'government': [2, 1], 'utility': [1, 3], 'knowledge': [2, 0], 'nature': [1, 2], 'natural-disasters': [2, 0], 'europe': [2, 5], 'organizations': [1, 2], 'ethnic-groups': [2, 2], 'non-parametric-statistics': [1, 0], 'humor': [2, 1], 'bodies-of-water': [1, 0], 'needs-feedback': [2, 1], 'war': [2, 1], 'politicians': [2, 4], 'life': [1, 1], 'rugby-league': [1, 0], 'pets': [2, 2], 'real-estate': [2, 6], 'management': [1, 0], 'parametric-statistics': [1, 1], 'ecology': [2, 2], 'discriminant-analysis': [2, 5], 'horse-racing': [2, 0], 'ranking': [3, 0], 'decision-theory': [1, 1], 'proofs': [1, 0], 'hobbies': [1, 0], 'social-philosophy': [1, 0], 'semiconductors': [1, 0], 'road-transport': [1, 4], 'geometry': [1, 0], 'human-computer-interaction': [1, 2], 'vehicles': [1, 1], 'cognitive-biases': [1, 0], 'numbers': [1, 3], 'logic': [0, 2], 'search-engines': [0, 3], 'mathematics-education': [0, 2], 'poetry': [0, 3], 'folklore': [0, 1], 'chemistry': [0, 5], 'perception': [0, 2], 'object-labeling': [0, 2], 'family': [0, 1], 'clothing': [0, 3], 'computational-science': [1, 1], 'physical-sciences': [0, 1], 'schools-and-traditions': [0, 1], 'environmental-engineering': [0, 1], 'painting': [0, 1], 'computing-and-society': [0, 1], 'historiography': [0, 2], 'parties': [0, 1], 'robotics': [0, 1], 'neurology': [0, 1], 'operations-research': [0, 2], 'software': [1, 1], 'personality': [0, 1], 'electronics': [0, 1], 'strategy': [0, 2], 'museums': [0, 1], 'zoology': [0, 1], 'reading': [0, 2], 'home': [0, 1], 'presidents': [0, 1], 'musicians': [1, 0], 'musical-groups': [1, 0], 'mass-media': [1, 0], 'military': [0, 3], 'product': [0, 1], 'model-monitoring': [0, 1], 'fishing': [0, 1], 'oceans': [0, 1], 'quantum-electronics': [1, 0], 'japan': [0, 1], 'rail-transport': [0, 2], 'metalworking': [1, 0], 'operating-systems': [0, 1], 'duplicate-detection': [0, 1], 'globalization': [0, 1], 'counting': [0, 2], 'construction': [0, 1], 'computer-architecture': [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "kernel_tags = {}\n",
    "tags_kernel = {}\n",
    "tags_high_and_low_vote_kernel_number = {}\n",
    "\n",
    "how_many_kernels_dont_have_tags = 0\n",
    "how_many_kernels_have_tags = 0\n",
    "\n",
    "for index, row in mt.iterrows():\n",
    "    kernel_id = row[\"id\"]\n",
    "    tag_string = row[\"km_tags\"]\n",
    "    if not isinstance(tag_string, str):\n",
    "        how_many_kernels_dont_have_tags += 1\n",
    "        tags_of_this_kernel = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        how_many_kernels_have_tags += 1\n",
    "        tags_of_this_kernel = tag_string.split(\";\")\n",
    "    for tag in tags_of_this_kernel:\n",
    "        #####\n",
    "        if tag in tags_kernel:\n",
    "            tags_kernel[tag].append(kernel_id)\n",
    "        else:\n",
    "            tags_kernel[tag] = [kernel_id]\n",
    "        #####\n",
    "        if tag in tags_high_and_low_vote_kernel_number:\n",
    "            if row[\"high_voted\"]:\n",
    "                tags_high_and_low_vote_kernel_number[tag][0] += 1\n",
    "            else:\n",
    "                tags_high_and_low_vote_kernel_number[tag][1] += 1\n",
    "        else:\n",
    "            tags_high_and_low_vote_kernel_number[tag] = [1, 0] if row[\"high_voted\"] else [0, 1]\n",
    "    kernel_tags[kernel_id] = tags_of_this_kernel\n",
    "\n",
    "print(\n",
    "    \"how many kernels have tags: \", how_many_kernels_have_tags, \"\\n\",\n",
    "    \"how_many_kernels_dont_have_tags: \", how_many_kernels_dont_have_tags, \"\\n\",\n",
    "    # \"how many tags are in total: \", len(list(tags_num.keys())), \"\\n\"\n",
    "    tags_high_and_low_vote_kernel_number\n",
    ")\n",
    "\n",
    "def counting_tags(string):\n",
    "    if isinstance(string, float):\n",
    "        return 0\n",
    "    return len(string.split(\";\"))\n",
    "\n",
    "def target_encoding_tags_sum(string, return_stats=\"sum\"):\n",
    "    import numpy as np\n",
    "    from statistics import mean, median\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    if isinstance(string, float):\n",
    "        tags = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        tags = string.split(\";\")\n",
    "    encoding_vals = []\n",
    "    for tag in tags:\n",
    "        encoding_vals.append(float(t[tag][0]) / sum(t[tag]))\n",
    "    \n",
    "    if return_stats == \"sum\":\n",
    "        return sum(encoding_vals)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def target_encoding_tags_avg(string, return_stats=\"avg\"):\n",
    "    import numpy as np\n",
    "    from statistics import mean, median\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    if isinstance(string, float):\n",
    "        tags = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        tags = string.split(\";\")\n",
    "    encoding_vals = []\n",
    "    for tag in tags:\n",
    "        encoding_vals.append(float(t[tag][0]) / sum(t[tag]))\n",
    "    \n",
    "    if (return_stats == \"mean\" or return_stats == \"avg\"):\n",
    "        return mean(encoding_vals)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def target_encoding_tags_max(string, return_stats=\"max\"):\n",
    "    import numpy as np\n",
    "    from statistics import mean, median\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    if isinstance(string, float):\n",
    "        tags = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        tags = string.split(\";\")\n",
    "    encoding_vals = []\n",
    "    for tag in tags:\n",
    "        encoding_vals.append(float(t[tag][0]) / sum(t[tag]))\n",
    "    \n",
    "    if return_stats == \"max\":\n",
    "        return max(encoding_vals)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def target_encoding_tags_min(string, return_stats=\"min\"):\n",
    "    import numpy as np\n",
    "    from statistics import mean, median\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    if isinstance(string, float):\n",
    "        tags = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        tags = string.split(\";\")\n",
    "    encoding_vals = []\n",
    "    for tag in tags:\n",
    "        encoding_vals.append(float(t[tag][0]) / sum(t[tag]))\n",
    "    \n",
    "    if return_stats == \"min\":\n",
    "        return min(encoding_vals)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def target_encoding_tags_median(string, return_stats=\"median\"):\n",
    "    import numpy as np\n",
    "    from statistics import mean, median\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    if isinstance(string, float):\n",
    "        tags = [\"<(no_tags)>\"]\n",
    "    else:\n",
    "        tags = string.split(\";\")\n",
    "    encoding_vals = []\n",
    "    for tag in tags:\n",
    "        encoding_vals.append(float(t[tag][0]) / sum(t[tag]))\n",
    "    \n",
    "    if return_stats == \"median\":\n",
    "        return median(encoding_vals)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "mt[\"km_num_of_tags\"] = 0\n",
    "mt[\"km_tags_te_sum\"] = None\n",
    "mt[\"km_tags_te_avg\"] = None\n",
    "mt[\"km_tags_te_max\"] = None\n",
    "mt[\"km_tags_te_min\"] = None\n",
    "mt[\"km_tags_te_median\"] = None\n",
    "\n",
    "mt[\"km_num_of_tags\"] = mt[\"km_tags\"].map(counting_tags)\n",
    "mt[\"km_tags_te_sum\"] = mt[\"km_tags\"].map(target_encoding_tags_sum)\n",
    "mt[\"km_tags_te_avg\"] = mt[\"km_tags\"].map(target_encoding_tags_avg)\n",
    "mt[\"km_tags_te_max\"] = mt[\"km_tags\"].map(target_encoding_tags_max)\n",
    "mt[\"km_tags_te_min\"] = mt[\"km_tags\"].map(target_encoding_tags_min)\n",
    "mt[\"km_tags_te_median\"] = mt[\"km_tags\"].map(target_encoding_tags_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding and other measures for km_isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_kernel = {}\n",
    "tags_high_and_low_vote_kernel_number = {}\n",
    "\n",
    "how_many_kernels_dont_have_tags = 0\n",
    "how_many_kernels_have_tags = 0\n",
    "\n",
    "for index, row in mt.iterrows():\n",
    "    kernel_id = row[\"id\"]\n",
    "    tag = row[\"km_isNotebook\"]\n",
    "    if row[\"km_isNotebook\"]:\n",
    "        how_many_kernels_have_tags += 1\n",
    "    else: \n",
    "        how_many_kernels_dont_have_tags += 1\n",
    "    ##########\n",
    "    if tag not in tags_kernel:\n",
    "        tags_kernel[tag] = [kernel_id]\n",
    "    else:\n",
    "        tags_kernel[tag].append(kernel_id)\n",
    "    ##########\n",
    "    if tag in tags_high_and_low_vote_kernel_number:\n",
    "        if row[\"high_voted\"]:\n",
    "            tags_high_and_low_vote_kernel_number[tag][0] += 1\n",
    "        else:\n",
    "            tags_high_and_low_vote_kernel_number[tag][1] += 1\n",
    "    else:\n",
    "        tags_high_and_low_vote_kernel_number[tag] = [1, 0] if row[\"high_voted\"] else [0, 1]\n",
    "\n",
    "print(\n",
    "    \"how many kernels are notebook: \", how_many_kernels_have_tags, \"\\n\",\n",
    "    \"how_many_kernels_arent_notebook: \", how_many_kernels_dont_have_tags, \"\\n\",\n",
    "    # \"how many tags are in total: \", len(list(tags_num.keys())), \"\\n\"\n",
    "    tags_high_and_low_vote_kernel_number\n",
    ")\n",
    "\n",
    "def target_encoding(tag):\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    return float(t[tag][0]) / sum(t[tag])\n",
    "\n",
    "mt[\"km_isNotebook\"] = mt[\"km_isNotebook\"].map(target_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_kernel = {}\n",
    "tags_high_and_low_vote_kernel_number = {}\n",
    "\n",
    "how_many_kernels_dont_have_tags = 0\n",
    "how_many_kernels_have_tags = 0\n",
    "\n",
    "for index, row in mt.iterrows():\n",
    "    kernel_id = row[\"id\"]\n",
    "    tag = row[\"km_language\"]\n",
    "    ##########\n",
    "    if tag not in tags_kernel:\n",
    "        tags_kernel[tag] = [kernel_id]\n",
    "    else:\n",
    "        tags_kernel[tag].append(kernel_id)\n",
    "    ##########\n",
    "    if tag in tags_high_and_low_vote_kernel_number:\n",
    "        if row[\"high_voted\"]:\n",
    "            tags_high_and_low_vote_kernel_number[tag][0] += 1\n",
    "        else:\n",
    "            tags_high_and_low_vote_kernel_number[tag][1] += 1\n",
    "    else:\n",
    "        tags_high_and_low_vote_kernel_number[tag] = [1, 0] if row[\"high_voted\"] else [0, 1]\n",
    "\n",
    "print(\n",
    "    \"how many kernels are notebook: \", how_many_kernels_have_tags, \"\\n\",\n",
    "    \"how_many_kernels_arent_notebook: \", how_many_kernels_dont_have_tags, \"\\n\",\n",
    "    # \"how many tags are in total: \", len(list(tags_num.keys())), \"\\n\"\n",
    "    tags_high_and_low_vote_kernel_number\n",
    ")\n",
    "\n",
    "def target_encoding(tag):\n",
    "    t = tags_high_and_low_vote_kernel_number\n",
    "    return float(t[tag][0]) / sum(t[tag])\n",
    "\n",
    "mt[\"km_language\"] = mt[\"km_language\"].map(target_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.to_csv(\"kernel_datassource.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
