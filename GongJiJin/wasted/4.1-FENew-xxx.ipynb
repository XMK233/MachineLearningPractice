{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release note\n",
    "\n",
    "全新套路，https://github.com/jiahengqi/datacastle_shixin/blob/master/runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data,model):\n",
    "    y_pred=model.predict_proba(data[feat])[:, 1]\n",
    "    return roc_auc_score(data.Label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = pd.read_csv('originalDataset/train.csv')\n",
    "# data_test_a = pd.read_csv('originalDataset/test.csv')\n",
    "\n",
    "train = pd.read_csv('originalDataset/train.csv')\n",
    "train_y = train.label\n",
    "test = pd.read_csv('originalDataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresToDiscard = [\"HYZK\", \"ZHIYE\", \"ZHICHEN\", \"ZHIWU\", \"XUELI\"]\n",
    "train.drop(featuresToDiscard, axis = 1, inplace = True)\n",
    "test.drop(featuresToDiscard, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial features:  ['GRJCJS', 'GRZHYE', 'GRZHSNJZYE', 'GRZHDNGJYE', 'GRYJCE', 'DWYJCE', 'DKFFE', 'DKYE', 'DKLL']\n",
      "categorical features:  ['XINGBIE', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n"
     ]
    }
   ],
   "source": [
    "## 过滤类别较少的和较多的列\n",
    "def get_numerical_serial_fea(data,feas):\n",
    "    numerical_serial_fea = []\n",
    "    numerical_noserial_fea = []\n",
    "    for fea in feas:\n",
    "        temp = data[fea].nunique()\n",
    "        if temp <= 40:\n",
    "            numerical_noserial_fea.append(fea)\n",
    "            continue\n",
    "        numerical_serial_fea.append(fea)\n",
    "    return numerical_serial_fea,numerical_noserial_fea\n",
    "    \n",
    "serial_fea_, categorical_fea_ = get_numerical_serial_fea(train,train.columns)\n",
    "categorical_fea = list(filter(lambda x: x not in [\"DKLL\", \"label\"], categorical_fea_))\n",
    "serial_fea = list(filter(lambda x: x not in [\"id\", \"CSNY\"], serial_fea_))\n",
    "serial_fea.append(\"DKLL\")\n",
    "print(\"serial features: \", serial_fea)\n",
    "print(\"categorical features: \", categorical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = categorical_fea #['登记机关', '行业代码', '行业门类', '企业类型']\n",
    "feat = serial_fea #list(set(train.columns)-set(train.select_dtypes(object))-set(['Label', 'ID'])-set(cat_feat))\n",
    "remove_col = []\n",
    "for col in feat:\n",
    "    if train[col].nunique() < 2:\n",
    "        remove_col.append(col)\n",
    "feat = list(set(feat) - set(remove_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XINGBIE', 'DWJJLX', 'DWSSHY', 'GRZHZT']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRZHDNGJYE',\n",
       " 'GRYJCE',\n",
       " 'DKFFE',\n",
       " 'DKYE',\n",
       " 'DWYJCE',\n",
       " 'GRZHSNJZYE',\n",
       " 'GRZHYE',\n",
       " 'GRJCJS',\n",
       " 'DKLL']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feat:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "\n",
    "    def transform(self, x):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, x, y):\n",
    "        self.fit(x, y)\n",
    "        self.transform(x)\n",
    "        \n",
    "class CatCount(Feat):\n",
    "    def transform(self, x):\n",
    "        for col in self.config['cat_columns']:\n",
    "            df_count = x[col].value_counts()\n",
    "            x[f'{col}_catcount'] = x[col].map(df_count)\n",
    "\n",
    "class CatCountRank(Feat):\n",
    "    def fit(self, x, y):\n",
    "        self.fit_dict = {}\n",
    "        for col in self.config['cat_columns']:\n",
    "            counter =  Counter(x[col]).most_common()\n",
    "            self.fit_dict[col] = {k: i for (i, (k, v)) in enumerate(counter)}\n",
    "\n",
    "    def transform(self, x):\n",
    "        for col in self.config['cat_columns']:\n",
    "            x[f'{col}_countrank'] = x[col].map(self.fit_dict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['cat_columns'] = cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_fea_index = []\n",
    "for i, col in enumerate(train.columns):\n",
    "    if col in cat_feat:\n",
    "        categorical_fea_index.append(i)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'min_child_weight': 5,\n",
    "    'num_leaves': 2 ** 5,\n",
    "    'lambda_l2': 10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 4,\n",
    "    'learning_rate': 0.1,\n",
    "    'seed': 2020,\n",
    "    'nthread': 28,\n",
    "    'n_jobs':24,\n",
    "    'verbose': -1,\n",
    "\n",
    "    ## \n",
    "    \"categorical_feature\": categorical_fea_index, #\"name:{}\".format(\",\".join(categorical_fea)),\n",
    "\n",
    "    #########\n",
    "#                 'silent': True,\n",
    "    # 'metric': 'auc',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▎                                                                          | 1/9 [00:01<00:09,  1.23s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 22%|██████████████████▋                                                                 | 2/9 [00:02<00:08,  1.19s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 33%|████████████████████████████                                                        | 3/9 [00:03<00:06,  1.14s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 44%|█████████████████████████████████████▎                                              | 4/9 [00:04<00:05,  1.09s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 56%|██████████████████████████████████████████████▋                                     | 5/9 [00:05<00:04,  1.04s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 67%|████████████████████████████████████████████████████████                            | 6/9 [00:06<00:03,  1.02s/it]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 78%|█████████████████████████████████████████████████████████████████▎                  | 7/9 [00:07<00:01,  1.02it/s]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      " 89%|██████████████████████████████████████████████████████████████████████████▋         | 8/9 [00:08<00:00,  1.01it/s]C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"trans_data\"):\n",
    "    os.makedirs(\"trans_data\")\n",
    "\n",
    "importanceThreshold = 500\n",
    "    \n",
    "if os.path.exists('trans_data/train_1000_10.pkl'):\n",
    "    train = pickle.load(open('trans_data/train_1000_10.pkl', 'rb'))\n",
    "    test = pickle.load(open('trans_data/test_1000_10.pkl', 'rb'))\n",
    "else:\n",
    "    d={'add':'+', 'sub':'-', 'mul':'*', 'div':'/'}\n",
    "    feat0 = feat.copy()\n",
    "    for i in trange(len(feat)):\n",
    "        df_temp=train[feat0].copy()\n",
    "        for j in range(i+1,len(feat)):\n",
    "#             print('%s|%s|add'%(feat[i],feat[j]))\n",
    "            df_temp['%s|%s|add'%(feat[i],feat[j])] = train[feat[i]]+train[feat[j]]\n",
    "            df_temp['%s|%s|sub'%(feat[i],feat[j])] = train[feat[i]]-train[feat[j]]\n",
    "            df_temp['%s|%s|mul'%(feat[i],feat[j])] = train[feat[i]]*train[feat[j]]\n",
    "            df_temp['%s|%s|div'%(feat[i],feat[j])] = train[feat[i]]/train[feat[j]]\n",
    "        model = LGBMClassifier(\n",
    "            **params, #n_estimators=1000, learning_rate=0.08, max_depth=7, subsample=0.8, colsample_bytree=0.6, n_jobs=4\n",
    "        )\n",
    "        model.fit(df_temp.values, train_y)\n",
    "        qq = pd.Series(model.feature_importances_, index=df_temp.columns).sort_values()\n",
    "        ## 特殊处理重要程度大于100的特征。卧槽，太帅了。\n",
    "        for col in set(qq.loc[qq>importanceThreshold].index)-set(feat0):\n",
    "            f0, f1, f2 = col.split('|')\n",
    "            train[col] = df_temp[col]\n",
    "            ## 如果这个特征靠谱，就把这个特征重复做到test数据集里面。这种操作手法太6了。\n",
    "            test[col] = eval(\"test['%s'] %s test['%s']\"%(f0, d[f2], f1))\n",
    "        feat0.extend(list(set(qq.loc[qq>importanceThreshold].index)-set(feat0)))\n",
    "    pickle.dump(train, open('trans_data/train_1000_10.pkl','wb'))\n",
    "    pickle.dump(test, open('trans_data/test_1000_10.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feat(data):\n",
    "    for col in cat_feat:\n",
    "        data[col] = data[col].fillna('empty').astype(str)\n",
    "    for col in data.columns:\n",
    "        if '年' not in col and '|' not in col and data[col].isna().sum()>0:\n",
    "            data['%s_na'%col] = data[col].isna().astype(int)\n",
    "            \n",
    "    featgen = CatCount(config)\n",
    "    featgen.transform(data)\n",
    "    \n",
    "gen_feat(train)\n",
    "gen_feat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 134)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featgen = CatCountRank(config)\n",
    "featgen.fit_transform(train, train_y)\n",
    "featgen.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XINGBIE</th>\n",
       "      <th>DWJJLX</th>\n",
       "      <th>DWSSHY</th>\n",
       "      <th>GRZHZT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  XINGBIE DWJJLX DWSSHY GRZHZT\n",
       "0       1    150     12      1\n",
       "1       2    110      0      1\n",
       "2       1    150      9      1\n",
       "3       1    150      7      1\n",
       "4       2    900     14      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[cat_feat].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRYJCE|GRJCJS|mul',\n",
       " 'GRYJCE|DKYE|sub',\n",
       " 'GRYJCE|DKLL|add',\n",
       " 'GRZHSNJZYE|GRZHYE|div',\n",
       " 'DKFFE|GRZHYE|mul',\n",
       " 'DKFFE|DKLL|div',\n",
       " 'DWYJCE',\n",
       " 'GRYJCE|GRZHSNJZYE|div',\n",
       " 'GRYJCE|DKYE|mul',\n",
       " 'GRZHYE|GRZHDNGJYE|add',\n",
       " 'GRJCJS|DKYE|mul',\n",
       " 'GRZHSNJZYE|DKYE|sub',\n",
       " 'DKFFE|GRZHYE|div',\n",
       " 'GRJCJS|DKYE|sub',\n",
       " 'GRZHSNJZYE|DKFFE|div',\n",
       " 'DKFFE|DKYE|sub',\n",
       " 'GRJCJS|DKFFE|div',\n",
       " 'GRZHYE|DKYE|sub',\n",
       " 'GRJCJS|GRZHSNJZYE|add',\n",
       " 'GRYJCE|GRZHYE|add',\n",
       " 'GRJCJS|GRZHSNJZYE|mul',\n",
       " 'GRZHSNJZYE|DKLL|div',\n",
       " 'DKFFE|GRZHDNGJYE|div',\n",
       " 'GRZHSNJZYE|DWYJCE|mul',\n",
       " 'GRYJCE|DKFFE|mul',\n",
       " 'DKFFE|DKYE|add',\n",
       " 'GRZHSNJZYE|DKYE|add',\n",
       " 'GRZHZT_catcount',\n",
       " 'GRZHYE|GRZHDNGJYE|div',\n",
       " 'DKLL|GRZHDNGJYE|mul',\n",
       " 'DKLL|DWYJCE|div',\n",
       " 'GRZHDNGJYE',\n",
       " 'GRJCJS|DWYJCE|div',\n",
       " 'GRJCJS|GRZHYE|mul',\n",
       " 'GRJCJS|DKFFE|sub',\n",
       " 'GRYJCE|DKLL|sub',\n",
       " 'GRZHSNJZYE|GRZHDNGJYE|sub',\n",
       " 'DKYE|GRZHDNGJYE|mul',\n",
       " 'DKLL|GRZHDNGJYE|sub',\n",
       " 'GRZHSNJZYE|DKYE|div',\n",
       " 'DKYE|GRZHDNGJYE|div',\n",
       " 'GRZHSNJZYE|GRZHYE|add',\n",
       " 'DKFFE|GRZHDNGJYE|sub',\n",
       " 'GRYJCE|GRZHDNGJYE|sub',\n",
       " 'GRJCJS|GRZHYE|div',\n",
       " 'DKFFE|DKYE|mul',\n",
       " 'GRZHYE|DKYE|mul',\n",
       " 'DKFFE|GRZHDNGJYE|mul',\n",
       " 'DWSSHY_countrank',\n",
       " 'GRYJCE|GRZHSNJZYE|add',\n",
       " 'GRYJCE|GRZHDNGJYE|div',\n",
       " 'GRJCJS|GRZHSNJZYE|div',\n",
       " 'GRYJCE|GRZHDNGJYE|mul',\n",
       " 'GRZHSNJZYE|GRZHDNGJYE|mul',\n",
       " 'XINGBIE_countrank',\n",
       " 'GRYJCE|GRJCJS|div',\n",
       " 'GRZHDNGJYE|DWYJCE|sub',\n",
       " 'GRZHSNJZYE|DKFFE|add',\n",
       " 'DKFFE',\n",
       " 'GRZHSNJZYE|DKFFE|mul',\n",
       " 'GRYJCE|GRZHYE|sub',\n",
       " 'GRZHSNJZYE|DWYJCE|div',\n",
       " 'GRYJCE|DKLL|div',\n",
       " 'GRJCJS|DKFFE|mul',\n",
       " 'DKFFE|DKYE|div',\n",
       " 'GRYJCE|GRZHDNGJYE|add',\n",
       " 'GRZHZT_countrank',\n",
       " 'DKYE|DWYJCE|mul',\n",
       " 'GRYJCE|DKFFE|add',\n",
       " 'GRZHSNJZYE|GRZHDNGJYE|add',\n",
       " 'GRJCJS|DKYE|add',\n",
       " 'GRZHYE|DWYJCE|div',\n",
       " 'GRJCJS|GRZHYE|sub',\n",
       " 'GRZHSNJZYE|DKYE|mul',\n",
       " 'GRZHDNGJYE|DKYE|sub',\n",
       " 'DKLL|DKYE|mul',\n",
       " 'GRZHDNGJYE|DWYJCE|div',\n",
       " 'DKFFE|DWYJCE|mul',\n",
       " 'DWJJLX_countrank',\n",
       " 'GRZHYE|DKYE|div',\n",
       " 'GRJCJS|GRZHDNGJYE|mul',\n",
       " 'GRZHSNJZYE|DKLL|mul',\n",
       " 'GRZHYE|GRZHDNGJYE|sub',\n",
       " 'GRJCJS|DKYE|div',\n",
       " 'GRYJCE|DKFFE|div',\n",
       " 'GRYJCE|DKLL|mul',\n",
       " 'GRZHSNJZYE|GRZHYE|mul',\n",
       " 'GRYJCE|DKFFE|sub',\n",
       " 'GRZHYE|GRZHDNGJYE|mul',\n",
       " 'DKYE|GRZHDNGJYE|add',\n",
       " 'GRJCJS|GRZHDNGJYE|sub',\n",
       " 'DKFFE|DWYJCE|div',\n",
       " 'GRZHYE',\n",
       " 'GRJCJS',\n",
       " 'DWSSHY_catcount',\n",
       " 'GRJCJS|DKFFE|add',\n",
       " 'GRZHSNJZYE|DWYJCE|sub',\n",
       " 'GRJCJS|GRZHYE|add',\n",
       " 'GRZHSNJZYE',\n",
       " 'DKLL',\n",
       " 'GRZHYE|DKYE|add',\n",
       " 'GRYJCE|GRJCJS|add',\n",
       " 'DKLL|DKYE|div',\n",
       " 'GRYJCE|DKYE|add',\n",
       " 'GRYJCE',\n",
       " 'DKFFE|GRZHYE|sub',\n",
       " 'GRYJCE|GRJCJS|sub',\n",
       " 'GRYJCE|GRZHSNJZYE|sub',\n",
       " 'DKYE',\n",
       " 'GRJCJS|GRZHDNGJYE|div',\n",
       " 'DKFFE|GRZHYE|add',\n",
       " 'GRJCJS|DKLL|mul',\n",
       " 'GRJCJS|DKLL|div',\n",
       " 'GRZHYE|DKLL|div',\n",
       " 'GRYJCE|GRZHYE|div',\n",
       " 'GRZHYE|DKLL|mul',\n",
       " 'GRZHSNJZYE|GRZHDNGJYE|div',\n",
       " 'XINGBIE_catcount',\n",
       " 'GRYJCE|GRZHSNJZYE|mul',\n",
       " 'DKLL|GRZHDNGJYE|div',\n",
       " 'CSNY',\n",
       " 'GRJCJS|DWYJCE|sub',\n",
       " 'GRZHSNJZYE|GRZHYE|sub',\n",
       " 'DKFFE|GRZHDNGJYE|add',\n",
       " 'DKYE|DWYJCE|div',\n",
       " 'GRZHSNJZYE|DKFFE|sub',\n",
       " 'DKYE|GRZHDNGJYE|sub',\n",
       " 'GRYJCE|DKYE|div',\n",
       " 'GRJCJS|GRZHDNGJYE|add',\n",
       " 'GRJCJS|GRZHSNJZYE|sub',\n",
       " 'DWJJLX_catcount',\n",
       " 'GRYJCE|GRZHYE|mul']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat0 = list(set(train.columns)-set(train.select_dtypes(object))-set(['label','id'])-set(cat_feat))\n",
    "remove_col = []\n",
    "for col in feat0:\n",
    "    if train[col].nunique() < 2:\n",
    "        remove_col.append(col)\n",
    "feat0 = list(set(feat0) - set(remove_col))\n",
    "feat0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true, y_predict):\n",
    "    '''\n",
    "    这是一个通用的计算最终分数的函数。\n",
    "    '''\n",
    "    d = pd.DataFrame()\n",
    "    d['y'] = list(y_true)\n",
    "    d['prob'] = list(y_predict)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    \n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.137295\tvalid_0's Weighted_Score: 0.408877\n",
      "0.40887681159420286 [0.40887681159420286]\n",
      "************************************ 2 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.141404\tvalid_0's Weighted_Score: 0.35308\n",
      "0.3809782608695652 [0.40887681159420286, 0.35307971014492756]\n",
      "************************************ 3 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.147347\tvalid_0's Weighted_Score: 0.347731\n",
      "0.3698959730660985 [0.40887681159420286, 0.35307971014492756, 0.34773139745916515]\n",
      "************************************ 4 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[70]\tvalid_0's binary_logloss: 0.140055\tvalid_0's Weighted_Score: 0.357713\n",
      "0.36685029195928354 [0.40887681159420286, 0.35307971014492756, 0.34773139745916515, 0.35771324863883847]\n",
      "************************************ 5 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.143421\tvalid_0's Weighted_Score: 0.38294\n",
      "0.3700682553460112 [0.40887681159420286, 0.35307971014492756, 0.34773139745916515, 0.35771324863883847, 0.38294010889292196]\n"
     ]
    }
   ],
   "source": [
    "def tpr_weight_funtion_lgb(y_true, y_predict):\n",
    "    '''\n",
    "    如果是给lgbm用的，参考https://github.com/microsoft/LightGBM/blob/c02917e493c36f3b1e349338f1087fed33126576/examples/python-guide/advanced_example.py#L154\n",
    "    第一个返回值，是这个函数的可以说是名字或者是标记吧；score就是得到的分数；最后一个就是问，score是越高越好吗。\n",
    "    '''\n",
    "#     y_predict = pred\n",
    "#     y_true = train_data #.get_label()\n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    \n",
    "    return \"Weighted_Score\", (0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3), True\n",
    "\n",
    "######################################################################\n",
    "kf = StratifiedKFold(5,True,random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "test_data = test[feat0].values\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "    print('************************************ {} ************************************'.format(str(idx+1)))\n",
    "\n",
    "    train_data = train.loc[train_index][feat0].values\n",
    "    valid_data = train.loc[valid_index][feat0].values\n",
    "    model = LGBMClassifier(\n",
    "        **params,\n",
    "#         n_estimators=10000, \n",
    "#         learning_rate=0.08, \n",
    "#         num_leaves=15, \n",
    "#         subsample=0.8, \n",
    "#         colsample_bytree=0.6, \n",
    "#         n_jobs=4,\n",
    "#         categorical_feature = categorical_fea_index, \n",
    "    )\n",
    "    model.fit(\n",
    "        train_data, train_y.loc[train_index], \n",
    "        eval_set=(valid_data, train_y.loc[valid_index]), \n",
    "        early_stopping_rounds=200,\n",
    "        verbose=200,\n",
    "        eval_metric = tpr_weight_funtion_lgb\n",
    "    )\n",
    "    pred = model.predict_proba(valid_data)[:,1]\n",
    "    prob[valid_index] = pred\n",
    "#     prob[valid_index] = model.predict_proba(valid_data)[:, 1]\n",
    "    \n",
    "    cv_scores.append(tpr_weight_funtion(train_y.iloc[valid_index], pred))\n",
    "    print(np.mean(cv_scores), cv_scores)\n",
    "    \n",
    "    test_prob += model.predict_proba(test_data)[:, 1]/kf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lgb_prob'] = prob\n",
    "test['lgb_prob'] = test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "0:\tlearn: 0.2371429\ttest: 0.2702899\tbest: 0.2702899 (0)\ttotal: 746ms\tremaining: 12m 25s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4432971014\n",
      "bestIteration = 259\n",
      "\n",
      "Shrink model to first 260 iterations.\n",
      "0.44329710144927537 [0.44329710144927537]\n",
      "************************************ 2 ************************************\n",
      "0:\tlearn: 0.2759184\ttest: 0.2168478\tbest: 0.2168478 (0)\ttotal: 733ms\tremaining: 12m 11s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8b3c9a189874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     model.fit(train_data, train_y.loc[train_index], \n\u001b[0;32m     96\u001b[0m               \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m              \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;31m#              eval_metric = score_forCAT()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m              )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4296\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4297\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4298\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4299\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1807\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1809\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1810\u001b[0m             )\n\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class score_forCAT(object):\n",
    "    '''\n",
    "    https://catboost.ai/docs/concepts/python-usages-examples.html#custom-loss-function-eval-metric\n",
    "    '''\n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "\n",
    "        ## weight没什么迪奥用。\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        \n",
    "        d = pd.DataFrame()\n",
    "        d['prob'] = list(approxes[0])\n",
    "        d['y'] = list(target)\n",
    "        d = d.sort_values(['prob'], ascending=[0])\n",
    "        y = d.y\n",
    "        PosAll = pd.Series(y).value_counts()[1]\n",
    "        NegAll = pd.Series(y).value_counts()[0]\n",
    "        pCumsum = d['y'].cumsum()\n",
    "        nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "        pCumsumPer = pCumsum / PosAll\n",
    "        nCumsumPer = nCumsum / NegAll\n",
    "        TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "        TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "        TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "        \n",
    "        score = (0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3)\n",
    "\n",
    "        return score, -1\n",
    "    \n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error\n",
    "\n",
    "kf = StratifiedKFold(5, True, random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "\n",
    "feat1=list(set(feat0 + cat_feat + ['lgb_prob']))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "test_data=test[feat1].values\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "#     print(list(train_y.iloc[train_index]))\n",
    "    print('************************************ {} ************************************'.format(str(idx+1)))\n",
    "    train_data = train.loc[train_index][feat1]\n",
    "    valid_data = train.loc[valid_index][feat1]\n",
    "    \n",
    "#     params_CAT = {\n",
    "#         'learning_rate': 0.1, \n",
    "#         'depth': 12, ## 曾经测试过15，但是一旦设置到15，就会奇慢无比\n",
    "#         'l2_leaf_reg': 80, #100 #50 # 设为20，能够达到40xx的分数。 \n",
    "#         'bootstrap_type': \"Bernoulli\", ## \"Bayesian\"比Bernoulli 略强点. 然后我们试试Bernoulli和subsample参数的组合吧。\n",
    "#         # \"bagging_temperature\": 2, ## 这个参数要跟bayesian bootstrap方法组合起来用。\n",
    "#         \"subsample\": 0.7, ## 窝槽，bernoulli+subsample加起来很吊啊。。。\n",
    "#         # \"sampling_frequency\": \"PerTree\", ## 这个设了没设一样。\n",
    "\n",
    "#         \"grow_policy\": \"Depthwise\", ## 这个有奇效。应该还有潜力可挖。\n",
    "#         \"min_data_in_leaf\": 2, ## 这个也有效果。默认是1，我估计这样搞就太精确了，容易导致过拟合。所以把区间放大一点效果反倒好。\n",
    "#         ## 上面两个，能够达到4236的分数。\n",
    "\n",
    "#         ## 如果要用这个参数，不要弄onehot。都交给catboost吧。\n",
    "#         \"one_hot_max_size\": 255, ## 能提高一点点。0.0002吧。\n",
    "\n",
    "#         ## 设置的大了，性能可能会下降。原档案警告如上。\n",
    "#         \"fold_permutation_block\": 2, ## 可能有效。可以关注一下。 设为2，达到了4250\n",
    "\n",
    "#         ## Balanced跑了两次，最高得到了4286的结果。不太稳定。\n",
    "#         \"auto_class_weights\": \"SqrtBalanced\",## 得到了4484，升级明显，多测几次，看看是不是偶然 \n",
    "\n",
    "#         ## 这个参数酌情不设吧。因为这个的作用应该跟StratifiedKFold一样吧。\n",
    "#         \"allow_const_label\": True,\n",
    "\n",
    "#         'od_type': 'Iter', \n",
    "#         'od_wait': 300, \n",
    "\n",
    "#         ## MinEntropy和默认值比较好，其他的比较拉垮。\n",
    "#         \"feature_border_type\": \"MinEntropy\", \n",
    "\n",
    "#         'random_seed': 11, \n",
    "#         'allow_writing_files': False, \n",
    "# #         \"task_type\": \"GPU\",\n",
    "#     }\n",
    "    params_CAT = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False, \n",
    "#                      \"task_type\": \"GPU\",\n",
    "                     }\n",
    "    model = CatBoostClassifier(\n",
    "        **params_CAT, \n",
    "        #iterations=10000, learning_rate=0.08, depth=7, \n",
    "        cat_features=cat_feat, \n",
    "        eval_metric= score_forCAT(), use_best_model= True\n",
    "    )\n",
    "    model.fit(train_data, train_y.loc[train_index], \n",
    "              eval_set=(valid_data, train_y.loc[valid_index]), early_stopping_rounds=50, \n",
    "             verbose=500\n",
    "#              eval_metric = score_forCAT()\n",
    "             )\n",
    "    pred = model.predict_proba(valid_data)[:,1]\n",
    "    prob[valid_index] = pred\n",
    "    test_prob += model.predict_proba(test_data)[:,1]/5\n",
    "    \n",
    "    cv_scores.append(tpr_weight_funtion(train_y.iloc[valid_index], pred))\n",
    "    print(np.mean(cv_scores), cv_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test_prob\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "test[['id', 'label']].to_csv('output/1215_count_rank.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
