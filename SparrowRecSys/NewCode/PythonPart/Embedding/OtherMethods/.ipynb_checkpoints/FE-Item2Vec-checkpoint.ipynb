{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install findspark pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://www.youtube.com/watch?v=qlY8m2Fk2D4&ab_channel=%E8%9A%82%E8%9A%81%E5%AD%A6Python \n",
    "\n",
    "title:【推荐系统 python】 21 Python 使用 PySpark 训练 item2vec 实现电影相关推荐\n",
    "\n",
    "GitHub: https://github.com/peiss/ant-learn-recsys, https://github.com/peiss/ant-learn-recsys/blob/master/04.%20Python%E8%AE%AD%E7%BB%83item2vec%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E7%9B%B8%E5%85%B3%E6%8E%A8%E8%8D%90.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO: \n",
    "\n",
    "* Input: rating data. \n",
    "* Output: a file `item2vecEmb.csv` which is the embedding of the movie ids. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the rating file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1094785740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580\n",
       "5       1      112     3.5  1094785740\n",
       "6       1      151     4.0  1094785734\n",
       "7       1      223     4.0  1112485573\n",
       "8       1      253     4.0  1112484940\n",
       "9       1      260     4.0  1112484826"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"D:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/\"\n",
    "rawSampleDataPath = file_path + \"/webroot/sampledata/ratings.csv\"\n",
    "\n",
    "rawSampleData = pd.read_csv(rawSampleDataPath)\n",
    "rawSampleData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the sequence of movie watching: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>924 919 337 151 112 50 541 593 29 293 47 296 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>62 110 589 70 908 480 266 3 260 541 924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>589 858 904 919 260 318 924 953 50 32 541 457 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10 356 454 480 589 377 586 350 368 370 594 520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>62 141 736 780 671 832 150 590 380 457 480 595...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                            movieId\n",
       "0       1  924 919 337 151 112 50 541 593 29 293 47 296 3...\n",
       "1       2            62 110 589 70 908 480 266 3 260 541 924\n",
       "2       3  589 858 904 919 260 318 924 953 50 32 541 457 ...\n",
       "3       4  10 356 454 480 589 377 586 350 368 370 594 520...\n",
       "4       5  62 141 736 780 671 832 150 590 380 457 480 595..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group = rawSampleData[rawSampleData.rating >= 3.5]\\\n",
    ".sort_values([\"userId\", \"timestamp\"], ascending = True)\\\n",
    ".groupby([\"userId\"])[\"movieId\"]\\\n",
    ".apply(lambda x: \" \".join([str(y) for y in x]) )\\\n",
    ".reset_index()\n",
    "df_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_group.to_csv(\"uid_movieids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a spark environment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark Item2vec\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.csv(\"preprocessedData/uid_movieids.csv\", header=True)\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a spark dataframe from a pandas dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|             movieId|\n",
      "+------+--------------------+\n",
      "|     1|924 919 337 151 1...|\n",
      "|     2|62 110 589 70 908...|\n",
      "|     3|589 858 904 919 2...|\n",
      "|     4|10 356 454 480 58...|\n",
      "|     5|62 141 736 780 67...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(df_group)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the spark dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# 把非常的字符串格式变成LIST形式\n",
    "df = df.withColumn('movie_ids', F.split(df.movieId, \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|userId|             movieId|           movie_ids|\n",
      "+------+--------------------+--------------------+\n",
      "|     1|924 919 337 151 1...|[924, 919, 337, 1...|\n",
      "|     2|62 110 589 70 908...|[62, 110, 589, 70...|\n",
      "|     3|589 858 904 919 2...|[589, 858, 904, 9...|\n",
      "|     4|10 356 454 480 58...|[10, 356, 454, 48...|\n",
      "|     5|62 141 736 780 67...|[62, 141, 736, 78...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the word2vec: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec()\\\n",
    ".setVectorSize(10)\\\n",
    ".setWindowSize(5)\\\n",
    ".setInputCol(\"movie_ids\")\\\n",
    ".setOutputCol(\"movie_2vec\")\n",
    "\n",
    "model = word2vec.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = model.findSynonyms(\"158\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|word|        similarity|\n",
      "+----+------------------+\n",
      "| 256|0.9595181941986084|\n",
      "| 186|0.9306996464729309|\n",
      "|  48|0.9181866645812988|\n",
      "| 168|0.9145238399505615|\n",
      "| 355|0.9065435528755188|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synonyms.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for row in model.getVectors().rdd.collect():\n",
    "#     print(row[\"word\"],  \" \".join([str(_) for _ in row[\"vector\"]])    )\n",
    "# #     print(movie_id)\n",
    "#     counter += 1\n",
    "#     if counter >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(model.getVectors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the movie vectors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 881/881 [00:00<00:00, 31546.62it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"preprocessedData/item2vecEmb_xmk.csv\", 'w') as f:\n",
    "    for row in tqdm.tqdm(model.getVectors().rdd.collect()):\n",
    "        movie_id = row[\"word\"]\n",
    "        vectors = \" \".join([str(_) for _ in row[\"vector\"]])\n",
    "        f.write(\"{}:{}\\n\".format(movie_id, vectors))\n",
    "#     for movie_id in model.getVectors().rdd.collect():\n",
    "#         vectors = \" \".join([str(emb) for emb in model.getVectors()[movie_id]])\n",
    "#         f.write(movie_id + \":\" + vectors + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the users: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the basic logic of user embedding? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingSamples = spark.createDataFrame(rawSampleData)\n",
    "ratingSamples.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|word|              vector|\n",
      "+----+--------------------+\n",
      "| 710|[0.41551432013511...|\n",
      "| 205|[0.47179889678955...|\n",
      "|  45|[-0.2113690823316...|\n",
      "| 515|[-0.2060780823230...|\n",
      "| 574|[0.34873422980308...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.getVectors().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 881/881 [00:00<00:00, 97588.32it/s]\n"
     ]
    }
   ],
   "source": [
    "Vectors_list = []\n",
    "# for key, value in model.getVectors().items():\n",
    "#     Vectors_list.append((key, list(value)))\n",
    "for row in tqdm.tqdm(model.getVectors().rdd.collect()):\n",
    "    movie_id = row[\"word\"]\n",
    "    vector = [float(_) for _ in row[\"vector\"]] ## 这里要转化为python基本形式, 如果不转的话, 就是numpy.float64, 这种格式后面是会遇上问题的. \n",
    "    Vectors_list.append((movie_id, vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors_list[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.createDataFrame(samples.tolist(), FloatType()).toDF(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    StructField('movieId', StringType(), False),\n",
    "    StructField('emb', ArrayType(DoubleType()), False)\n",
    "]\n",
    "schema = StructType(fields)\n",
    "Vectors_df = spark.createDataFrame(Vectors_list, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingSamples = ratingSamples.join(Vectors_df, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ratingSamples.select('userId', 'emb').rdd.map(lambda x: (x[0], x[1])).reduceByKey(lambda a, b: [a[i] + b[i] for i in range(len(a))]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6455604750663042 3.6822450892068446 -1.0383881330490112 1.9448952544480562 8.581681437790394 -0.15152354445308447 -1.0901359003037214 -4.314250817522407 3.0553889609873295 -1.4465340673923492\n"
     ]
    }
   ],
   "source": [
    "with open(\"preprocessedData/userEmb_xmk.csv\", 'w') as f:\n",
    "    for row in results:\n",
    "        userId = row[0]\n",
    "        vectors = \" \".join([str(emb) for emb in row[1]])\n",
    "        if userId == 1: \n",
    "            print(userId, vectors)\n",
    "        f.write(\"{}:{}\\n\".format(userId, vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(后面的代码可以不用跑了, 只是做实验的.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1 = ratingSamples.where(col(\"userId\") == \"1\").rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6455604750663042, 3.6822450892068446, -1.0383881330490112, 1.9448952544480562, 8.581681437790394, -0.15152354445308447, -1.0901359003037214, -4.314250817522407, 3.0553889609873295, -1.4465340673923492]\n"
     ]
    }
   ],
   "source": [
    "target = [0] * len(samples_1[0][\"emb\"])\n",
    "for row in samples_1:\n",
    "#     print(row[\"emb\"])\n",
    "    target = [target[i] + row[\"emb\"][i] for i in range(len(target))]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到了吗, 最后计算的到的userEmb, 和我自己做实验写的代码(将userId为1的用户看过的, 有embedding的电影, 的embedding, 加起来.)计算出来的embedding, 是一样的. 证明**原作者计算的所谓用户embedding就是用户看过电影的embedding的和.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
