{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\n",
    "# H:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample as tf dataset\n",
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=12,\n",
    "        label_name='label',\n",
    "        na_value=\"0\",\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(\n",
    "    #\"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/trainingSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\trainingSamples.csv\"\n",
    ")\n",
    "test_dataset = get_dataset(\n",
    "#     \"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/testSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\testSamples.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'movieAvgRating': tf.keras.layers.Input(name='movieAvgRating', shape=(), dtype='float32'),\n",
    "    'movieRatingStddev': tf.keras.layers.Input(name='movieRatingStddev', shape=(), dtype='float32'),\n",
    "    'movieRatingCount': tf.keras.layers.Input(name='movieRatingCount', shape=(), dtype='int32'),\n",
    "    'userAvgRating': tf.keras.layers.Input(name='userAvgRating', shape=(), dtype='float32'),\n",
    "    'userRatingStddev': tf.keras.layers.Input(name='userRatingStddev', shape=(), dtype='float32'),\n",
    "    'userRatingCount': tf.keras.layers.Input(name='userRatingCount', shape=(), dtype='int32'),\n",
    "    'releaseYear': tf.keras.layers.Input(name='releaseYear', shape=(), dtype='int32'),\n",
    "\n",
    "    'movieId': tf.keras.layers.Input(name='movieId', shape=(), dtype='int32'),\n",
    "    'userId': tf.keras.layers.Input(name='userId', shape=(), dtype='int32'),\n",
    "    'userRatedMovie1': tf.keras.layers.Input(name='userRatedMovie1', shape=(), dtype='int32'),\n",
    "\n",
    "    'userGenre1': tf.keras.layers.Input(name='userGenre1', shape=(), dtype='string'),\n",
    "    'userGenre2': tf.keras.layers.Input(name='userGenre2', shape=(), dtype='string'),\n",
    "    'userGenre3': tf.keras.layers.Input(name='userGenre3', shape=(), dtype='string'),\n",
    "    'userGenre4': tf.keras.layers.Input(name='userGenre4', shape=(), dtype='string'),\n",
    "    'userGenre5': tf.keras.layers.Input(name='userGenre5', shape=(), dtype='string'),\n",
    "    'movieGenre1': tf.keras.layers.Input(name='movieGenre1', shape=(), dtype='string'),\n",
    "    'movieGenre2': tf.keras.layers.Input(name='movieGenre2', shape=(), dtype='string'),\n",
    "    'movieGenre3': tf.keras.layers.Input(name='movieGenre3', shape=(), dtype='string'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie id embedding feature\n",
    "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)\n",
    "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
    "movie_ind_col = tf.feature_column.indicator_column(movie_col) # movid id indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user id embedding feature\n",
    "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\n",
    "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
    "user_ind_col = tf.feature_column.indicator_column(user_col) # user id indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre features vocabulary\n",
    "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
    "               'Sci-Fi', 'Drama', 'Thriller',\n",
    "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user genre embedding feature\n",
    "user_genre_col = tf.feature_column.categorical_column_with_vocabulary_list(key=\"userGenre1\",\n",
    "                                                                           vocabulary_list=genre_vocab)\n",
    "user_genre_emb_col = tf.feature_column.embedding_column(user_genre_col, 10)\n",
    "user_genre_ind_col = tf.feature_column.indicator_column(user_genre_col) # user genre indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item genre embedding feature\n",
    "item_genre_col = tf.feature_column.categorical_column_with_vocabulary_list(key=\"movieGenre1\",\n",
    "                                                                           vocabulary_list=genre_vocab)\n",
    "item_genre_emb_col = tf.feature_column.embedding_column(item_genre_col, 10)\n",
    "item_genre_ind_col = tf.feature_column.indicator_column(item_genre_col) # item genre indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb_layer = tf.keras.layers.DenseFeatures([movie_emb_col])(inputs)\n",
    "user_emb_layer = tf.keras.layers.DenseFeatures([user_emb_col])(inputs)\n",
    "item_genre_emb_layer = tf.keras.layers.DenseFeatures([item_genre_emb_col])(inputs)\n",
    "user_genre_emb_layer = tf.keras.layers.DenseFeatures([user_genre_emb_col])(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM part, cross different categorical feature embeddings\n",
    "product_layer_item_user = tf.keras.layers.Dot(axes=1)([item_emb_layer, user_emb_layer])\n",
    "product_layer_item_genre_user_genre = tf.keras.layers.Dot(axes=1)([item_genre_emb_layer, user_genre_emb_layer])\n",
    "product_layer_item_genre_user = tf.keras.layers.Dot(axes=1)([item_genre_emb_layer, user_emb_layer])\n",
    "product_layer_user_genre_item = tf.keras.layers.Dot(axes=1)([item_emb_layer, user_genre_emb_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm first-order term columns: without embedding and concatenate to the output layer directly\n",
    "fm_first_order_columns = [movie_ind_col, user_ind_col, user_genre_ind_col, item_genre_ind_col]\n",
    "\n",
    "# The first-order term in the FM layer\n",
    "fm_first_order_layer = tf.keras.layers.DenseFeatures(fm_first_order_columns)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_feature_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
    "                        tf.feature_column.numeric_column('movieRatingCount'),\n",
    "                        tf.feature_column.numeric_column('movieAvgRating'),\n",
    "                        tf.feature_column.numeric_column('movieRatingStddev'),\n",
    "                        tf.feature_column.numeric_column('userRatingCount'),\n",
    "                        tf.feature_column.numeric_column('userAvgRating'),\n",
    "                        tf.feature_column.numeric_column('userRatingStddev'),\n",
    "                        movie_emb_col,\n",
    "                        user_emb_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep part, MLP to generalize all input features\n",
    "deep = tf.keras.layers.DenseFeatures(deep_feature_columns)(inputs)\n",
    "deep = tf.keras.layers.Dense(64, activation='relu')(deep)\n",
    "deep = tf.keras.layers.Dense(64, activation='relu')(deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate fm part and deep part\n",
    "concat_layer = tf.keras.layers.concatenate([fm_first_order_layer, product_layer_item_user, product_layer_item_genre_user_genre,\n",
    "                                            product_layer_item_genre_user, product_layer_user_genre_item, deep], axis=1)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(concat_layer)\n",
    "model = tf.keras.Model(inputs, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "### 怎么跑下一行代码? 需要预装一点东西. \n",
    "##### https://stackoverflow.com/questions/47605558/importerror-failed-to-import-pydot-you-must-install-pydot-and-graphviz-for-py\n",
    "# pip install pydot\n",
    "# pip install pydotplus\n",
    "# pip install graphviz\n",
    "# Download and install graphviz binaries from https://graphviz.gitlab.io/_pages/Download/Download_windows.html \n",
    "# Add path to graphviz bin folder in system PATH\n",
    "\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xmk23\\appdata\\local\\continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:595: UserWarning: Input dict contained keys ['rating', 'timestamp', 'userRatedMovie2', 'userRatedMovie3', 'userRatedMovie4', 'userRatedMovie5', 'userAvgReleaseYear', 'userReleaseYearStddev'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7403/7403 [==============================] - 149s 20ms/step - loss: 0.8639 - accuracy: 0.6133 - auc: 0.6373 - auc_1: 0.6745\n",
      "Epoch 2/5\n",
      "7403/7403 [==============================] - 135s 18ms/step - loss: 0.5690 - accuracy: 0.7068 - auc: 0.7706 - auc_1: 0.7985\n",
      "Epoch 3/5\n",
      "7403/7403 [==============================] - 128s 17ms/step - loss: 0.5080 - accuracy: 0.7528 - auc: 0.8263 - auc_1: 0.8514\n",
      "Epoch 4/5\n",
      "7403/7403 [==============================] - 127s 17ms/step - loss: 0.4473 - accuracy: 0.7911 - auc: 0.8701 - auc_1: 0.8916\n",
      "Epoch 5/5\n",
      "7403/7403 [==============================] - 138s 19ms/step - loss: 0.3910 - accuracy: 0.8232 - auc: 0.9029 - auc_1: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f8854c550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = tf.keras.Model(inputs, output_layer)\n",
    "# compile the model, set loss function, optimizer and evaluation metrics\n",
    "# tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'), tf.keras.metrics.AUC(curve='PR')])\n",
    "\n",
    "# train the model\n",
    "model.fit(train_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870/1870 [==============================] - 17s 8ms/step - loss: 0.7332 - accuracy: 0.6556 - auc: 0.6995 - auc_1: 0.7320\n",
      "\n",
      "\n",
      "Test Loss 0.7332375049591064, Test Accuracy 0.655570387840271, Test ROC AUC 0.6995195746421814, Test PR AUC 0.7320491075515747\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}, Test ROC AUC {}, Test PR AUC {}'.format(test_loss, test_accuracy,\n",
    "                                                                                   test_roc_auc, test_pr_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted good rating: 61.63%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 41.23%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 2.46%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 79.41%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 91.53%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 90.86%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 3.92%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 76.59%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 1.46%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 7.92%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 37.97%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 94.39%  | Actual rating label:  Good Rating\n"
     ]
    }
   ],
   "source": [
    "# print some predict results\n",
    "predictions = model.predict(test_dataset)\n",
    "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
    "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
    "          \" | Actual rating label: \",\n",
    "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model, \n",
    "#     \"file:///Users/zhewang/Workspace/SparrowRecSys/src/main/resources/webroot/modeldata/deepfm/001\", \n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\modeldata\",\n",
    "    overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
