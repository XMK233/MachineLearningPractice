{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample as tf dataset\n",
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=12,\n",
    "        label_name='label',\n",
    "        na_value=\"0\",\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(\n",
    "    #\"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/trainingSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\trainingSamples.csv\"\n",
    ")\n",
    "test_dataset = get_dataset(\n",
    "#     \"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/testSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\testSamples.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input for keras model\n",
    "inputs = {\n",
    "    'movieAvgRating': tf.keras.layers.Input(name='movieAvgRating', shape=(), dtype='float32'),\n",
    "    'movieRatingStddev': tf.keras.layers.Input(name='movieRatingStddev', shape=(), dtype='float32'),\n",
    "    'movieRatingCount': tf.keras.layers.Input(name='movieRatingCount', shape=(), dtype='int32'),\n",
    "    'userAvgRating': tf.keras.layers.Input(name='userAvgRating', shape=(), dtype='float32'),\n",
    "    'userRatingStddev': tf.keras.layers.Input(name='userRatingStddev', shape=(), dtype='float32'),\n",
    "    'userRatingCount': tf.keras.layers.Input(name='userRatingCount', shape=(), dtype='int32'),\n",
    "    'releaseYear': tf.keras.layers.Input(name='releaseYear', shape=(), dtype='int32'),\n",
    "\n",
    "    'movieId': tf.keras.layers.Input(name='movieId', shape=(), dtype='int32'),\n",
    "    'userId': tf.keras.layers.Input(name='userId', shape=(), dtype='int32'),\n",
    "    'userRatedMovie1': tf.keras.layers.Input(name='userRatedMovie1', shape=(), dtype='int32'),\n",
    "\n",
    "    'userGenre1': tf.keras.layers.Input(name='userGenre1', shape=(), dtype='string'),\n",
    "    'userGenre2': tf.keras.layers.Input(name='userGenre2', shape=(), dtype='string'),\n",
    "    'userGenre3': tf.keras.layers.Input(name='userGenre3', shape=(), dtype='string'),\n",
    "    'userGenre4': tf.keras.layers.Input(name='userGenre4', shape=(), dtype='string'),\n",
    "    'userGenre5': tf.keras.layers.Input(name='userGenre5', shape=(), dtype='string'),\n",
    "    'movieGenre1': tf.keras.layers.Input(name='movieGenre1', shape=(), dtype='string'),\n",
    "    'movieGenre2': tf.keras.layers.Input(name='movieGenre2', shape=(), dtype='string'),\n",
    "    'movieGenre3': tf.keras.layers.Input(name='movieGenre3', shape=(), dtype='string'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre features vocabulary\n",
    "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
    "               'Sci-Fi', 'Drama', 'Thriller',\n",
    "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n",
    "\n",
    "GENRE_FEATURES = {\n",
    "    'userGenre1': genre_vocab,\n",
    "    'userGenre2': genre_vocab,\n",
    "    'userGenre3': genre_vocab,\n",
    "    'userGenre4': genre_vocab,\n",
    "    'userGenre5': genre_vocab,\n",
    "    'movieGenre1': genre_vocab,\n",
    "    'movieGenre2': genre_vocab,\n",
    "    'movieGenre3': genre_vocab\n",
    "}\n",
    "\n",
    "# all categorical features\n",
    "categorical_columns = []\n",
    "for feature, vocab in GENRE_FEATURES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature, vocabulary_list=vocab)\n",
    "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
    "    categorical_columns.append(emb_col)\n",
    "# movie id embedding feature\n",
    "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)\n",
    "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
    "categorical_columns.append(movie_emb_col)\n",
    "\n",
    "# user id embedding feature\n",
    "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\n",
    "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
    "categorical_columns.append(user_emb_col)\n",
    "\n",
    "# all numerical features\n",
    "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
    "                     tf.feature_column.numeric_column('movieRatingCount'),\n",
    "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
    "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
    "                     tf.feature_column.numeric_column('userRatingCount'),\n",
    "                     tf.feature_column.numeric_column('userAvgRating'),\n",
    "                     tf.feature_column.numeric_column('userRatingStddev')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide and deep model architecture\n",
    "# deep part for all input features\n",
    "deep = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)(inputs)\n",
    "deep = tf.keras.layers.Dense(128, activation='relu')(deep)\n",
    "deep = tf.keras.layers.Dense(128, activation='relu')(deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature \n",
    "Crossing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross feature between current movie and user historical movie\n",
    "rated_movie = tf.feature_column.categorical_column_with_identity(key='userRatedMovie1', num_buckets=1001)\n",
    "## 大概了解了什么是indicator_column: 说白了就是categorical_column_with_identity做了onehot之后的结果的一个稠密化，供模型的后续使用。\n",
    "### 参考：https://cloud.tencent.com/developer/article/1467606\n",
    "crossed_feature = tf.feature_column.indicator_column(tf.feature_column.crossed_column([movie_col, rated_movie], 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide part for cross feature\n",
    "wide = tf.keras.layers.DenseFeatures(crossed_feature)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the 2 parts of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = tf.keras.layers.concatenate([deep, wide])\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
    "model = tf.keras.Model(inputs, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 10000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xmk23\\appdata\\local\\continuum\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:595: UserWarning: Input dict contained keys ['rating', 'timestamp', 'userRatedMovie2', 'userRatedMovie3', 'userRatedMovie4', 'userRatedMovie5', 'userAvgReleaseYear', 'userReleaseYearStddev'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7403/7403 [==============================] - 80s 10ms/step - loss: 1.0664 - accuracy: 0.5801 - auc: 0.5970 - auc_1: 0.6430\n",
      "Epoch 2/5\n",
      "7403/7403 [==============================] - 66s 9ms/step - loss: 0.6064 - accuracy: 0.6760 - auc: 0.7271 - auc_1: 0.7545\n",
      "Epoch 3/5\n",
      "7403/7403 [==============================] - 62s 8ms/step - loss: 0.5532 - accuracy: 0.7209 - auc: 0.7850 - auc_1: 0.8062\n",
      "Epoch 4/5\n",
      "7403/7403 [==============================] - 63s 9ms/step - loss: 0.5085 - accuracy: 0.7522 - auc: 0.8243 - auc_1: 0.8465\n",
      "Epoch 5/5\n",
      "7403/7403 [==============================] - 66s 9ms/step - loss: 0.4847 - accuracy: 0.7666 - auc: 0.8433 - auc_1: 0.8650\n",
      "1870/1870 [==============================] - 9s 4ms/step - loss: 0.6176 - accuracy: 0.6840 - auc: 0.7436 - auc_1: 0.7684\n",
      "\n",
      "\n",
      "Test Loss 0.6175830364227295, Test Accuracy 0.6840463280677795, Test ROC AUC 0.7436078190803528, Test PR AUC 0.7683594226837158\n",
      "Predicted good rating: 70.57%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 22.83%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 81.93%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 9.97%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 17.43%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 52.75%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 5.56%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 53.98%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 83.81%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 53.51%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 78.87%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 13.43%  | Actual rating label:  Good Rating\n"
     ]
    }
   ],
   "source": [
    "# compile the model, set loss function, optimizer and evaluation metrics\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'), tf.keras.metrics.AUC(curve='PR')])\n",
    "\n",
    "# train the model\n",
    "model.fit(train_dataset, epochs=5)\n",
    "\n",
    "# evaluate the model\n",
    "test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}, Test ROC AUC {}, Test PR AUC {}'.format(test_loss, test_accuracy,\n",
    "                                                                                   test_roc_auc, test_pr_auc))\n",
    "\n",
    "# print some predict results\n",
    "predictions = model.predict(test_dataset)\n",
    "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
    "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
    "          \" | Actual rating label: \",\n",
    "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
