{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample as tf dataset\n",
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=12,\n",
    "        label_name='label',\n",
    "        na_value=\"0\",\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(\n",
    "    #\"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/trainingSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\trainingSamples.csv\"\n",
    ")\n",
    "test_dataset = get_dataset(\n",
    "#     \"H:/MachineLearningPractice/SparrowRecSys/NewCode/JavaPart/src/main/resources/webroot/sampledata/testSamples.csv\"\n",
    "    r\"D:\\MachineLearningPractice\\SparrowRecSys\\NewCode\\JavaPart\\src\\main\\resources\\webroot\\sampledata\\testSamples.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
    "               'Sci-Fi', 'Drama', 'Thriller',\n",
    "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n",
    "\n",
    "GENRE_FEATURES = {\n",
    "    'userGenre1': genre_vocab,\n",
    "    'userGenre2': genre_vocab,\n",
    "    'userGenre3': genre_vocab,\n",
    "    'userGenre4': genre_vocab,\n",
    "    'userGenre5': genre_vocab,\n",
    "    'movieGenre1': genre_vocab,\n",
    "    'movieGenre2': genre_vocab,\n",
    "    'movieGenre3': genre_vocab\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all categorical features\n",
    "categorical_columns = []\n",
    "for feature, vocab in GENRE_FEATURES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list( ## to one-hot\n",
    "        key=feature, vocabulary_list=vocab)\n",
    "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
    "    categorical_columns.append(emb_col)\n",
    "# movie id embedding feature\n",
    "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001) ## to one-hot\n",
    "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
    "categorical_columns.append(movie_emb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user id embedding feature\n",
    "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\n",
    "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
    "categorical_columns.append(user_emb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all numerical features\n",
    "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
    "                     tf.feature_column.numeric_column('movieRatingCount'),\n",
    "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
    "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
    "                     tf.feature_column.numeric_column('userRatingCount'),\n",
    "                     tf.feature_column.numeric_column('userAvgRating'),\n",
    "                     tf.feature_column.numeric_column('userRatingStddev')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('movieId', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int32>), ('userId', <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=int32>), ('rating', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>), ('timestamp', <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int32>), ('releaseYear', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=int32>), ('movieGenre1', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('movieGenre2', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('movieGenre3', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('movieRatingCount', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int32>), ('movieAvgRating', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('movieRatingStddev', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>), ('userRatedMovie1', <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int32>), ('userRatedMovie2', <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int32>), ('userRatedMovie3', <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=int32>), ('userRatedMovie4', <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=int32>), ('userRatedMovie5', <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=int32>), ('userRatingCount', <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=int32>), ('userAvgReleaseYear', <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=int32>), ('userReleaseYearStddev', <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>), ('userAvgRating', <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>), ('userRatingStddev', <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>), ('userGenre1', <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>), ('userGenre2', <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>), ('userGenre3', <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>), ('userGenre4', <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>), ('userGenre5', <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('movieId', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int32>), ('userId', <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=int32>), ('rating', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>), ('timestamp', <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int32>), ('releaseYear', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=int32>), ('movieGenre1', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('movieGenre2', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('movieGenre3', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('movieRatingCount', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int32>), ('movieAvgRating', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('movieRatingStddev', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>), ('userRatedMovie1', <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int32>), ('userRatedMovie2', <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int32>), ('userRatedMovie3', <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=int32>), ('userRatedMovie4', <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=int32>), ('userRatedMovie5', <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=int32>), ('userRatingCount', <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=int32>), ('userAvgReleaseYear', <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=int32>), ('userReleaseYearStddev', <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>), ('userAvgRating', <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>), ('userRatingStddev', <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>), ('userGenre1', <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>), ('userGenre2', <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>), ('userGenre3', <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>), ('userGenre4', <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>), ('userGenre5', <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "7403/7403 [==============================] - 72s 9ms/step - loss: 6.6919 - accuracy: 0.5520 - auc: 0.5560 - auc_1: 0.6066\n",
      "Epoch 2/5\n",
      "7403/7403 [==============================] - 68s 9ms/step - loss: 0.6977 - accuracy: 0.6427 - auc: 0.6825 - auc_1: 0.7142 4s - loss: - E\n",
      "Epoch 3/5\n",
      "7403/7403 [==============================] - 62s 8ms/step - loss: 0.5669 - accuracy: 0.7087 - auc: 0.7694 - auc_1: 0.7903\n",
      "Epoch 4/5\n",
      "7403/7403 [==============================] - 57s 8ms/step - loss: 0.5267 - accuracy: 0.7397 - auc: 0.8090 - auc_1: 0.8275\n",
      "Epoch 5/5\n",
      "7403/7403 [==============================] - 68s 9ms/step - loss: 0.5015 - accuracy: 0.7539 - auc: 0.8300 - auc_1: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c2f78f1668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding + MLP model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "# compile the model, set loss function, optimizer and evaluation metrics\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'), tf.keras.metrics.AUC(curve='PR')])\n",
    "\n",
    "# train the model\n",
    "model.fit(train_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('movieId', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int32>), ('userId', <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=int32>), ('rating', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>), ('timestamp', <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int32>), ('releaseYear', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=int32>), ('movieGenre1', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('movieGenre2', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('movieGenre3', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('movieRatingCount', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int32>), ('movieAvgRating', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('movieRatingStddev', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>), ('userRatedMovie1', <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int32>), ('userRatedMovie2', <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int32>), ('userRatedMovie3', <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=int32>), ('userRatedMovie4', <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=int32>), ('userRatedMovie5', <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=int32>), ('userRatingCount', <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=int32>), ('userAvgReleaseYear', <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=int32>), ('userReleaseYearStddev', <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>), ('userAvgRating', <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>), ('userRatingStddev', <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>), ('userGenre1', <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>), ('userGenre2', <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>), ('userGenre3', <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>), ('userGenre4', <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>), ('userGenre5', <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "1870/1870 [==============================] - 10s 3ms/step - loss: 0.5997 - accuracy: 0.6941 - auc: 0.7531 - auc_1: 0.7813\n",
      "\n",
      "\n",
      "Test Loss 0.5997158885002136, Test Accuracy 0.6940730810165405, Test ROC AUC 0.7531378865242004, Test PR AUC 0.7812909483909607\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}, Test ROC AUC {}, Test PR AUC {}'.format(test_loss, test_accuracy,\n",
    "                                                                                   test_roc_auc, test_pr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('movieId', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int32>), ('userId', <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=int32>), ('rating', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>), ('timestamp', <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=int32>), ('releaseYear', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=int32>), ('movieGenre1', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>), ('movieGenre2', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('movieGenre3', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('movieRatingCount', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int32>), ('movieAvgRating', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('movieRatingStddev', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>), ('userRatedMovie1', <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=int32>), ('userRatedMovie2', <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=int32>), ('userRatedMovie3', <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=int32>), ('userRatedMovie4', <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=int32>), ('userRatedMovie5', <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=int32>), ('userRatingCount', <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=int32>), ('userAvgReleaseYear', <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=int32>), ('userReleaseYearStddev', <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>), ('userAvgRating', <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float32>), ('userRatingStddev', <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>), ('userGenre1', <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>), ('userGenre2', <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>), ('userGenre3', <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>), ('userGenre4', <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>), ('userGenre5', <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "Predicted good rating: 86.09%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 97.90%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 75.16%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 91.10%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 37.20%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 66.78%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 61.58%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 64.67%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 52.10%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 81.53%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 92.83%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 67.02%  | Actual rating label:  Good Rating\n"
     ]
    }
   ],
   "source": [
    "# print some predict results\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
    "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
    "          \" | Actual rating label: \",\n",
    "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other codes\n",
    "\n",
    "You can test out some detail parts in previous code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ed836211a6a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
