{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VTGKBzAtohn"
   },
   "source": [
    "# Release Notes\n",
    "\n",
    "上一个版本：`3.4-FE-SomeAvgAndIncrementalProportion-ChangeHP_CAT, 2.0-EDA-1-forQuarter4`\n",
    "\n",
    "我们从一开始就使用featuretools来搞。这样就要完全重新设计特征计算的思路了。\n",
    "\n",
    "注意，这里的代码，最好只跑一次，把结果暂存本地之后，重复使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "_SRLl5araf_d"
   },
   "source": [
    "# Setting working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15114,
     "status": "ok",
     "timestamp": 1607146985845,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "uYrTyv-UafC6",
    "outputId": "5a9c7d95-98dd-462f-97aa-e6325ab49f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1607146987282,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "ZyoMIfsAbiNI"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/XiamenIntlBank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a2b09970cabc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/XiamenIntlBank'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/XiamenIntlBank'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/XiamenIntlBank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XBqtONK5azWB"
   },
   "source": [
    "Go to this place for original dataset: \n",
    "\n",
    "`'/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/FinanceRiskControl/originalDataset'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0B7KKhqBIlS9"
   },
   "outputs": [],
   "source": [
    "## 安装catboost和lightgbm。\n",
    "## catboost耗费显存极大，但是飞快；lightgbm好像不是那么的方便，gpu使用不起来。\n",
    "# !pip install catboost\n",
    "\n",
    "# !pip install featuretools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drotXWXNMFL-"
   },
   "source": [
    "# Importing libraries and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1607151175126,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "NY-oAIAAIggg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, cohen_kappa_score\n",
    "# import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import featuretools as ft\n",
    "import re, os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wABHFDoycf1A"
   },
   "source": [
    "# Rudimentary processing\n",
    "\n",
    "Like encoding some object type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original dataset\n",
    "\n",
    "重新设计特征处理的方式。这种方式要分开加载各个子表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeColName(df_origin, df_name):\n",
    "    '''\n",
    "    df_origin is data frame\n",
    "    df_name is string, the name of the dataframe\n",
    "    '''\n",
    "    df = df_origin.copy()\n",
    "    cols = df.columns\n",
    "    newCols = []\n",
    "    for col in cols:\n",
    "        if col == \"cust_no\":\n",
    "            newCol = col\n",
    "        else:\n",
    "            newCol = \"{}_{}\".format(df_name, col)\n",
    "        newCols.append(newCol)\n",
    "    df.columns = newCols\n",
    "    return df\n",
    "\n",
    "def changeColName_id(df_origin, df_name):\n",
    "    df = df_origin.copy()\n",
    "    df.rename(columns = {\"cust_no\": \"cust_no-\" + df_name}, inplace = True)\n",
    "    return df\n",
    "\n",
    "def transformTheDateToYearMonthDay(data, feas):\n",
    "    ## 将日期列变成三个列：年，月，日\n",
    "    for fea in feas: \n",
    "        print(fea)\n",
    "        if fea in [\"behavior_m3_B6\"]: ## 这个列有时分秒，不只有日期。\n",
    "            data[fea + \"_DT\"] = pd.to_datetime(data[fea],format = '%Y-%m-%d %H:%M:%S')\n",
    "        else: ## 这些列，只有日期。\n",
    "            data[fea + \"_DT\"] = pd.to_datetime(data[fea],format = '%Y-%m-%d')\n",
    "        ## \n",
    "        data[fea + \"_Year\"] = featuretools.primitives.Year()(data[fea + \"_DT\"])\n",
    "        ## \n",
    "        data[fea + \"_Month\"] = featuretools.primitives.Month()(data[fea + \"_DT\"])\n",
    "        ## \n",
    "        data[fea + \"_Day\"] = featuretools.primitives.Day()(data[fea + \"_DT\"])\n",
    "        ### \n",
    "        data.drop([fea, fea + \"_DT\"], axis = 1, inplace = True)\n",
    "        \n",
    "def transformTheDateToDaysFrom20000101(data, feas):\n",
    "    ## 将日期转换为距离新千年第一天的距离\n",
    "    startdate = datetime.datetime.strptime(\n",
    "        \"2000-01-01 00:00:00\",\n",
    "        '%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "#     (data_train[\"behavior_m3_B6_DT\"] - data_train[fea + \"_DT\"]).dt.days\n",
    "    for fea in feas:   \n",
    "        print(fea)\n",
    "        data[fea] = data[fea].astype(str)\n",
    "        if fea in [\"behavior_m3_B6\"]: ## 这个列有时分秒，不只有日期。\n",
    "            data[fea] = pd.to_datetime(data[fea],format = '%Y-%m-%d %H:%M:%S')\n",
    "            data[fea] = data[fea].apply(lambda x: x-startdate).dt.days\n",
    "        else: ## 这些列，只有日期。\n",
    "            data[fea] = pd.to_datetime(data[fea],format='%Y-%m-%d')\n",
    "            data[fea] = data[fea].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这些数据，看样子都是数值型的\n",
    "\n",
    "aum_m1 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/aum_train/aum_m7.csv'), \n",
    "    \"aum_m1\"\n",
    ")\n",
    "aum_m2 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/aum_train/aum_m8.csv'), \n",
    "    \"aum_m2\"\n",
    ")\n",
    "aum_m3 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/aum_train/aum_m9.csv'), \n",
    "    \"aum_m3\"\n",
    ")\n",
    "##########\n",
    "aum_m = pd.merge(\n",
    "    aum_m1, aum_m2, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "\n",
    "aum_m = pd.merge(\n",
    "    aum_m, aum_m3, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "################\n",
    "# aum_m = changeColName_id(aum_m, \"aum_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior_m3_B6\n"
     ]
    }
   ],
   "source": [
    "## 这些东西，大多数也是数值类型的\n",
    "## 每个季度的第一个月，第二个月，没有behavior_m(Y)数据，那就删掉这两个列。\n",
    "\n",
    "behavior_m1 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/behavior_train/behavior_m7.csv'), \n",
    "    \"behavior_m1\"\n",
    ")\n",
    "behavior_m2 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/behavior_train/behavior_m8.csv'), \n",
    "    \"behavior_m2\"\n",
    ")\n",
    "behavior_m3 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/behavior_train/behavior_m9.csv'), \n",
    "    \"behavior_m3\"\n",
    ")\n",
    "##########\n",
    "behavior_m = pd.merge(\n",
    "    behavior_m1, behavior_m2, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "\n",
    "behavior_m = pd.merge(\n",
    "    behavior_m, behavior_m3, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "################ [\"behavior_m3_B6\"]\n",
    "transformTheDateToDaysFrom20000101(behavior_m3, [\"behavior_m3_B6\"])\n",
    "\n",
    "# behavior_m3.head()\n",
    "##################\n",
    "# behavior_m = changeColName_id(behavior_m, \"behavior_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_event_E1\n",
      "big_event_E2\n",
      "big_event_E3\n",
      "big_event_E4\n",
      "big_event_E5\n",
      "big_event_E6\n",
      "big_event_E7\n",
      "big_event_E8\n",
      "big_event_E9\n",
      "big_event_E10\n",
      "big_event_E12\n",
      "big_event_E13\n",
      "big_event_E14\n",
      "big_event_E16\n",
      "big_event_E18\n"
     ]
    }
   ],
   "source": [
    "## 这些东西，大多数也是数值类型的\n",
    "## 每个季度的第一个月，第二个月，没有behavior_m(Y)数据，那就删掉这两个列。\n",
    "\n",
    "big_event = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/big_event_train/big_event_Q3.csv'),\n",
    "    \"big_event\",\n",
    ")\n",
    "\n",
    "## 这边删掉了E11这个列。注意。别的表不见得这个列都是空值。\n",
    "### 时间列：[col for col in big_event.columns if (col not in [\"cust_no\", \"E11\"] and \"E11\" not in col and \"E15\" not in col and \"E17\" not in col)]\n",
    "transformTheDateToDaysFrom20000101(\n",
    "    big_event, \n",
    "    [col for col in big_event.columns if (col not in [\"cust_no\", \"E11\"] and \"E11\" not in col and \"E15\" not in col and \"E17\" not in col)]\n",
    ")\n",
    "##############\n",
    "# big_event = changeColName_id(big_event, \"big_event\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cunkuan_m1 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/cunkuan_train/cunkuan_m7.csv'), \n",
    "    \"cunkuan_m1\"\n",
    ")\n",
    "cunkuan_m2 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/cunkuan_train/cunkuan_m8.csv'), \n",
    "    \"cunkuan_m2\"\n",
    ")\n",
    "cunkuan_m3 = changeColName(\n",
    "    pd.read_csv('originalDataset/x_train/cunkuan_train/cunkuan_m9.csv'), \n",
    "    \"cunkuan_m3\"\n",
    ")\n",
    "##########\n",
    "cunkuan_m = pd.merge(\n",
    "    cunkuan_m1, cunkuan_m2, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "\n",
    "cunkuan_m = pd.merge(\n",
    "    cunkuan_m, cunkuan_m3, \n",
    "    how='outer',on='cust_no'\n",
    ")\n",
    "############\n",
    "# cunkuan_m = changeColName_id(cunkuan_m, \"cunkuan_m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cust_info_qX`, 这个表里面有大量的分类信息，必须要同时结合训练集和测试集一起处理才行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cust info, 还是需要结合test测试集。\n",
    "cust_info_q3 = pd.read_csv('originalDataset/x_train/cust_info_q3.csv')\n",
    "cust_info_q4 = pd.read_csv('originalDataset/x_train/cust_info_q4.csv')\n",
    "cust_info_q1 = pd.read_csv('originalDataset/x_test/cust_info_q1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_fea = list(cust_info_q3.select_dtypes(exclude=['object']).columns)\n",
    "object_fea = list(filter(lambda x: x not in numerical_fea,list(cust_info_q3.columns)))\n",
    "object_fea.remove(\"cust_no\")\n",
    "object_fea.remove(\"I3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "def mapTheValue(data, fea, dic):\n",
    "    \"\"\"\n",
    "    data_train is the dataset. \n",
    "    fea is the target feature. \n",
    "    dic is the mapping dictionary. \n",
    "    \"\"\"\n",
    "    data[fea] = data[fea].apply(lambda x: dic.get(x, -1)) \n",
    "\n",
    "\n",
    "## 这两个特征，是暗含了顺序\n",
    "for dt in [cust_info_q3]: \n",
    "    mapTheValue(\n",
    "        dt, \"I3\", {\n",
    "            \"普通客户\": 0, \n",
    "            \"黄金\": 1,\n",
    "            \"白金\": 2,\n",
    "            \"钻石\": 3,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "for col in tqdm.tqdm(object_fea): \n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(cust_info_q3[col].astype(str).values) + list(cust_info_q4[col].astype(str).values) + list(cust_info_q1[col].astype(str).values))\n",
    "    cust_info_q3[col] = le.transform(list(cust_info_q3[col].astype(str).values))\n",
    "    \n",
    "###################\n",
    "# cust_info_q4 = changeColName_id(cust_info_q4, \"cust_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Featuretools to merge tables and generate new features\n",
    "\n",
    "利用featuretools来组合诸多表格。这些表格中，以cust_info为最顶层的数据表。\n",
    "\n",
    "跑这些东西耗时太长，最好只跑一次，结果存本地就行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing aum_m sum...\n",
      "Built 44 features\n",
      "Elapsed: 00:12 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m max...\n",
      "Built 44 features\n",
      "Elapsed: 00:13 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m mode...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m min...\n",
      "Built 44 features\n",
      "Elapsed: 00:13 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m count...\n",
      "Built 21 features\n",
      "Elapsed: 00:08 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m num_unique...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m mean...\n",
      "Built 44 features\n",
      "Elapsed: 00:13 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m percent_true...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m std...\n",
      "Built 44 features\n",
      "Elapsed: 00:11 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing aum_m skew...\n",
      "Built 44 features\n",
      "Elapsed: 20:56 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m sum...\n",
      "Built 36 features\n",
      "Elapsed: 00:09 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m max...\n",
      "Built 36 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m mode...\n",
      "Built 24 features\n",
      "Elapsed: 07:13 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m min...\n",
      "Built 36 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m count...\n",
      "Built 21 features\n",
      "Elapsed: 00:08 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m num_unique...\n",
      "Built 24 features\n",
      "Elapsed: 04:16 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m mean...\n",
      "Built 36 features\n",
      "Elapsed: 00:09 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m percent_true...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m std...\n",
      "Built 36 features\n",
      "Elapsed: 00:09 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing behavior_m skew...\n",
      "Built 36 features\n",
      "Elapsed: 13:52 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m sum...\n",
      "Built 26 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m max...\n",
      "Built 26 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m mode...\n",
      "Built 20 features\n",
      "Elapsed: 00:05 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m min...\n",
      "Built 26 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m count...\n",
      "Built 21 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m num_unique...\n",
      "Built 20 features\n",
      "Elapsed: 00:05 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m mean...\n",
      "Built 26 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m percent_true...\n",
      "Built 20 features\n",
      "Elapsed: 00:05 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m std...\n",
      "Built 26 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing cunkuan_m skew...\n",
      "Built 26 features\n",
      "Elapsed: 02:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event sum...\n",
      "Built 38 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event max...\n",
      "Built 38 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event mode...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event min...\n",
      "Built 38 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event count...\n",
      "Built 21 features\n",
      "Elapsed: 00:07 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event num_unique...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event mean...\n",
      "Built 38 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event percent_true...\n",
      "Built 20 features\n",
      "Elapsed: 00:06 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event std...\n",
      "Built 38 features\n",
      "Elapsed: 00:10 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n",
      "Doing big_event skew...\n",
      "Built 38 features\n",
      "Elapsed: 16:01 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "def generateFeaturesWithFeaturetools(\n",
    "    entity_id_core, dataframe_core, index_core, \n",
    "    etyIds, dfs, dfIndexs, \n",
    "):\n",
    "    '''\n",
    "    一些教程：https://www.jiqizhixin.com/articles/2018-06-21-2\n",
    "    ft.dfs()的文档：https://featuretools.alteryx.com/en/stable/generated/featuretools.dfs.html?highlight=dfs\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(\"preprocessedData/featuretools-agg-q3-scheme1\"):\n",
    "        os.makedirs(\"preprocessedData/featuretools-agg-q3-scheme1\")\n",
    "        \n",
    "    for etyId, df, dfIndex in zip(etyIds, dfs, dfIndexs):\n",
    "        ## 创建两个表格。其中第一个表是以cust_info_qx来创建，我们便要以此为据，来为每一个用户创建新特征。\n",
    "        es = ft.EntitySet(id = 'cust')\n",
    "        ### 注意这里哦，xxx_q4\n",
    "        es = es.entity_from_dataframe(entity_id = entity_id_core, dataframe = dataframe_core, \n",
    "                                  index = index_core)\n",
    "        es = es.entity_from_dataframe(entity_id = etyId, dataframe = df, \n",
    "                                  make_index = True, ## 如果是第一次跑这个代码框，那就要跑这一行，因为这一行会给dataframe增加一列，所以运行过一次再运行，是会报错的。\n",
    "                                  index = dfIndex)\n",
    "        ## 增加表之间的关系\n",
    "        es = es.add_relationship(\n",
    "            ft.Relationship(\n",
    "                es['cust_info']['cust_no'],\n",
    "                es[etyId]['cust_no']\n",
    "            )\n",
    "        )\n",
    "        ## 最后计算新特征. 注意，这里的agg所有的取值，已经是ft.dfs函数支持的所有了。\n",
    "        for agg in [\"sum\", \"max\", \"mode\", \"min\", \"count\", \"num_unique\", \"mean\", \"percent_true\", \"std\", \"skew\", ]: #\n",
    "            print(f\"Doing {etyId} {agg}...\")\n",
    "            features, feature_names = ft.dfs(\n",
    "                entityset = es, \n",
    "                target_entity = 'cust_info', \n",
    "                agg_primitives = [agg],\n",
    "                verbose=1, \n",
    "                max_depth = 2, \n",
    "            )\n",
    "            ## 命名的关键信息：etyId, agg\n",
    "            features = features.reset_index()\n",
    "            features.to_csv(f\"preprocessedData/featuretools-agg-q3-scheme1/{etyId}-{agg}.csv\", index=False)\n",
    "            \n",
    "generateFeaturesWithFeaturetools(\n",
    "    \"cust_info\", cust_info_q3, \"cust_no\", \n",
    "    [\"aum_m\", \"behavior_m\", \"cunkuan_m\", \"big_event\", ], # \n",
    "    [aum_m, behavior_m, cunkuan_m, big_event, ], #\n",
    "    [\"aum_id\", \"behavior_id\", \"cunkuan_id\", \"bigEvent_id\", ], # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为`entity_from_dataframe`有`time_index`这个参数，所以之前做的时间类型的转换，可以酌情不用做了。\n",
    "\n",
    "https://featuretools.alteryx.com/en/stable/generated/featuretools.EntitySet.entity_from_dataframe.html?highlight=entity_from_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine the features generated by `featuretools`\n",
    "\n",
    "这部分代码，本notebook不需要用，但是留在这边做备份。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessedData/aum_m-sum.csv 1\n",
      "preprocessedData/aum_m-max.csv 2\n",
      "preprocessedData/aum_m-mode.csv 3\n",
      "preprocessedData/aum_m-min.csv 4\n",
      "preprocessedData/aum_m-count.csv 5\n",
      "preprocessedData/aum_m-num_unique.csv 6\n",
      "preprocessedData/aum_m-mean.csv 7\n",
      "preprocessedData/aum_m-percent_true.csv 8\n",
      "preprocessedData/aum_m-std.csv 9\n",
      "preprocessedData/aum_m-skew.csv 10\n",
      "preprocessedData/behavior_m-sum.csv 11\n",
      "preprocessedData/behavior_m-max.csv 12\n",
      "preprocessedData/behavior_m-mode.csv 13\n",
      "preprocessedData/behavior_m-min.csv 14\n",
      "preprocessedData/behavior_m-count.csv 15\n",
      "preprocessedData/behavior_m-num_unique.csv 16\n",
      "preprocessedData/behavior_m-mean.csv 17\n",
      "preprocessedData/behavior_m-percent_true.csv 18\n",
      "preprocessedData/behavior_m-std.csv 19\n",
      "preprocessedData/behavior_m-skew.csv 20\n",
      "preprocessedData/cunkuan_m-sum.csv 21\n",
      "preprocessedData/cunkuan_m-max.csv 22\n",
      "preprocessedData/cunkuan_m-mode.csv 23\n",
      "preprocessedData/cunkuan_m-min.csv 24\n",
      "preprocessedData/cunkuan_m-count.csv 25\n",
      "preprocessedData/cunkuan_m-num_unique.csv 26\n",
      "preprocessedData/cunkuan_m-mean.csv 27\n",
      "preprocessedData/cunkuan_m-percent_true.csv 28\n",
      "preprocessedData/cunkuan_m-std.csv 29\n",
      "preprocessedData/cunkuan_m-skew.csv 30\n",
      "preprocessedData/big_event-sum.csv 31\n",
      "preprocessedData/big_event-max.csv 32\n",
      "preprocessedData/big_event-mode.csv 33\n",
      "preprocessedData/big_event-min.csv 34\n",
      "preprocessedData/big_event-count.csv 35\n",
      "preprocessedData/big_event-num_unique.csv 36\n",
      "preprocessedData/big_event-mean.csv 37\n",
      "preprocessedData/big_event-percent_true.csv 38\n",
      "preprocessedData/big_event-std.csv 39\n",
      "preprocessedData/big_event-skew.csv 40\n",
      "(543823, 396)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "newFeatures = pd.DataFrame()\n",
    "for etyId in [\"aum_m\", \"behavior_m\", \"cunkuan_m\", \"big_event\", ]:\n",
    "    for agg in [\"sum\", \"max\", \"mode\", \"min\", \"count\", \"num_unique\", \"mean\", \"percent_true\", \"std\", \"skew\", ]: \n",
    "        counter += 1\n",
    "        print(f\"preprocessedData/{etyId}-{agg}.csv\", counter)\n",
    "        features = pd.read_csv(f\"preprocessedData/{etyId}-{agg}.csv\")\n",
    "        ## 把原始的Ixx列都删掉，然后和原列整合\n",
    "        features.drop(\n",
    "            [col for col in features.columns if re.search(\"^I\\d+$\", col) != None] + [\"cust_no\"], \n",
    "            axis = 1, \n",
    "            inplace=True\n",
    "        )\n",
    "        newFeatures = pd.concat([newFeatures, features], axis=1)\n",
    "print(newFeatures.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "d8wxvCVFmZ-_",
    "kmVWMMJwyzUO",
    "6JyBck_410PY",
    "8ffAB5HC14Pf"
   ],
   "machine_shape": "hm",
   "name": "3.1-FE-KeepTheFeaturesAsTheyOriginallyWere.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
