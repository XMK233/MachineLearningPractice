{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VTGKBzAtohn"
   },
   "source": [
    "# Release Notes\n",
    "\n",
    "上一个版本：3.0-FE-Original, 3.6-xxx\n",
    "\n",
    "两个季度的合并起来训练。没见的效果有更好。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "_SRLl5araf_d"
   },
   "source": [
    "# Setting working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15114,
     "status": "ok",
     "timestamp": 1607146985845,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "uYrTyv-UafC6",
    "outputId": "5a9c7d95-98dd-462f-97aa-e6325ab49f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1607146987282,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "ZyoMIfsAbiNI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/XiamenIntlBank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XBqtONK5azWB"
   },
   "source": [
    "Go to this place for original dataset: \n",
    "\n",
    "`'/content/drive/My Drive/Colab Notebooks/MachineLearningPractice/FinanceRiskControl/originalDataset'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0B7KKhqBIlS9"
   },
   "outputs": [],
   "source": [
    "## 安装catboost和lightgbm。\n",
    "## catboost耗费显存极大，但是飞快；lightgbm好像不是那么的方便，gpu使用不起来。\n",
    "!pip install catboost\n",
    "# !pip uninstall lightgbm\n",
    "# !pip install lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drotXWXNMFL-"
   },
   "source": [
    "# Importing libraries and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11437,
     "status": "ok",
     "timestamp": 1607147017175,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "4in9DfMTbPnR",
    "outputId": "690b91eb-352e-470f-f43d-fea934ced2c3"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1607151175126,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "NY-oAIAAIggg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, cohen_kappa_score\n",
    "# import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import tensorflow as tf\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wABHFDoycf1A"
   },
   "source": [
    "# Starting feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5ypM1_uBK2O"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2375,
     "status": "ok",
     "timestamp": 1607147025822,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "Msb6jagB6IWh"
   },
   "outputs": [],
   "source": [
    "data_train_3 = pd.read_csv('preprocessedData/quarter3_merged-validLabels.csv')\n",
    "data_train_4 = pd.read_csv('preprocessedData/quarter4_merged-validLabels.csv')\n",
    "\n",
    "data_test_a = pd.read_csv('preprocessedData/quarter1_merged-validUsers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([data_train_3, data_train_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145296, 87)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECJ8Nv3Ya7cl"
   },
   "source": [
    "## Delete the cols that have too many null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1607147032171,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "-Zz8L28xa7cl",
    "outputId": "4283a7c6-7659-437f-cd34-d93080da55d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nan可视化\n",
    "def seeWhichColumnsHaveMissingValues(data_train): \n",
    "    missing = data_train.isnull().sum()/len(data_train)\n",
    "    missing = missing[missing > 0]\n",
    "    missing.sort_values(inplace=True)\n",
    "#     print((missing))\n",
    "    missing.plot.bar()\n",
    "seeWhichColumnsHaveMissingValues(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1607147035433,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "8VhX_Z3Qa7cl",
    "outputId": "af8dae3d-aac3-4c58-c779-b98f450c3ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big_event_E5', 'big_event_E18', 'big_event_E16', 'big_event_E4', 'big_event_E14', 'big_event_E12', 'big_event_E8', 'big_event_E13', 'cust_info_I10', 'cust_info_I14', 'big_event_E7', 'cust_info_I13', 'big_event_E9', 'big_event_E11', 'cust_info_I9']\n"
     ]
    }
   ],
   "source": [
    "def seeWhichColumnsHaveMissingValuesMoreThanAThreshold(data_train, threshold): \n",
    "    missing = data_train.isnull().sum()/len(data_train)\n",
    "    missing = missing[missing > threshold]\n",
    "    missing.sort_values(inplace=True)\n",
    "    return list(missing.index)\n",
    "colsThatHaveTooManyNull = seeWhichColumnsHaveMissingValuesMoreThanAThreshold(data_train, 0.15)\n",
    "print(colsThatHaveTooManyNull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjzseA7qa7cm"
   },
   "source": [
    "上述的列，空值太多(多于15%)，有可能会影响结果，故先放弃。\n",
    "\n",
    "注意，如果你训练集这样搞了，那么你测试集就得删掉一样的列，不论测试集相应的列有多少空值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1607147036275,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "mdqkqn_La7cm",
    "outputId": "a61fceca-74fb-45ba-abd5-e6bd594e9c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1607147036599,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "lwOLCOT4a7cm",
    "outputId": "73792810-a720-4c07-c256-511a58f34067"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test_a.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1607147037413,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "6MtdaJRla7cm"
   },
   "outputs": [],
   "source": [
    "data_train = data_train.drop(colsThatHaveTooManyNull, axis=1)\n",
    "data_test_a = data_test_a.drop(colsThatHaveTooManyNull, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhXbv16eCFHv"
   },
   "source": [
    "## Classify the features into multiple groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1607147038416,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "zA9BsyNKa7cm"
   },
   "outputs": [],
   "source": [
    "id_col = [\"cust_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1607147038741,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "QvUtj12XEuHp"
   },
   "outputs": [],
   "source": [
    "numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "object_fea = list(filter(lambda x: x not in numerical_fea,list(data_train.columns)))\n",
    "label = 'label'\n",
    "numerical_fea.remove(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1607147039473,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "VH6YmDxdF_pI",
    "outputId": "6e098188-3452-48af-863b-19f63b9788b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aum_m1_X1', 'aum_m1_X2', 'aum_m1_X3', 'aum_m1_X4', 'aum_m1_X5', 'aum_m1_X6', 'aum_m1_X7', 'aum_m1_X8', 'aum_m2_X1', 'aum_m2_X2', 'aum_m2_X3', 'aum_m2_X4', 'aum_m2_X5', 'aum_m2_X6', 'aum_m2_X7', 'aum_m2_X8', 'aum_m3_X1', 'aum_m3_X2', 'aum_m3_X3', 'aum_m3_X4', 'aum_m3_X5', 'aum_m3_X6', 'aum_m3_X7', 'aum_m3_X8', 'behavior_m1_B1', 'behavior_m1_B2', 'behavior_m1_B3', 'behavior_m1_B4', 'behavior_m1_B5', 'behavior_m2_B1', 'behavior_m2_B2', 'behavior_m2_B3', 'behavior_m2_B4', 'behavior_m2_B5', 'behavior_m3_B1', 'behavior_m3_B2', 'behavior_m3_B3', 'behavior_m3_B4', 'behavior_m3_B5', 'behavior_m3_B7', 'big_event_E15', 'big_event_E17', 'cunkuan_m1_C1', 'cunkuan_m1_C2', 'cunkuan_m2_C1', 'cunkuan_m2_C2', 'cunkuan_m3_C1', 'cunkuan_m3_C2', 'cust_info_I2', 'cust_info_I11']\n",
      "['cust_info_I4', 'cust_info_I6', 'cust_info_I7', 'cust_info_I15', 'cust_info_I16', 'cust_info_I17', 'cust_info_I18', 'cust_info_I19', 'cust_info_I20']\n"
     ]
    }
   ],
   "source": [
    "## 过滤类别较少的和较多的列\n",
    "def get_numerical_serial_fea(data,feas):\n",
    "    numerical_serial_fea = []\n",
    "    numerical_noserial_fea = []\n",
    "    for fea in feas:\n",
    "        temp = data[fea].nunique()\n",
    "        if temp <= 10:\n",
    "            numerical_noserial_fea.append(fea)\n",
    "            continue\n",
    "        numerical_serial_fea.append(fea)\n",
    "    return numerical_serial_fea,numerical_noserial_fea\n",
    "    \n",
    "numerical_serial_fea,numerical_categorical_fea = get_numerical_serial_fea(data_train,numerical_fea)\n",
    "print(numerical_serial_fea)\n",
    "print(numerical_categorical_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nawA3zUra7cm"
   },
   "source": [
    "`big_event_E11, cust_info_I7, cust_info_I9` from numerical_categorical_fea, 类别太少，没有意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1607147042177,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "Or7Y6Ntya7cm"
   },
   "outputs": [],
   "source": [
    "# numerical_categorical_fea.remove(\"big_event_E11\")\n",
    "numerical_categorical_fea.remove(\"cust_info_I7\")\n",
    "# numerical_categorical_fea.remove(\"cust_info_I9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1607147042656,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "-YkLtZeZa7cm"
   },
   "outputs": [],
   "source": [
    "data_train.drop([\"cust_info_I7\"], axis = 1, inplace=True)\n",
    "data_test_a.drop([\"cust_info_I7\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFaueF-Ba7cm"
   },
   "source": [
    "找日期：所有在`object_fea`里面的`big_event_xx`和`behavior_m3_B6` 是时间类型的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1607147043273,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "NWyeNyhZa7cm",
    "outputId": "aa9cb069-3f2c-472d-f29c-4d985a604c07",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['behavior_m3_B6', 'big_event_E1', 'big_event_E2', 'big_event_E3', 'big_event_E6', 'big_event_E10']\n"
     ]
    }
   ],
   "source": [
    "date_fea = []\n",
    "for fea in object_fea:\n",
    "    if \"big_event\" in fea or \"behavior\" in fea:\n",
    "        date_fea.append(fea)\n",
    "print(date_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na5lB3NAa7cm"
   },
   "source": [
    "找其他类型的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1607147043943,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "u36NxvVSa7cm",
    "outputId": "bad49d47-b77a-494b-f528-e8ca940ec238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cust_info_I1', 'cust_info_I3', 'cust_info_I5', 'cust_info_I8', 'cust_info_I12']\n"
     ]
    }
   ],
   "source": [
    "object_categorical_fea = []\n",
    "for fea in object_fea:\n",
    "    if fea not in date_fea and fea not in id_col:\n",
    "        object_categorical_fea.append(fea)\n",
    "print(object_categorical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1607147045620,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "zi2xeIifC820"
   },
   "outputs": [],
   "source": [
    "total_list = sorted(list(data_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1607147045770,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "5enpq5neCJpQ",
    "outputId": "fee4085f-80a4-43d8-a044-75394fc9cedf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cust_no']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1607147046095,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "pf_9yAUia7cm",
    "outputId": "f80222df-5b1a-4768-b6b8-881752cb540c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aum_m1_X1', 'aum_m1_X2', 'aum_m1_X3', 'aum_m1_X4', 'aum_m1_X5', 'aum_m1_X6', 'aum_m1_X7', 'aum_m1_X8', 'aum_m2_X1', 'aum_m2_X2', 'aum_m2_X3', 'aum_m2_X4', 'aum_m2_X5', 'aum_m2_X6', 'aum_m2_X7', 'aum_m2_X8', 'aum_m3_X1', 'aum_m3_X2', 'aum_m3_X3', 'aum_m3_X4', 'aum_m3_X5', 'aum_m3_X6', 'aum_m3_X7', 'aum_m3_X8', 'behavior_m1_B1', 'behavior_m1_B2', 'behavior_m1_B3', 'behavior_m1_B4', 'behavior_m1_B5', 'behavior_m2_B1', 'behavior_m2_B2', 'behavior_m2_B3', 'behavior_m2_B4', 'behavior_m2_B5', 'behavior_m3_B1', 'behavior_m3_B2', 'behavior_m3_B3', 'behavior_m3_B4', 'behavior_m3_B5', 'behavior_m3_B7', 'big_event_E15', 'big_event_E17', 'cunkuan_m1_C1', 'cunkuan_m1_C2', 'cunkuan_m2_C1', 'cunkuan_m2_C2', 'cunkuan_m3_C1', 'cunkuan_m3_C2', 'cust_info_I2', 'cust_info_I11']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_serial_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1607147046552,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "-UuHCU1ya7cm",
    "outputId": "4b625ac5-ca10-4d3c-fb34-25e59fa9a516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cust_info_I4', 'cust_info_I6', 'cust_info_I15', 'cust_info_I16', 'cust_info_I17', 'cust_info_I18', 'cust_info_I19', 'cust_info_I20']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_categorical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1607147048327,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "JDy3s7Ina7cm",
    "outputId": "5af3a8ab-0e15-4cbe-8cff-d78fcf3d9225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['behavior_m3_B6', 'big_event_E1', 'big_event_E2', 'big_event_E3', 'big_event_E6', 'big_event_E10']\n"
     ]
    }
   ],
   "source": [
    "print(date_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1607147048461,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "1Rwkdvpqa7cm",
    "outputId": "b4a3cf97-8dd8-42e3-a978-577caa3c222f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cust_info_I1', 'cust_info_I3', 'cust_info_I5', 'cust_info_I8', 'cust_info_I12']\n"
     ]
    }
   ],
   "source": [
    "print(object_categorical_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwWr4ZjDa7cn"
   },
   "source": [
    "`object_categorical_fea` 还能继续分，有的是有等级的，有的没有等级（这些没有等级的，可以考虑进行那个啥，onehot）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RhCLznRa7cn"
   },
   "source": [
    "下面的代码用来检查有没有特征被漏掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1607147049685,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "YrnDkESDa7cn"
   },
   "outputs": [],
   "source": [
    "new_cates = numerical_categorical_fea + numerical_serial_fea + date_fea + object_categorical_fea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1607147049975,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "oBca0b_yHHLd",
    "outputId": "0047f1dd-4071-4eee-8e4f-fa149ad7fe0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_no', 'label'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(total_list) - set(new_cates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebrsHJ6Qa7cn"
   },
   "source": [
    "如果空留label、ID，则无特征被遗漏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1607147052265,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "kBCSWqv0MEFg"
   },
   "outputs": [],
   "source": [
    "# data_train = data_train.head(200)\n",
    "# data_test_a = data_test_a.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO9voAt2Iggz"
   },
   "source": [
    "## Fill the null. \n",
    "\n",
    "**Mind this**: Some other filling schemes can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EvOutC_iIggu"
   },
   "outputs": [],
   "source": [
    "# data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9GIs4Eq1SSba"
   },
   "outputs": [],
   "source": [
    "# data_train[\"n14\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CsuIy3wdmzYf"
   },
   "outputs": [],
   "source": [
    "## Change the infinite number into NaN. \n",
    "# data_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# data_test_a.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Rx4kv6DPYZ2"
   },
   "source": [
    "Lagrange interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LwAHEKltOuq0"
   },
   "outputs": [],
   "source": [
    "# 创建函数，做插值，以空值前后5个数据（共10个数据）为例做插值  \n",
    "from scipy.interpolate import lagrange  \n",
    "\n",
    "## https://www.programmersought.com/article/37145216331/\n",
    "def fillNanWithLagr(col,nv=-1,k=3):\n",
    "    # col \"fill column vector\", nv \"empty value, default -1\", k \"Lagrangian interval, default 3\"\n",
    "    # Get the null position\n",
    "    if nv is np.nan:\n",
    "        tar = col[col.isnull()].index.tolist()\n",
    "    else:\n",
    "        tar = col[col==nv].index.tolist()\n",
    "\n",
    "    for idx in tqdm.tqdm(tar, position=0, leave=True):\n",
    "      ## you can also use tqdm.tqdm_notebook(). The graphic info is more beautiful. \n",
    "    # for idx in tqdm.tqdm(tar):\n",
    "                # Get Lagrange interval\n",
    "                # The empty value position is removed here, because the filled empty value cannot be used to calculate other empty values\n",
    "        # print(idx, end=\"\")\n",
    "        rel = col.iloc[\n",
    "            list(\n",
    "                set(list(range(idx-k,idx))+list(range(idx+1,idx+k+1))).difference(set(tar))\n",
    "            )\n",
    "        ]\n",
    "                # Keep a reasonable range\n",
    "        rel = rel[rel>=0][rel<len(col)]\n",
    "                # Fill in Lagrangian mean\n",
    "        # lagrange(arg1,arg2)(arg3)\n",
    "                # arg1 \"Iterable object index\", arg2 \"Iterable object conversion table\", arg3 \"Fill position\"\n",
    "        col.iloc[idx] = lagrange(rel.index,list(rel))(idx)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "weDgNR7tPWEE"
   },
   "outputs": [],
   "source": [
    "# # data_train_cp = data_train.copy()\n",
    "# # data_test_a_cp = data_test_a.copy()\n",
    "\n",
    "# for i, data in enumerate([data_train, data_test_a]):\n",
    "#     print(\"in the {} dataset:\".format(i + 1))\n",
    "#     for fea in numerical_fea:\n",
    "#         if fea == \"id\":\n",
    "#             continue\n",
    "#         print(fea)\n",
    "#         data[fea] = fillNanWithLagr(data[fea], np.nan, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NqES9O8GgpU0"
   },
   "outputs": [],
   "source": [
    "# data_train.to_csv(\"preprocessedData/lagrangeInterpolated_train.csv\", index=False)\n",
    "# data_test_a.to_csv(\"preprocessedData/lagrangeInterpolated_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnSLGKvwPc4p"
   },
   "source": [
    "Median interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3blBa4yKIgg0"
   },
   "outputs": [],
   "source": [
    "# #按照平均数填充数值型特征\n",
    "# data_train[numerical_fea] = data_train[numerical_fea].fillna(data_train[numerical_fea].median())\n",
    "# data_test_a[numerical_fea] = data_test_a[numerical_fea].fillna(data_train[numerical_fea].median())\n",
    "# #按照众数填充类别型特征\n",
    "# data_train[category_fea] = data_train[category_fea].fillna(data_train[category_fea].mode())\n",
    "# data_test_a[category_fea] = data_test_a[category_fea].fillna(data_train[category_fea].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlIexCxBYMVu"
   },
   "source": [
    "`employmentLength` cannot be filled by `mode()`. I don't know why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4jqp71z-YFSH"
   },
   "outputs": [],
   "source": [
    "# data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AiVUxLIvdX7C"
   },
   "outputs": [],
   "source": [
    "# data_train = data_train.fillna(axis = 0, method = \"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJssSa3cgFhL"
   },
   "source": [
    "No filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kC0dLEzDgILa"
   },
   "outputs": [],
   "source": [
    "## No filling of any null value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnyS0rikLLN5"
   },
   "source": [
    "## Change `object_categorical_fea` \n",
    "\n",
    "这里面也有一些类是可以进行序列化的，比如`cust_info_I3`用户的等级, `cust_info_I10`学历, `cust_info_I14`官阶，这几个都可以序列化。\n",
    "\n",
    "鉴于这个notebook只做最原生态的处理，所以就将之简单归类了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1607147057880,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "TD8EAAp2a7cn",
    "outputId": "6762e44c-10fb-4b27-83d4-9886884f821f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cust_info_I1',\n",
       " 'cust_info_I3',\n",
       " 'cust_info_I5',\n",
       " 'cust_info_I8',\n",
       " 'cust_info_I12']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_categorical_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnVmsgwThfpD"
   },
   "source": [
    "### Scheme A\n",
    "\n",
    "对他们进行普通分类，最普通的分类，就是将他们编码为数字。不搞dummy操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1607147060799,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "IjU1Ryfsa7cn"
   },
   "outputs": [],
   "source": [
    "def mapTheValue(data, fea, dic):\n",
    "    \"\"\"\n",
    "    data_train is the dataset. \n",
    "    fea is the target feature. \n",
    "    dic is the mapping dictionary. \n",
    "    \"\"\"\n",
    "    data[fea] = data[fea].apply(lambda x: dic.get(x, -1)) \n",
    "\n",
    "\n",
    "## 这几个特征，是暗含了顺序\n",
    "for dt in [data_train, data_test_a]: \n",
    "    #### \n",
    "    mapTheValue(\n",
    "        dt, \"cust_info_I3\", \n",
    "        {s : i + 1 for i, s in enumerate([\"普通客户\", \"黄金\", '白金', '钻石'])}\n",
    "    )\n",
    "    ####\n",
    "#     qte = {s : i + 1 for i, s in enumerate(['文盲或半文盲', '小学教育', '初级中学教育', '技工学校毕业', '中等职业教育', '普通高级中学教育', \n",
    "#                                           '专科教育', '大学本科', '研究生教育'])}\n",
    "#     qte.update({'未知': np.nan})\n",
    "#     mapTheValue(dt, \"cust_info_I10\", {\n",
    "#         \"普通客户\": 0, \n",
    "#         \"黄金\": 1,\n",
    "#         \"白金\": 2,\n",
    "#         \"钻石\": 3,\n",
    "#     })\n",
    "    #### \n",
    "#     qte = {s : i + 1 for i, s in enumerate(['一般员工', \n",
    "#                                           '中级领导(行政级别局级以下处级以上领导或大公司中级管理人员)', \n",
    "#                                           '初级领导(行政级别处级以下领导或大公司初级管理人员)', \n",
    "#                                           '高级领导(行政级别局级及局级以上领导或大公司高级管理人员)'])}\n",
    "#     qte.update({'其他': np.nan})\n",
    "#     mapTheValue(\n",
    "#         dt, \"cust_info_I14\", ## 职务\n",
    "#         qte,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1607147061200,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "lwuXDiYya7cn"
   },
   "outputs": [],
   "source": [
    "# data_test_a[[\"cust_info_I1\", \"cust_info_I3\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1607147061838,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "uIH8cAxJa7cn",
    "outputId": "cfe29fd4-9426-482c-e644-ec62f3b4c5ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "## 要用，就用所有的str来编码。这里算是一个修正吧。\n",
    "cust_info_q3 = pd.read_csv('originalDataset/x_train/cust_info_q3.csv')\n",
    "cust_info_q4 = pd.read_csv('originalDataset/x_train/cust_info_q4.csv')\n",
    "cust_info_q1 = pd.read_csv('originalDataset/x_test/cust_info_q1.csv')\n",
    "\n",
    "for col in tqdm.tqdm(\n",
    "    ## 把尚未编码的cust_info特征进行普通编码\n",
    "    [fea for fea in list(data_train.select_dtypes(['object']).columns) if \"cust_info\" in fea] \n",
    "): \n",
    "    ## 获取最原处的列名，也就是IXX. \n",
    "    originColName = col.split(\"_\")[-1]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(cust_info_q3[originColName].astype(str).values) + list(cust_info_q4[originColName].astype(str).values) + list(cust_info_q1[originColName].astype(str).values))\n",
    "    data_train[col] = le.transform(list(data_train[col].astype(str).values))\n",
    "    data_test_a[col] = le.transform(list(data_test_a[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSIb3612LKyr"
   },
   "source": [
    "## Change `date_fea` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1607147064826,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "MpDWHm3ma7co",
    "outputId": "df8a2304-348a-4c84-a798-c633cd7ce708",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['behavior_m3_B6',\n",
       " 'big_event_E1',\n",
       " 'big_event_E2',\n",
       " 'big_event_E3',\n",
       " 'big_event_E6',\n",
       " 'big_event_E10']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9WKNPVNigiL"
   },
   "source": [
    "### Scheme A\n",
    "\n",
    "最普通，直接将日期改为距离最早日期多少天。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 18733,
     "status": "ok",
     "timestamp": 1607147085036,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "I6OTxb0ta7co"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior_m3_B6\n",
      "big_event_E1\n",
      "big_event_E2\n",
      "big_event_E3\n",
      "big_event_E6\n",
      "big_event_E10\n"
     ]
    }
   ],
   "source": [
    "startdate = datetime.datetime.strptime(\n",
    "    \"2000-01-01 00:00:00\",\n",
    "    '%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "for fea in date_fea:   \n",
    "# [ \"behavior_m3_B6\",  \n",
    "# 'big_event_E1',\n",
    "#  'big_event_E2',\n",
    "#  'big_event_E3',\n",
    "#  'big_event_E6',\n",
    "#  'big_event_E10']\n",
    "    print(fea)\n",
    "    \n",
    "    data_train[fea] = data_train[fea].astype(str)\n",
    "    data_test_a[fea] = data_test_a[fea].astype(str)\n",
    "    \n",
    "    ## 这里改为与某一固定日期（千禧年第一天）的距离。否则，不同的表格，这些列所得到的数据的标准不一，这样会出事情的。\n",
    "    if fea in [\"behavior_m3_B6\"]: ## 这个列有时分秒，不只有日期。\n",
    "        for data in [data_train, data_test_a]:\n",
    "            data[fea] = pd.to_datetime(data[fea],format = '%Y-%m-%d %H:%M:%S')\n",
    "            data[fea] = data[fea].apply(lambda x: x-startdate).dt.days ## 这里或许有潜力可挖，比如，换成秒，分钟啊什么的。\n",
    "    else: ## 这些列，只有日期。\n",
    "        for data in [data_train, data_test_a]:\n",
    "            data[fea] = pd.to_datetime(data[fea],format='%Y-%m-%d')\n",
    "            data[fea] = data[fea].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gLG8fnXLLG9"
   },
   "source": [
    "## Change `numerical_serial_fea` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YItCzkxOiE0b"
   },
   "source": [
    "### Scheme A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于单个月的统计量\n",
    "\n",
    "求平均：某月每一个产品平均存款金额\n",
    "\n",
    "    for i in range(3):\n",
    "        'cunkuan_m{i}_C1', 某月存款产民金额\n",
    "        'cunkuan_m{i}_C2', 某月存款产品个数\n",
    "    \n",
    "求平均：某月，每一次平均转入多少金额\n",
    "    \n",
    "    for i in range(3):\n",
    "        behavior_m{i}_B2 转账转入次数\n",
    "        behavior_m{i}_B3 转账转入金额\n",
    "    \n",
    "求平均：某月，每一次平均转出多少金额\n",
    "\n",
    "    for i in range(3):\n",
    "        'behavior_m{i}_B4', 转账转出次数\n",
    "        'behavior_m{i}_B5', 转账转出金额"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAvgWithinMonth_cunkuan_c12(data_train):\n",
    "#     f'cunkuan_m{i}_C1'#, 某月存款产品金额\n",
    "#     f'cunkuan_m{i}_C2'#, 某月存款产品个数\n",
    "    newCols = []\n",
    "    for i in range(1, 3+1):\n",
    "        data_train[f\"cunkuan_m{i}_C1-C2\"] = data_train[f'cunkuan_m{i}_C1'] / data_train[f'cunkuan_m{i}_C2']\n",
    "        newCols.append(f\"cunkuan_m{i}_C1-C2\")\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = calculateAvgWithinMonth_cunkuan_c12(data_train)\n",
    "newCols_data_test_a = calculateAvgWithinMonth_cunkuan_c12(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAvgWithinMonth_behavior_b32(data_train):\n",
    "#     behavior_m{i}_B2 # 转账转入次数\n",
    "#     behavior_m{i}_B3 # 转账转入金额\n",
    "    newCols = []\n",
    "    for i in range(1, 3+1):\n",
    "        data_train[f\"behavior_m{i}_B3-B2\"] = data_train[f'behavior_m{i}_B3'] / data_train[f'behavior_m{i}_B2']\n",
    "        newCols.append(f\"behavior_m{i}_B3-B2\")\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = calculateAvgWithinMonth_behavior_b32(data_train)\n",
    "newCols_data_test_a = calculateAvgWithinMonth_behavior_b32(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAvgWithinMonth_behavior_b54(data_train):\n",
    "#     behavior_m{i}_B2 # 转账转入次数\n",
    "#     behavior_m{i}_B3 # 转账转入金额\n",
    "    newCols = []\n",
    "    for i in range(1, 3+1):\n",
    "        data_train[f\"behavior_m{i}_B5-B4\"] = data_train[f'behavior_m{i}_B5'] / data_train[f'behavior_m{i}_B4']\n",
    "        newCols.append(f\"behavior_m{i}_B5-B4\")\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = calculateAvgWithinMonth_behavior_b54(data_train)\n",
    "newCols_data_test_a = calculateAvgWithinMonth_behavior_b54(data_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于单个的统计量，我们可以计算每一个月的增长率\n",
    "    \n",
    "    for i in range(1, 8+1):\n",
    "        aum_m2_X{i} 相对于 aum_m1_X{i} 增长了多少，\n",
    "        aum_m3_X{i} 相对于 aum_m2_X{i} 增长了多少，\n",
    "        aum_m3_X{i} 相对于 aum_m1_X{i} 增长了多少，\n",
    "        \n",
    "    for i in range(1, 5 + 1): \n",
    "        behavior_m2_B{i} 相对于 behavior_m1_B{i} 增长了多少，\n",
    "        behavior_m3_B{i} 相对于 behavior_m2_B{i} 增长了多少，\n",
    "        behavior_m3_B{i} 相对于 behavior_m1_B{i} 增长了多少，\n",
    "        \n",
    "    for i in range(1, 2 + 1):\n",
    "        cunkuan_m2_C{i} 相对于 cunkuan_m1_C{i} 增长了多少，\n",
    "        cunkuan_m3_C{i} 相对于 cunkuan_m2_C{i} 增长了多少，\n",
    "        cunkuan_m3_C{i} 相对于 cunkuan_m1_C{i} 增长了多少，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incrementalRate_aum_m32_m21(data_train):\n",
    "#     aum_m2_X{i} 相对于 aum_m1_X{i} 增长了多少，\n",
    "#     aum_m3_X{i} 相对于 aum_m2_X{i} 增长了多少，\n",
    "    newCols = []\n",
    "    for i in range(1, 8+1):\n",
    "        data_train[f\"aum_m21_X{i}\"] = (data_train[f\"aum_m2_X{i}\"] - data_train[f\"aum_m1_X{i}\"]) / data_train[f\"aum_m1_X{i}\"]\n",
    "        data_train[f\"aum_m32_X{i}\"] = (data_train[f\"aum_m3_X{i}\"] - data_train[f\"aum_m2_X{i}\"]) / data_train[f\"aum_m2_X{i}\"]\n",
    "        newCols.extend([f\"aum_m21_X{i}\", f\"aum_m32_X{i}\"])\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = incrementalRate_aum_m32_m21(data_train)\n",
    "newCols_data_test_a = incrementalRate_aum_m32_m21(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incrementalRate_behavior_m32_m21(data_train):\n",
    "#     behavior_m2_B{i} 相对于 behavior_m1_B{i} 增长了多少，\n",
    "#     behavior_m3_B{i} 相对于 behavior_m2_B{i} 增长了多少，\n",
    "    newCols = []\n",
    "    for i in range(1, 5 + 1):\n",
    "        data_train[f\"behavior_m21_B{i}\"] = (data_train[f\"behavior_m2_B{i}\"] - data_train[f\"behavior_m1_B{i}\"]) / data_train[f\"behavior_m1_B{i}\"]\n",
    "        data_train[f\"behavior_m32_B{i}\"] = (data_train[f\"behavior_m3_B{i}\"] - data_train[f\"behavior_m2_B{i}\"]) / data_train[f\"behavior_m2_B{i}\"]\n",
    "        newCols.extend([f\"behavior_m21_B{i}\", f\"behavior_m32_B{i}\"])\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = incrementalRate_behavior_m32_m21(data_train)\n",
    "newCols_data_test_a = incrementalRate_behavior_m32_m21(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incrementalRate_cunkuan_m32_m21(data_train):\n",
    "#     cunkuan_m2_C{i} 相对于 cunkuan_m1_C{i} 增长了多少，\n",
    "#     cunkuan_m3_C{i} 相对于 cunkuan_m2_C{i} 增长了多少，\n",
    "    newCols = []\n",
    "    for i in range(1, 2 + 1):\n",
    "        data_train[f\"cunkuan_m21_C{i}\"] = (data_train[f\"cunkuan_m2_C{i}\"] - data_train[f\"cunkuan_m1_C{i}\"]) / data_train[f\"cunkuan_m1_C{i}\"]\n",
    "        data_train[f\"cunkuan_m32_C{i}\"] = (data_train[f\"cunkuan_m3_C{i}\"] - data_train[f\"cunkuan_m2_C{i}\"]) / data_train[f\"cunkuan_m2_C{i}\"]\n",
    "        newCols.extend([f\"cunkuan_m21_C{i}\", f\"cunkuan_m32_C{i}\"])\n",
    "    return newCols\n",
    "\n",
    "newCols_data_train = incrementalRate_cunkuan_m32_m21(data_train)\n",
    "newCols_data_test_a = incrementalRate_cunkuan_m32_m21(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seeWhichColumnsHaveMissingValues(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aum_m21_X4', 'aum_m32_X5', 'aum_m21_X5', 'aum_m32_X6', 'aum_m21_X6', 'aum_m32_X2', 'aum_m21_X2']\n"
     ]
    }
   ],
   "source": [
    "colsThatHaveTooManyNull = seeWhichColumnsHaveMissingValuesMoreThanAThreshold(data_train, 0.90)\n",
    "print(colsThatHaveTooManyNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(colsThatHaveTooManyNull, axis=1)\n",
    "data_test_a = data_test_a.drop(colsThatHaveTooManyNull, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145296, 103)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc7sxLQtK-JT"
   },
   "source": [
    "## Change `numerical_categorical_fea` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOQlCS3plUVI"
   },
   "source": [
    "### Scheme A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_serial = [col for col in data_train.columns if col not in [\"cust_no\", \"label\", \"cust_info_I1\", \"cust_info_I5\", \"cust_info_I8\", \"cust_info_I12\"] + numerical_categorical_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['behavior_m1_B1', 'behavior_m3_B1', 'cunkuan_m21_C2', 'cunkuan_m32_C2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFVCAYAAADmNDgjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5RVdb3/8ecLUMmfGZB5IQUVM5AUQbTS7GYorlT8mgTdTCu7ftct7GY/lvYtjSxb1+xm/qobhql8NTVvKt4sy1BXpSaDQogKDoY5V/OSvwL9Ig6+v3+cPePxeGbmDLNn9uzzeT3WmsU+n/3D93kL8zp7n/1DEYGZmaVnSNEFmJlZMRwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJGlZ0Ab0xcuTIGDt2bNFlmJmVytKlS/8WEaNqx0sVAGPHjqWlpaXoMszMSkXS4/XGfQjIzCxRDgAzs0Q5AMzMElWq7wDqeeWVV2hra2Pjxo1Fl2JdGD58OGPGjGGrrbYquhQzq1L6AGhra2OHHXZg7NixSCq6HKsRETzzzDO0tbUxbty4ossxsyqlPwS0ceNGRowY4V/+g5QkRowY4T00s0Go9AEA+Jf/IOf/P2aDU1MEwGC0/fbbF11CXVdccQVz584FYN68eYwePZr999+fCRMm8NOf/rTH9W+66SYeeuih/i7TzAZA6b8DqDX2zF/kur21//ahXLfXF+3t7Qwblu//stNPP50vfelLPProo0yZMoUTTjih2y9rb7rpJo4++mgmTJiQax32Rnn/Xe4vg+nfiPWO9wBycNxxxzFlyhQmTpzI/PnzO8e/+MUvcsABB3D44Yezbt06AN7//vdzxhlnMG3aNPbee29+97vfAZXvMj75yU8yadIkJk+ezB133AFUPrHPmjWLY445hiOOOII777yTww47jI985CPsvffenHnmmVx99dVMmzaNSZMmsWbNGgBuueUWDjroICZPnswHP/hBnn766W7fw/jx49l222157rnnALjssss48MAD2W+//fjwhz/MSy+9xN13382iRYv48pe/zP7778+aNWtYs2YNM2bMYMqUKRx66KE88sgjuffXzPqHAyAHl19+OUuXLqWlpYWLLrqIZ555hhdffJEDDjiA+++/n8MOO4xvfOMbncu3t7dz33338f3vf79z/NJLLwVgxYoV/PSnP+Xkk0/u/OL0nnvu4corr2Tx4sUALF++nAsvvJAVK1awcOFCVq9ezX333cenP/1pLr74YgAOOeQQ7r33Xh544AHmzJnDd77znW7fw/3338/48eN561vfCsDxxx/PkiVLWL58Oe985ztZsGAB73nPezj22GM5//zzWbZsGXvuuSennnoqF198MUuXLuW73/0un/nMZ/Jtrpn1m6Y7BFSEiy66iBtvvBGAJ554gkcffZQhQ4Ywe/ZsAE488USOP/74zuU7pqdMmcLatWsB+P3vf89pp50GwD777MPuu+/O6tWrAZg+fTpvectbOtc/8MAD2XXXXQHYc889OeKIIwCYNGlS555DW1sbs2fP5qmnnmLTpk1dnoJ5wQUXcNlll/HYY4/xq1/9qnP8wQcf5Gtf+xrPP/88GzZs4Mgjj3zDuhs2bODuu+9m1qxZnWMvv/xyo20zs4J5D6CP7rzzTm6//Xbuueceli9fzuTJk+ue8lh9Jsw222wDwNChQ2lvbwcq58t3Zbvttnvd6471AYYMGdL5esiQIZ3bO+2005g7dy4rVqzgRz/6UZenYZ5++umsWrWK6667jpNOOqlzuU984hNccsklrFixgq9//et113/11Vd585vfzLJlyzp/Hn744S7fh5kNLg6APnrhhRfYeeed2XbbbXnkkUe49957gcovxxtuuAGAa665hkMOOaTb7bzvfe/j6quvBmD16tX85S9/4R3veEef6ho9ejQAV155ZY/LH3/88UydOrVz2fXr17PrrrvyyiuvdNYFsMMOO7B+/XoAdtxxR8aNG8fPfvYzoBJiy5cv3+KazWxgOQD6aMaMGbS3t/Oud72Ls846i4MPPhiofGpfuXIlU6ZMYfHixZx99tndbuczn/kMmzdvZtKkScyePZsrrrjidZ/0e2vevHnMmjWLQw89lJEjRza0ztlnn833vvc9Xn31Vb75zW9y0EEHMX36dPbZZ5/OZebMmcP555/P5MmTWbNmDVdffTULFixgv/32Y+LEidx8881bXLOZDSx1d+hhsJk6dWrUPg/g4Ycf5p3vfGdBFVmj/P+p93waqOVF0tKImFo77j0AM7NEOQDMzBLlADAzS1RTBECZvsdIkf//mA1Opb8QbPjw4TzzzDO+JfQg1fE8gOHDhxddiiXOX6q/UekDYMyYMbS1tXXea8cGn44ngpnZ4FL6ANhqq638pCkzsy3QFN8BmJlZ7zkAzMwS5QAwM0tU6b8D6KsynBngS+3NrD80tAcgaYakVZJaJZ1ZZ/42kq7L5v9R0thsfLqkpZJWZH9+oGqdKdl4q6SL5HM4zcwGVI97AJKGApcC04E2YImkRRFR/WTwU4DnImIvSXOA84DZwN+AYyLiSUn7ArcBo7N1fgicCtwL3ArMAH6Zz9uyIpRhbwq8R2XWoZE9gGlAa0Q8FhGbgGuBmTXLzAQ6bjp/A3C4JEXEAxHxZDa+Ehie7S3sCuwYEfdE5TLRq4Dj+vxuzMysYY0EwGjgiarXbbz2Kf4Ny0REO/ACMKJmmQ8DD0TEy9nybT1s08zM+lEjXwLXOzZfe3OXbpeRNJHKYaEjerHNjnVPpXKoiN12262nWs3MrEGN7AG0AW+vej0GeLKrZSQNA3YCns1ejwFuBE6KiDVVy1ffG6DeNgGIiPkRMTUipo4aNaqBcs3MrBGNBMASYLykcZK2BuYAi2qWWQScnE2fACyOiJD0ZuAXwFci4g8dC0fEU8B6SQdnZ/+cBPhZgmZmA6jHAMiO6c+lcgbPw8D1EbFS0jmSjs0WWwCMkNQKfAHoOFV0LrAXcJakZdnPW7N5/wL8GGgF1uAzgMzMBlRDF4JFxK1UTtWsHju7anojMKvOet8CvtXFNluAfXtTrJmZ5ce3gjAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS1RDASBphqRVklolnVln/jaSrsvm/1HS2Gx8hKQ7JG2QdEnNOndm21yW/bw1jzdkZmaNGdbTApKGApcC04E2YImkRRHxUNVipwDPRcRekuYA5wGzgY3AWcC+2U+tj0VESx/fg5mZbYFG9gCmAa0R8VhEbAKuBWbWLDMTuDKbvgE4XJIi4sWI+D2VIDAzs0GkkQAYDTxR9botG6u7TES0Ay8AIxrY9k+ywz9nSVIDy5uZWU4aCYB6v5hjC5ap9bGImAQcmv18vO5/XDpVUouklnXr1vVYrJmZNaaRAGgD3l71egzwZFfLSBoG7AQ8291GI+K/sz/XA9dQOdRUb7n5ETE1IqaOGjWqgXLNzKwRjQTAEmC8pHGStgbmAItqllkEnJxNnwAsjogu9wAkDZM0MpveCjgaeLC3xZuZ2Zbr8SygiGiXNBe4DRgKXB4RKyWdA7RExCJgAbBQUiuVT/5zOtaXtBbYEdha0nHAEcDjwG3ZL/+hwO3AZbm+MzMz61aPAQAQEbcCt9aMnV01vRGY1cW6Y7vY7JTGSjQzs/7gK4HNzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS1RDASBphqRVklolnVln/jaSrsvm/1HS2Gx8hKQ7JG2QdEnNOlMkrcjWuUiS8nhDZmbWmB4DQNJQ4FLgKGAC8FFJE2oWOwV4LiL2Ai4AzsvGNwJnAV+qs+kfAqcC47OfGVvyBszMbMs0sgcwDWiNiMciYhNwLTCzZpmZwJXZ9A3A4ZIUES9GxO+pBEEnSbsCO0bEPRERwFXAcX15I2Zm1juNBMBo4Imq123ZWN1lIqIdeAEY0cM223rYJgCSTpXUIqll3bp1DZRrZmaNaCQA6h2bjy1YZouWj4j5ETE1IqaOGjWqm02amVlvNBIAbcDbq16PAZ7sahlJw4CdgGd72OaYHrZpZmb9qJEAWAKMlzRO0tbAHGBRzTKLgJOz6ROAxdmx/boi4ilgvaSDs7N/TgJu7nX1Zma2xYb1tEBEtEuaC9wGDAUuj4iVks4BWiJiEbAAWCiplcon/zkd60taC+wIbC3pOOCIiHgI+BfgCuBNwC+zHzMzGyA9BgBARNwK3FozdnbV9EZgVhfrju1ivAXYt9FCzcwsX74S2MwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ4AM7NEOQDMzBLlADAzS5QDwMwsUQ0FgKQZklZJapV0Zp3520i6Lpv/R0ljq+Z9JRtfJenIqvG1klZIWiapJY83Y2ZmjRvW0wKShgKXAtOBNmCJpEUR8VDVYqcAz0XEXpLmAOcBsyVNAOYAE4F/AG6XtHdEbM7W+8eI+FuO78fMzBrUyB7ANKA1Ih6LiE3AtcDMmmVmAldm0zcAh0tSNn5tRLwcEX8GWrPtmZlZwRoJgNHAE1Wv27KxustERDvwAjCih3UD+LWkpZJO7eo/LulUSS2SWtatW9dAuWZm1ohGAkB1xqLBZbpb970RcQBwFPBZSe+r9x+PiPkRMTUipo4aNaqBcs3MrBGNBEAb8Paq12OAJ7taRtIwYCfg2e7WjYiOP/8HuBEfGjIzG1CNBMASYLykcZK2pvKl7qKaZRYBJ2fTJwCLIyKy8TnZWULjgPHAfZK2k7QDgKTtgCOAB/v+dszMrFE9ngUUEe2S5gK3AUOByyNipaRzgJaIWAQsABZKaqXyyX9Otu5KSdcDDwHtwGcjYrOkXYAbK98TMwy4JiJ+1Q/vz8zMutBjAABExK3ArTVjZ1dNbwRmdbHuucC5NWOPAfv1tlgzM8uPrwQ2M0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0tUQwEgaYakVZJaJZ1ZZ/42kq7L5v9R0tiqeV/JxldJOrLRbZqZWf/qMQAkDQUuBY4CJgAflTShZrFTgOciYi/gAuC8bN0JwBxgIjAD+IGkoQ1u08zM+lEjewDTgNaIeCwiNgHXAjNrlpkJXJlN3wAcLknZ+LUR8XJE/BlozbbXyDbNzKwfDWtgmdHAE1Wv24CDulomItolvQCMyMbvrVl3dDbd0zYBkHQqcGr2coOkVQ3UXLSRwN/y2pjOy2tLpZRrL8H9xP3MU1n6uXu9wUYCQHXGosFluhqvt+dRu83KYMR8YH53BQ42kloiYmrRdTQD9zJf7me+yt7PRg4BtQFvr3o9Bniyq2UkDQN2Ap7tZt1GtmlmZv2okQBYAoyXNE7S1lS+1F1Us8wi4ORs+gRgcURENj4nO0toHDAeuK/BbZqZWT/q8RBQdkx/LnAbMBS4PCJWSjoHaImIRcACYKGkViqf/Odk666UdD3wENAOfDYiNgPU22b+b68wpTpkNci5l/lyP/NV6n6q8kHdzMxS4yuBzcwS5QAwM0uUA8DMLFEOADOzRDkA+pGk7YuuwdIm6UhJp1TfoDEb/1QxFZWbpH0kHV77b1vSjKJq6gsHQP96qOgCmomkFUXXUCaSvg18FZgE/FbSaVWz5xZTVXlJ+hxwM3Aa8KCk6vuXfbuYqvqmkVtBWDckfaGrWYD3AHpJ0vFdzQLeNpC1NIFjgMnZtTzzgGsk7RERp1P/Ni3WvX8GpkTEhmyP6gZJYyPiQkraTwdA330bOJ/KhW61vIfVe9cBV1P/3lDDB7iWshsWEe0AEfG8pGOA+ZJ+BmxdbGmlNDQiNgBExFpJ76cSArvjAEjW/cBNEbG0doakTxdQT9n9CfhuRDxYO0PSBwuop8zWSDosIu4CyK7CP0XSt4APF1taKf1V0v4RsQwg2xM4GricymG20vGVwH0k6R3AsxGxrs68XSLi6QLKKi1JhwKPR8Rf6sybGhEtBZRVSpLeBEREbKwzb3RE/HcBZZWWpDHAK/X+TUt6b0T8oYCy+sQBYNakskew7hARN9SMfwz4n4j4TTGVlZOkA4GREfHLmvFjgCfrHQUY7HyMuo8kjZT0dUmfk7S9pB9KelDSzZL2Krq+spE0XNLJko5VxRmS/kvShZJGFl1fyXwDuKvO+G+Bcwa4lmZwPvBwnfGHs3ml4wDou2uAbXjtVtePUbkl9n8BPy6wrrK6CjgC+BRwJ7AbcAmwHriisKrKadt6hyYj4q/AdgXUU3YjImJt7WBEtFJ5AmLp+EvgvtslIv5P9gzkxyOi45PAI5I+W2RhJTUhIvbNHizUFhGHZeO/krS8yMJKaLikzjOBOkjaCnhTQTWVWXc9K2Wgeg+g7zZD5Zs23vhs0FcHvpzS2wSV51DwxqfEbR74ckrt58Blkjp/OWXT/5HNs965XdK52Ye9TpK+ASwuqKY+8R5A3+0haRGV84A7pslejyuurNIaI+kiKv3rmCZ7Pbq4skrpa8C3gMclPZ6N7UblAU5nFVZVeX2RymHdVknLsrH9gBaglKd8+yygPpJ0WHfzO87BtsZIOrm7+RFx5UDV0iyy00E7TkhojYj/VzN/us8IapykPYCJ2cuVEfFYzfyJZXnCoQNggEj6z4jwxTc5kXRxRJzW85LWE0n3R8QBRdfRLMrUT38HMHD2KLqAJvPeogtoIqW8jcEgVpp+OgAGjne1bLDy3818laafDgAzs0Q5AAZOaXYLS8L9zM/aogtoMpuKLqBRDoCBc0bRBTSZC4suoMwkTe+YjoiunsFgdWQX0tWOdd6mJCIOHtiKtpwDoB9J6rxpVET8ushaykLS27L7KV0qaYSkeZJWSLpe0q4dy0XEFQWW2QwWFF1A2Uj6R0ltwJOSfl3zmM1S/vv2hWB9JKmr070E7D+QtTSJK4BfULm0/g4qD4f5EDCTyhWsM7tc016n6qLEN8yipPeuKdh3gCMjYqWkE4DfSPp4RNxLSQ9J+jqAPpK0mcodF+v9BTg4InzPlV6Q9EBETM6m/xIRu1XNWxYRDtUGSXoOOBHYUDsLuC4idhn4qspL0vKI2K/q9UQqt9Q4EzirLOf+V/MeQN89DPzviHi0doakJwqop+yqD0te1c0869m9wEv1rkaXtKqAesruFUlvy+6mSrYncDiVO//uWWxpW8YB0Hfz6PoXk69U7b2bJW0fERsi4msdg9mzFVYXWFfpRMRR3cx730DW0iTOBHYB/toxEBFt2bOBS3nnXx8CMjNLlPcAciLpzcBJwFiq+hoRnyuqpjJzP/tO0tupPKlqNPBL4PyIeCWbd1NEHFdkfWUjaR/gAiq3ef8clTuqHkdlz/TkiKj3tLBBzQGQn1upHHNdgZ8DkAf3s+8uB/6TSh9PAe6SdExEPAPsXmhl5TSfSqBuT+X+/2cAnwSOpvLUusOLK23L+BBQTsp0B8AycD/7rvasKUknAl8BjgV+5v72Ts0Zaq0RsVfVvFL+ffUeQH4WSvpnKmcEvNwxGBHPFldSqbmffbeVpOERsREgIv6vpL8Ct1HSRxgWbGjV9Pdq5m09kIXkxafV5WcTld3De4Cl2U9LoRWVm/vZdz8GDqoeiIjbgVnAg4VUVG6XStoeICJ+0DGYnaF2e2FV9YEPAeVE0hrgoIiofS6wbQH306z/+RBQflYCLxVdRBNxP3MiaRyVa1LG8vozqo4tqqYya6Z+OgDysxlYJukOXn/M2qctbhn3Mz83Ubn52y34jKo8NE0/HQD5uSn7sXy4n/nZGBEXFV1EE2mafvo7gAHih8Lny/1snKR/AsZTuWVx9d7U/YUVVWLN1E/vAQwcPxQ+X+5n4yYBHwc+wGuHLCJ7bb3XNP10AAwc72rly/1s3P8C9oiI0jyqcJBrmn76OgCz5rcceHPRRTSRpumn9wAGTimfGDSIuZ+N2wV4RNISXn/MunSnLQ4STdNPB0AOJA0FroyIE7tZzA+Fb5D7mbuvF11Ak2mafvosoJxIug04phmOCw4G7ufAkXRPRLy76DqaRZn66T2A/KwF/pA9iPvFjsGIqL1plDVmLe7nQBledAFNpjT9dADk58nsZwiwQ8G1NAP3c+D4MEC+StNPHwLKmaQdgIiIDUXX0gzcz/5X1nvZD1Zl6qdPA82JpH0lPUDlNrsrJS2VNLHousrK/RxQPqMqX6XppwMgP/OBL0TE7hGxO/BF4LKCayoz93PgfLzoAppMafrpAMjPdhFxR8eLiLgTP3WpL9zPnEg6XtKjkl6Q9HdJ6yX9vWN+RPjhML3QTP30dwA5kXQjcD+wMBs6EZgaEccVV1V5uZ/5kdRK5ZTah4uupRk0Uz+9B5CfTwGjgJ8DN2bTnyy0onJzP/PzdDP8shpEmqaf3gMwa3KSLgTeRuX5CtW3Lvh5YUWVWDP109cB9JGk70fE5yXdQp3zf8t4f5AiuZ/9Ykcqj9c8omosqOxdWe81TT+9B9BHkqZExFJJh9WbHxF3DXRNZeZ+mg0c7wH0UUQszSbfAtwaES93t7x1z/3Mn6ThwCnARKpuUxARnyqsqBJrpn76S+D8HAuslrRQ0ockOVz7xv3Mz0Iqx6yPBO4CxgDrC62o3Jqmnz4ElCNJWwFHAbOBQ4DfRMSni62qvNzPfEh6ICImS/pTRLwr6+ttEVG6RxgOBs3UT3+qylFEvCLpl1S+EHoTMBPwL6wt5H7m5pXsz+cl7Qv8FRhbXDml1zT99CGgnEiaIekKoBU4AfgxsGuhRZWY+5mr+ZJ2Bs4CFgEPAd8ptqRSa5p++hBQTiRdC1wL/NJfXPad+2nW/xwAZk1O0tn1xiPinIGupRk0Uz99CCgnkg6WtETSBkmbJG2uvkGU9Y77masXq342U/lifWyRBZVc0/TTewA5kdQCzAF+BkwFTgL2ioivFlpYSbmf/UfSNsCiiDiy6FqaQZn76bOAchQRrZKGRsRm4CeS7i66pjJzP/vNtsAeRRfRRErbTwdAfl6StDWwTNJ3gKfw/ev7wv3MiaQVvHZfpaFU7qz6zeIqKrdm6qcPAeVE0u7A08DWwOnATsAPIqK10MJKyv3MT9bLDu1UbmfcXlQ9ZddM/XQAmDU5SadExIKasX+LiDOLqqnMmqmfPgSUE0nvBeYBu1PV14go5bHBormfuTpB0saIuBpA0g+AbQquqcyapp/eA8iJpEeoHKpYSuXUMAAi4pnCiiox9zM/kt5E5YrVy6mcsvhsRHy+2KrKq5n66QDIiaQ/RsRBRdfRLNzPvpP0lqqXO1B5gtUfgLMBIuLZIuoqq2bspwOgjyQdkE1+hMoZAT/n9Y+Ju7+IusrK/cyPpD9TOVtFVX92CB9O651m7KcDoI8k3dHN7CjjLWKL5H6aDRwHgFkCJL2Hyu0Kqr9Qv6qwgkquWfrps4ByImkX4NvAP0TEUZImAO+uPV3MGuN+5kfSQmBPYBmvfaEeQOl+YQ0GzdRP7wHkJHtwyU+Ar0bEftkjDB+IiEkFl1ZK7md+JD0MTAj/Y89FM/XTdwPNz8iIuB54FSC7MnBz96tYN9zP/DxI5Rm2lo+m6acPAeXnRUkjyO4RIulg4IViSyo19zM/I4GHJN3H68+oOra4kkqtafrpAMjPF6hcHLKHpD9QuUHUCcWWVGruZ37mFV1Ak5lXdAF5cQDk5yHgRuAlYD2Vi0RWF1pRubmfOYmIu4quoZk0Uz/9JXBOJF0P/B24Ohv6KLBzRMwqrqrycj/zI2k9r92+eGtgK+DFiNixuKrKq5n66T2A/LwjIvaren2HpOWFVVN+7mdOImKH6teSjgOmFVRO6TVTP30WUH4eyL6oBEDSQVTuE2Jbxv3sJxFxE+ArqnNS5n56D6CPqp4OtBVwkqS/ZK93p3Ic23rB/cyfpOOrXg6h8oxlH/vdQs3UTwdA3x1ddAFNxv3M3zFV0+3AWqB0pywOIk3TTwdAH0XE40XX0Ezcz34xBPjXiHgeQNLOwL8Dnyq0qvJqmn76OwCz5veujl9WABHxHDC5wHrKrmn66QAwa35Dsk+pQOeDTbz3v+Wapp+lLNrMeuXfgbsl3UDly8qPAOcWW1KpNU0/fSGYWQKy22l/gMpTrH4bET6jqg+apZ8OADOzRPk7ADOzRDkAzMwS5QAwa5CkeZK+VHQdZnlxAJiZJcoBYMmTdJKkP0laLmmhpN0l/TYb+62k3eqsc6ekqdn0SElrs+lPSLpJ0i2S/ixprqQvSHpA0r3ZOeMd658n6T5JqyUdOqBv2gwHgCVO0kTgq8AHsttP/ytwCXBVRLyLyvMILurlZvcF/pI0ioMAAAD7SURBVInKLYLPBV6KiMnAPcBJVcsNi4hpwOeBr/fpjZhtAQeApe4DwA0R8TeAiHgWeDdwTTZ/IXBIL7d5R0Ssj4h1VJ5jfEs2vgIYW7Xcz7M/l9aMmw0IB4ClTvR8K99689t57d/P8Jp5L1dNv1r1+lVef/V9x/hmfFW+FcABYKn7LfARSSOg874udwNzsvkfA35fZ721wJRs2g+rt1Lypw5LWkSslHQucJekzcADwOeAyyV9GVgHfLLOqt8Frpf0cWDxgBVsliPfCsLMLFE+BGRmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXq/wOCVzp5kFAZ9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_outliers_by_3segama(data,fea):\n",
    "    data_std = np.std(data[fea])\n",
    "    data_mean = np.mean(data[fea])\n",
    "    outliers_cut_off = data_std * 3\n",
    "    lower_rule = data_mean - outliers_cut_off\n",
    "    upper_rule = data_mean + outliers_cut_off\n",
    "    data[fea+'_outliers'] = data[fea].apply(lambda x:str('异常值') if x > upper_rule or x < lower_rule else '正常值')\n",
    "    return data\n",
    "\n",
    "data_train_cp = data_train.copy()\n",
    "feaList = []\n",
    "numList = []\n",
    "for fea in numerical_serial:\n",
    "    # if fea in ['homeOwnership', 'verificationStatus', \"applicationType\", \"initialListStatus\", \"policyCode\"]:\n",
    "    #     continue\n",
    "    data_train_cp = find_outliers_by_3segama(data_train_cp,fea)\n",
    "    valCount = data_train_cp[fea+'_outliers'].value_counts()\n",
    "    abnormalRate = 1-valCount[\"正常值\"] / len(data_train_cp)\n",
    "    if abnormalRate > 0.02:\n",
    "        feaList.append(fea)\n",
    "        numList.append(abnormalRate)\n",
    "        # print(valCount, \"\\n\") ## 获得正常值和异常值的数量\n",
    "        # print(1-valCount[\"正常值\"] / len(data_train_cp), \"\\n\") ## 获得正常值和异常值的数量\n",
    "        # print(data_train_cp.groupby(fea+'_outliers')['isDefault'].sum(), \"\\n\") ## 获得异常值和正常值里面有多少个正例\n",
    "        # print('*'*100)\n",
    "        \n",
    "tmpPd = pd.DataFrame({\n",
    "    \"column\": feaList, \n",
    "    \"abnormalRate\": numList,\n",
    "})\n",
    "tmpPd.set_index([\"column\"], inplace=True)\n",
    "tmpPd.plot(kind='bar')\n",
    "feaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi3(arr):\n",
    "    '''\n",
    "    计算卡方值\n",
    "    arr:频数统计表,二维numpy数组。\n",
    "    '''\n",
    "    assert(arr.ndim==2)\n",
    "    #计算每行总频数\n",
    "    R_N = arr.sum(axis=1)\n",
    "    #每列总频数\n",
    "    C_N = arr.sum(axis=0)\n",
    "    #总频数\n",
    "    N = arr.sum()\n",
    "    # 计算期望频数 C_i * R_j / N。\n",
    "    E = np.ones(arr.shape)* C_N / N\n",
    "    E = (E.T * R_N).T\n",
    "    square = (arr-E)**2 / E\n",
    "    #期望频数为0时，做除数没有意义，不计入卡方值\n",
    "    square[E==0] = 0\n",
    "    #卡方值\n",
    "    v = square.sum()\n",
    "    return v\n",
    "\n",
    "def chiMerge(df,col,target,max_groups=None,threshold=None):\n",
    "\n",
    "    '''\n",
    "    卡方分箱\n",
    "    df: pandas dataframe数据集\n",
    "    col: 需要分箱的变量名（数值型）\n",
    "    target: 类标签\n",
    "    max_groups: 最大分组数。\n",
    "    threshold: 卡方阈值，如果未指定max_groups，默认使用置信度95%设置threshold。\n",
    "    return: 包括各组的起始值的列表.\n",
    "    '''\n",
    "\n",
    "    freq_tab = pd.crosstab(df[col],df[target])\n",
    "\n",
    "    #转成numpy数组用于计算。\n",
    "    freq = freq_tab.values\n",
    "\n",
    "    #初始分组切分点，每个变量值都是切分点。每组中只包含一个变量值.\n",
    "\n",
    "    #分组区间是左闭右开的，如cutoffs = [1,2,3]，则表示区间 [1,2) , [2,3) ,[3,3+)。\n",
    "    cutoffs = freq_tab.index.values\n",
    "\n",
    "    #如果没有指定最大分组\n",
    "    if max_groups is None:    \n",
    "        #如果没有指定卡方阈值，就以95%的置信度（自由度为类数目-1）设定阈值。\n",
    "        if threshold is None:\n",
    "            #类数目\n",
    "            cls_num = freq.shape[-1]\n",
    "            threshold = chi2.isf(0.05,df= cls_num - 1)\n",
    "\n",
    "    while True:\n",
    "        minvalue = None\n",
    "        minidx = None\n",
    "        #从第1组开始，依次取两组计算卡方值，并判断是否小于当前最小的卡方\n",
    "        for i in range(len(freq) - 1):\n",
    "            v = chi3(freq[i:i+2])\n",
    "            if minvalue is None or (minvalue > v): #小于当前最小卡方，更新最小值\n",
    "                minvalue = v\n",
    "                minidx = i\n",
    "\n",
    "        #如果最小卡方值小于阈值，则合并最小卡方值的相邻两组，并继续循环\n",
    "        if  (max_groups is not None and  max_groups< len(freq) ) or (threshold is not None and minvalue < threshold):\n",
    "            #minidx后一行合并到minidx\n",
    "            tmp  = freq[minidx] + freq[minidx+1]\n",
    "            freq[minidx] = tmp\n",
    "            #删除minidx后一行\n",
    "            freq = np.delete(freq,minidx+1,0)\n",
    "            #删除对应的切分点\n",
    "            cutoffs = np.delete(cutoffs,minidx+1,0)\n",
    "\n",
    "        else: #最小卡方值不小于阈值，停止合并。\n",
    "            break\n",
    "    return cutoffs\n",
    "\n",
    "def value2group(x,cutoffs):\n",
    "\n",
    "    '''\n",
    "    将变量的值转换成相应的组。\n",
    "    x: 需要转换到分组的值\n",
    "    cutoffs: 各组的起始值。\n",
    "    return: x对应的组，如group1。从group1开始。\n",
    "    '''\n",
    "\n",
    "    #切分点从小到大排序。\n",
    "    cutoffs = sorted(cutoffs)\n",
    "    num_groups = len(cutoffs)\n",
    "\n",
    "    #异常情况：小于第一组的起始值。这里直接放到第一组。\n",
    "    #异常值建议在分组之前先处理妥善。\n",
    "    if x < cutoffs[0]:\n",
    "        return 1 #'group1'\n",
    "\n",
    "    for i in range(1,num_groups):\n",
    "        if cutoffs[i-1] <= x < cutoffs[i]:\n",
    "            return i # 'group{}'.format(i)\n",
    "\n",
    "    #最后一组，也可能会包括一些非常大的异常值。\n",
    "    return num_groups #'group{}'.format(num_groups)\n",
    "\n",
    "def calWOE(df ,var ,target):\n",
    "\n",
    "    '''\n",
    "    计算WOE编码\n",
    "    param df：数据集pandas.dataframe\n",
    "    param var：已分组的列名，无缺失值\n",
    "    param target：响应变量（0,1）\n",
    "    return：编码字典\n",
    "    '''\n",
    "    eps = 0.000001  #避免除以0\n",
    "    gbi = pd.crosstab(df[var],df[target]) + eps\n",
    "    gb = df[target].value_counts() + eps\n",
    "    gbri = gbi/gb\n",
    "    gbri['woe'] = np.log(gbri[1]/gbri[0])\n",
    "    return gbri['woe'].to_dict()\n",
    "\n",
    "def calIV(df,var,target):\n",
    "\n",
    "    '''\n",
    "    计算IV值\n",
    "    param df：数据集pandas.dataframe\n",
    "    param var：已分组的列名，无缺失值\n",
    "    param target：响应变量（0,1）\n",
    "    return：IV值\n",
    "    '''\n",
    "    eps = 0.000001  #避免除以0\n",
    "    gbi = pd.crosstab(df[var],df[target]) + eps\n",
    "    gb = df[target].value_counts() + eps\n",
    "    gbri = gbi/gb\n",
    "    gbri['woe'] = np.log(gbri[1]/gbri[0])\n",
    "    gbri['iv'] = (gbri[1] - gbri[0])*gbri['woe']\n",
    "    return gbri['iv'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "for fea in tqdm.tqdm(feaList): ## [\"n0\", \"n6\", \"delinquency_2years\"]\n",
    "    try:\n",
    "        cutoffs = chiMerge(data_train, fea, 'label', max_groups=10)\n",
    "        data_train[fea] = data_train[fea].apply(value2group,args=(cutoffs,))\n",
    "        data_test_a[fea] = data_test_a[fea].apply(value2group,args=(cutoffs,))\n",
    "#         print(f\"{fea} is successful.\".format(fea))\n",
    "    except:\n",
    "        print(f\"{fea} is failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145296, 103)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 11602,
     "status": "ok",
     "timestamp": 1607147085041,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "mFhuSEel_GjL"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "#     seeWhichColumnsHaveMissingValues(data_train)\n",
    "    colsThatHaveTooManyNull = seeWhichColumnsHaveMissingValuesMoreThanAThreshold(data_train, 0.90)\n",
    "    if len(colsThatHaveTooManyNull):\n",
    "        print(colsThatHaveTooManyNull)\n",
    "        data_train = data_train.drop(colsThatHaveTooManyNull, axis=1)\n",
    "        data_test_a = data_test_a.drop(colsThatHaveTooManyNull, axis=1)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0yALhIla_ym"
   },
   "source": [
    "## Feature Generation\n",
    "\n",
    "利用 https://zhuanlan.zhihu.com/p/26444240 介绍的方法开展特征合成：\n",
    "\n",
    "```\n",
    "median(N1)_by(C1)  \\\\ 中位数\n",
    "mean(N1)_by(C1)  \\\\ 算术平均数\n",
    "mode(N1)_by(C1)  \\\\ 众数\n",
    "min(N1)_by(C1)  \\\\ 最小值\n",
    "max(N1)_by(C1)  \\\\ 最大值\n",
    "std(N1)_by(C1)  \\\\ 标准差\n",
    "var(N1)_by(C1)  \\\\ 方差\n",
    "freq(C2)_by(C1)  \\\\ 频数\n",
    "\n",
    "freq(C1) \\\\这个不需要groupby也有意义\n",
    "```\n",
    "\n",
    "上述只是一种思路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Ah5J0w-12BaF"
   },
   "outputs": [],
   "source": [
    "# data_train.to_csv(\"preprocessedData/data_train-1129-a_a_a_b_b_a_x_x.csv\", index=False)\n",
    "# data_test_a.to_csv(\"preprocessedData/data_test_a-1129-a_a_a_b_b_a_x_x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "OwVpGhO32BaF"
   },
   "outputs": [],
   "source": [
    "# data_train = pd.read_csv(\"preprocessedData/data_train-1129-a_a_a_b_b_a_x_x.csv\")\n",
    "# data_test_a = pd.read_csv(\"preprocessedData/data_test_a-1129-a_a_a_b_b_a_x_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "V_tlOvOdOKSo"
   },
   "outputs": [],
   "source": [
    "# ####\n",
    "# ## 这个适用于A-F。\n",
    "# ##\n",
    "# ####\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from scipy.stats import pearsonr\n",
    "# #选择K个最好的特征，返回选择特征后的数据\n",
    "# #第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，\n",
    "# #输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数\n",
    "# #参数k为选择的特征个数\n",
    "\n",
    "# def selectNFeatures(numSelectedFeatures, data_train, y_train, fillMethod = \"ffill\"):\n",
    "#     ## 到时候，就指着返回下面两个表了\n",
    "#     selectedFeatures = []\n",
    "#     deletedFeatures = []\n",
    "\n",
    "#     ## 无脑处理：将所有的正负无穷都处理掉。\n",
    "#     data_train = data_train.replace([np.inf, -np.inf], np.nan)\n",
    "#     ## 填充方法\n",
    "#     if fillMethod in [\"ffill\", \"bfill\"]:\n",
    "#         data_train = data_train.fillna(axis = 1, method = fillMethod) # \"ffill\"\n",
    "#     else: \n",
    "#         data_train = data_train.fillna(data_train.median())  \n",
    "\n",
    "#     ## columnsThatHaveNullVal 这些列，终究是有空值的，那就放弃他们吧。\n",
    "#     tmpList = data_train.isnull().sum().to_frame('nulls')\n",
    "#     columnsThatHaveNullVal = list(tmpList[tmpList[\"nulls\"] > 0].index)\n",
    "#     deletedFeatures.extend(columnsThatHaveNullVal)\n",
    "#     data_train.drop(columnsThatHaveNullVal, axis = 1, inplace=True)\n",
    "\n",
    "#     # print(data_train.isnull().sum())\n",
    "#     # print()\n",
    "#     # print(y_train.isnull().sum())\n",
    "#     # print(data_train.head(20))\n",
    "#     # print(np.any(np.isnan(data_train)))\n",
    "\n",
    "#     selector = SelectKBest(k=numSelectedFeatures)\n",
    "#     selector.fit(data_train, y_train)\n",
    "#     colNums = selector.get_support(True)\n",
    "#     # print(colNums)\n",
    "#     for i, col in enumerate(list(data_train.columns)):\n",
    "#         if i in colNums:\n",
    "#             selectedFeatures.append(col)\n",
    "#         # else: \n",
    "#         #     deletedFeatures.append(col)\n",
    "#     # print(selectedFeatures, deletedFeatures)\n",
    "            \n",
    "#     return selectedFeatures , deletedFeatures\n",
    "\n",
    "# def combinationOfFeatures(category, serial, method, method_name, data_train, data_test_a, n):\n",
    "#     '''\n",
    "#     combine and generate some new features. \n",
    "\n",
    "#     category: list of the categorical column names\n",
    "#     serial: list of the serial column names\n",
    "#     method: [\"mean\"], [\"max\"], [\"min\"], pd.Series.model, etc..\n",
    "#     method_name: the name of the method. Must be strings. \n",
    "#     n: newly generated features, select n from them. if n == -1, then select all of the newly generated features. \n",
    "#     '''\n",
    "#     # ori_cols_train = list(data_train.columns)\n",
    "#     # ori_cols_test = list(data_test_a.columns)\n",
    "\n",
    "#     new_cols = []\n",
    "    \n",
    "#     for col in category: \n",
    "#         for numFea in serial: #half_serials + [\"isDefault\"]: # for numFea in [\"isDefault\"]: \n",
    "#             # print(\"categorical: {}, serial: {}\".format(col, numFea))\n",
    "#             temp_dict = data_train.groupby([col])[numFea].agg(method).reset_index().rename(columns={method_name: col + '_{}_{}'.format(numFea, method_name)})\n",
    "#             temp_dict.index = temp_dict[col].values\n",
    "#             temp_dict = temp_dict[col + '_{}_{}'.format(numFea, method_name)].to_dict()\n",
    "            \n",
    "#             data_train[col + '_{}_{}'.format(numFea, method_name)] = data_train[col].map(temp_dict)\n",
    "#             data_test_a[col + '_{}_{}'.format(numFea, method_name)] = data_test_a[col].map(temp_dict)\n",
    "            \n",
    "#             new_cols.append(col + '_{}_{}'.format(numFea, method_name))\n",
    "    \n",
    "#     if n >= 0: \n",
    "#         tmp_train = data_train[new_cols].copy()\n",
    "\n",
    "#         selectedFeatures, deletedFeatures = selectNFeatures(n, tmp_train, data_train[[\"isDefault\"]]) #\n",
    "\n",
    "#         data_train.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "#         data_test_a.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "#         # data_train = data_train[ori_cols_train + selectedFeatures]\n",
    "#         # data_test_a = data_test_a[ori_cols_test + selectedFeatures]\n",
    "\n",
    "#     elif n < 0:\n",
    "#         pass\n",
    "\n",
    "#     return data_train, data_test_a\n",
    "\n",
    "# def combinationOfFeatures_divide(feaGroup1, feaGroup2, method, df, df_test, n):\n",
    "#     ori_cols_train = list(df.columns)\n",
    "#     ori_cols_test = list(df_test.columns)\n",
    "\n",
    "#     new_cols = []\n",
    "\n",
    "#     for fea1 in feaGroup1: ## grade\n",
    "#         for fea2 in feaGroup2: ## nXX\n",
    "            \n",
    "#             df['{}_to_{}_'.format(fea1, method) + fea2] = df[fea1] / df.groupby([fea2])[fea1].transform(method)\n",
    "#             df_test['{}_to_{}_'.format(fea1, method) + fea2] = df_test[fea1] / df_test.groupby([fea2])[fea1].transform(method)\n",
    "            \n",
    "#             new_cols.append('{}_to_{}_'.format(fea1, method) + fea2)\n",
    "#     # print(new_cols)\n",
    "    \n",
    "#     if n >= 0:\n",
    "#         tmp_train = df[new_cols].copy()\n",
    "        \n",
    "#         selectedFeatures , deletedFeatures = selectNFeatures(n, tmp_train, df[[\"isDefault\"]], \"median\") # \n",
    "#         # print(data_train.columns)\n",
    "#         # print(data_train.)\n",
    "#         # print(selectedFeatures)\n",
    "        \n",
    "#         df.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "#         df_test.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "#         # df = df[ori_cols_train + selectedFeatures]\n",
    "#         # df_test = df_test[ori_cols_test + selectedFeatures]\n",
    "    \n",
    "#     elif n < 0:\n",
    "#         pass\n",
    "\n",
    "#     return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "eJl1k0dEuxyk"
   },
   "outputs": [],
   "source": [
    "####\n",
    "## 这个适用于F2及以后。\n",
    "##\n",
    "####\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import pearsonr\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "#第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，\n",
    "#输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数\n",
    "#参数k为选择的特征个数\n",
    "\n",
    "def selectNFeatures(numSelectedFeatures, data_train, y_train, fillMethod = \"ffill\"):\n",
    "    ## 到时候，就指着返回下面两个表了\n",
    "    selectedFeatures = []\n",
    "    # deletedFeatures = []\n",
    "\n",
    "    ## 无脑处理：将所有的正负无穷都处理掉。\n",
    "    data_train = data_train.replace([np.inf, -np.inf], np.nan)\n",
    "    ## 填充方法\n",
    "    if fillMethod in [\"ffill\", \"bfill\"]:\n",
    "        data_train = data_train.fillna(axis = 1, method = fillMethod) # \"ffill\"\n",
    "    else: \n",
    "        data_train = data_train.fillna(data_train.median())  \n",
    "\n",
    "    ## columnsThatHaveNullVal 这些列，终究是有空值的，那就放弃他们吧。\n",
    "    tmpList = data_train.isnull().sum().to_frame('nulls')\n",
    "    columnsThatHaveNullVal = list(tmpList[tmpList[\"nulls\"] > 0].index)\n",
    "    # deletedFeatures.extend(columnsThatHaveNullVal)\n",
    "    data_train.drop(columnsThatHaveNullVal, axis = 1, inplace=True)\n",
    "\n",
    "    # print(data_train.isnull().sum())\n",
    "    # print()\n",
    "    # print(y_train.isnull().sum())\n",
    "    # print(data_train.head(20))\n",
    "    # print(np.any(np.isnan(data_train)))\n",
    "\n",
    "    selector = SelectKBest(k=numSelectedFeatures)\n",
    "    selector.fit(data_train, y_train)\n",
    "    colNums = selector.get_support(True)\n",
    "    # print(colNums)\n",
    "    for i, col in enumerate(list(data_train.columns)):\n",
    "        if i in colNums:\n",
    "            selectedFeatures.append(col)\n",
    "        # else: \n",
    "        #     deletedFeatures.append(col)\n",
    "    # print(selectedFeatures, deletedFeatures)\n",
    "            \n",
    "    return selectedFeatures #, deletedFeatures\n",
    "\n",
    "def combinationOfFeatures(category, serial, method, method_name, data_train, data_test_a, n):\n",
    "    '''\n",
    "    combine and generate some new features. \n",
    "\n",
    "    category: list of the categorical column names\n",
    "    serial: list of the serial column names\n",
    "    method: [\"mean\"], [\"max\"], [\"min\"], pd.Series.model, etc..\n",
    "    method_name: the name of the method. Must be strings. \n",
    "    n: newly generated features, select n from them. if n == -1, then select all of the newly generated features. \n",
    "    '''\n",
    "    ori_cols_train = list(data_train.columns)\n",
    "    ori_cols_test = list(data_test_a.columns)\n",
    "\n",
    "    new_cols = []\n",
    "    \n",
    "    for col in category: \n",
    "        for numFea in serial: #half_serials + [\"isDefault\"]: # for numFea in [\"isDefault\"]: \n",
    "            # print(\"categorical: {}, serial: {}\".format(col, numFea))\n",
    "            temp_dict = data_train.groupby([col])[numFea].agg(method).reset_index().rename(columns={method_name: col + '_{}_{}'.format(numFea, method_name)})\n",
    "            temp_dict.index = temp_dict[col].values\n",
    "            temp_dict = temp_dict[col + '_{}_{}'.format(numFea, method_name)].to_dict()\n",
    "            \n",
    "            data_train[col + '_{}_{}'.format(numFea, method_name)] = data_train[col].map(temp_dict)\n",
    "            data_test_a[col + '_{}_{}'.format(numFea, method_name)] = data_test_a[col].map(temp_dict)\n",
    "            \n",
    "            new_cols.append(col + '_{}_{}'.format(numFea, method_name))\n",
    "    \n",
    "    if n >= 0: \n",
    "        tmp_train = data_train[new_cols].copy()\n",
    "\n",
    "        selectedFeatures = selectNFeatures(n, tmp_train, data_train[[\"isDefault\"]]) #, deletedFeatures\n",
    "\n",
    "        # data_train.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "        # data_test_a.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "        data_train = data_train[ori_cols_train + selectedFeatures]\n",
    "        data_test_a = data_test_a[ori_cols_test + selectedFeatures]\n",
    "\n",
    "    elif n < 0:\n",
    "        pass\n",
    "\n",
    "    return data_train, data_test_a\n",
    "\n",
    "def combinationOfFeatures_divide(feaGroup1, feaGroup2, method, df, df_test, n):\n",
    "    ori_cols_train = list(df.columns)\n",
    "    ori_cols_test = list(df_test.columns)\n",
    "\n",
    "    new_cols = []\n",
    "\n",
    "    for fea1 in feaGroup1: ## grade\n",
    "        for fea2 in feaGroup2: ## nXX\n",
    "            \n",
    "            df['{}_to_{}_'.format(fea1, method) + fea2] = df[fea1] / df.groupby([fea2])[fea1].transform(method)\n",
    "            df_test['{}_to_{}_'.format(fea1, method) + fea2] = df_test[fea1] / df_test.groupby([fea2])[fea1].transform(method)\n",
    "            \n",
    "            new_cols.append('{}_to_{}_'.format(fea1, method) + fea2)\n",
    "    # print(new_cols)\n",
    "    \n",
    "    if n >= 0:\n",
    "        tmp_train = df[new_cols].copy()\n",
    "        \n",
    "        selectedFeatures = selectNFeatures(n, tmp_train, df[[\"isDefault\"]], \"median\") # , deletedFeatures\n",
    "        # print(data_train.columns)\n",
    "        # print(data_train.)\n",
    "        # print(selectedFeatures)\n",
    "        \n",
    "        # df.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "        # df_test.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "        df = df[ori_cols_train + selectedFeatures]\n",
    "        df_test = df_test[ori_cols_test + selectedFeatures]\n",
    "    \n",
    "    elif n < 0:\n",
    "        pass\n",
    "\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8wxvCVFmZ-_"
   },
   "source": [
    "### Scheme A: \n",
    "\n",
    "Do nothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresNeedToBeRegularized = [col for col in data_train.columns if col not in \n",
    "     ### 除了 [\"cust_info_I3\", \"cust_info_I10\", \"cust_info_I14\"] 以外的所有categorical的特征，不要。\n",
    "    [fea for fea in (numerical_categorical_fea + object_categorical_fea) if fea not in [\"cust_info_I3\", \"cust_info_I10\", \"cust_info_I14\"]] \n",
    "    ### id，label，不要。\n",
    "    + [\"cust_no\", \"label\"] \n",
    "    ### 前面分箱后的特征，不要。\n",
    "    + feaList\n",
    "                               \n",
    "]\n",
    "\n",
    "##[col for col in data_train.columns if col not in [\"cust_no\", \"label\", \"cust_info_I1\", \"cust_info_I5\", \"cust_info_I8\", \"cust_info_I12\"] + numerical_categorical_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[featuresNeedToBeRegularized] = data_train[featuresNeedToBeRegularized].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "data_test_a[featuresNeedToBeRegularized] = data_test_a[featuresNeedToBeRegularized].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145296, 103)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbNJUSRy7AJ2"
   },
   "source": [
    "## Delete the features that will not be used to fit the model\n",
    "\n",
    "No `xx_outliers` features, no labels, no original dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2663,
     "status": "ok",
     "timestamp": 1607147085041,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "B2tFJmQca7co",
    "outputId": "2de1c5cf-01dc-4865-ca5f-e020b00c32da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cust_no', 'aum_m1_X1', 'aum_m1_X2', 'aum_m1_X3', 'aum_m1_X4',\n",
      "       'aum_m1_X5', 'aum_m1_X6', 'aum_m1_X7', 'aum_m1_X8', 'aum_m2_X1',\n",
      "       ...\n",
      "       'behavior_m21_B3', 'behavior_m32_B3', 'behavior_m21_B4',\n",
      "       'behavior_m32_B4', 'behavior_m21_B5', 'behavior_m32_B5',\n",
      "       'cunkuan_m21_C1', 'cunkuan_m32_C1', 'cunkuan_m21_C2', 'cunkuan_m32_C2'],\n",
      "      dtype='object', length=103)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHCBYBI27Eet"
   },
   "source": [
    "### Scheme A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1607149119399,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "ofVFgUvzFqpM"
   },
   "outputs": [],
   "source": [
    "features = [f for f in data_train.columns if f not in [\"cust_no\", \"label\"] and '_outliers' not in f]\n",
    "y_train = data_train['label'].map({-1: 0, 0: 1, 1: 2})\n",
    "x_train = data_train[features]\n",
    "x_test = data_test_a[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1607150349435,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "ZJ0sGAM8bxWn"
   },
   "outputs": [],
   "source": [
    "# x_train = x_train.head(1000)\n",
    "# x_test = x_test.head(1000)\n",
    "# y_train = y_train.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdJf-IVJ75y8"
   },
   "source": [
    "# Save preprocessed data if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1607147089605,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "id": "Bvn4nd9a0AtJ"
   },
   "outputs": [],
   "source": [
    "x_train.to_csv(\"preprocessedData/x_train-3.7.csv\", index=False)\n",
    "x_test.to_csv(\"preprocessedData/x_test-3.7.csv\", index=False)\n",
    "y_train.to_csv(\"preprocessedData/y_train-3.7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "MUvmaksc2jSs"
   },
   "source": [
    "# Load preprocessed data if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1607147090317,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "cyz1hnkb2gxo"
   },
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv(\"preprocessedData/x_train-1129-A_A_A_B_B_A_F_B.csv\")\n",
    "# x_test = pd.read_csv(\"preprocessedData/x_test-1129-A_A_A_B_B_A_F_B.csv\")\n",
    "# y_train = pd.read_csv(\"preprocessedData/y_train-1129-A_A_A_B_B_A_F_B.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "4WQ9gcu09pNN"
   },
   "source": [
    "# Some hands on model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "-IYkxir4FO9I"
   },
   "source": [
    "### Scheme A\n",
    "\n",
    "普通方案. 单个模型. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ZHOBTMNsa7co"
   },
   "source": [
    "我们先弄出kappa的计算方式。确定实现正确了，才用到模型训练里面去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1607152113735,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "AOEDXFrx9pNO"
   },
   "outputs": [],
   "source": [
    "def getTheFinalVotingResult(l):\n",
    "    dic = defaultdict(list)\n",
    "    maxNum = -1\n",
    "    for i, j in Counter(l).items():\n",
    "        ## i是l里面的数字，j是i在l出现的次数\n",
    "        maxNum = max(maxNum, j)\n",
    "        ## 根据出现次数，来归类i\n",
    "        dic[j].append(i)\n",
    "    return random.choice(dic[maxNum])\n",
    "def kappa_withSklearn_lgb(y_pred, y):\n",
    "    # print(y_pred.shape)\n",
    "    index_array = np.argmax(np.reshape(y_pred, (-1, 3)), axis=-1)\n",
    "    return \"Kappa~~\", cohen_kappa_score(index_array, y.get_label().astype(int)), True\n",
    "\n",
    "def kappa_withSklearn_xgb(y_pred, y):\n",
    "    index_array = np.argmax(y_pred, axis=-1)\n",
    "    return \"Kappa\", cohen_kappa_score(index_array, y.get_label().astype(int)) * -1\n",
    "\n",
    "def kappaMyImplementation(sample_y, sample_pred): \n",
    "    ## 我自己实现的kappa \n",
    "    ## https://baike.baidu.com/item/kappa%E7%B3%BB%E6%95%B0/9385025\n",
    "    p0 = accuracy_score(sample_y, sample_pred)\n",
    "    y_count = Counter(sample_y)\n",
    "    pred_count = Counter(sample_pred)\n",
    "    n = len(sample_y)\n",
    "    s = 0\n",
    "    for l in [-1, 0, 1]:\n",
    "        ai = y_count.get(l, 0)\n",
    "        bi = pred_count.get(l, 0)\n",
    "        s += ai * bi\n",
    "    pe = s / (n * n)\n",
    "    return \"Kappa\", (p0 - pe) / (1 - pe), True\n",
    "\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name, folds = 5):\n",
    "    # folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    newStackingTestSet = pd.DataFrame(columns=[\"k{}\".format(i + 1) for i in range(folds)])\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y.iloc[train_index], train_x.iloc[valid_index], train_y.iloc[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'multiclass',\n",
    "                'num_class': 3,\n",
    "#                 'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,    \n",
    "#                 'device_type': 'gpu',\n",
    "#                 'max_bin': 63\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              verbose_eval=200, early_stopping_rounds=200, \n",
    "                              feval= kappa_withSklearn_lgb,  \n",
    "                             )\n",
    "            val_pred_ = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            print(val_pred_.shape)\n",
    "            test_pred_ = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            val_pred = np.argmax(val_pred_, axis=-1)\n",
    "            test_pred = np.argmax(test_pred_, axis=-1)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'multi:softprob',\n",
    "                      \"num_class\": 3, \n",
    "#                       'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04, \n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "\n",
    "#                       'tree_method': \"gpu_hist\", #  # \n",
    "                      'tree_method': 'exact',\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, \n",
    "                              evals=watchlist, verbose_eval=200, early_stopping_rounds=200, \n",
    "                             feval = kappa_withSklearn_xgb\n",
    "                             )\n",
    "            # https://stackoverflow.com/questions/55579610/xgboost-attributeerror-dataframe-object-has-no-attribute-feature-names\n",
    "            val_pred_  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred_ = model.predict(xgb.DMatrix(test_x) , ntree_limit=model.best_ntree_limit)\n",
    "            val_pred = np.argmax(val_pred_, axis=-1)\n",
    "            test_pred = np.argmax(test_pred_, axis=-1)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False, \n",
    "                      \"eval_metric\": \"Kappa\", \n",
    "#                       \"loss_function\": 'MultiClass', \n",
    "\n",
    "#                       \"task_type\": \"GPU\",\n",
    "                     }\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x).ravel()\n",
    "            test_pred = model.predict(test_x).ravel()\n",
    "            \n",
    "        ## 下面这个test，可以考虑像如下这样进行，或者是求平均亦可。\n",
    "        # test += test_pred / kf.n_splits ## Minke's invention, no basis or reference.\n",
    "        # test += test_pred\n",
    "        ##\n",
    "        train[valid_index] = val_pred\n",
    "        cv_scores.append(cohen_kappa_score(val_y, val_pred))\n",
    "        print(sum(cv_scores)/len(cv_scores), cv_scores)\n",
    "\n",
    "        newStackingTestSet[\"k{}\".format(i + 1)] = test_pred\n",
    "\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    print(\"what is kf.n_splits?\", kf.n_splits)\n",
    "\n",
    "    newStackingTestSet[\"voteRst\"] = newStackingTestSet[list(newStackingTestSet.columns)].apply(getTheFinalVotingResult, axis = 1)\n",
    "    # print(newStackingTestSet)\n",
    "    print(cohen_kappa_score(y_train, train))\n",
    "\n",
    "    return train, newStackingTestSet, np.mean(cv_scores) # test / kf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1607152121286,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "ON43ckVt9pNO"
   },
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_train, lgb_test, lgb_meanPerf = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_train, lgb_test, lgb_meanPerf\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test, xgb_meanPerf = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test, xgb_meanPerf\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test, cat_meanPerf = cv_model(CatBoostClassifier, x_train, y_train, x_test, \"cat\")\n",
    "    return cat_train, cat_test, cat_meanPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26223,
     "status": "ok",
     "timestamp": 1607152149038,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "Dyt-HIG2a7co",
    "outputId": "43cf032e-7b18-42a2-ba88-ff1957d48d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[02:35:13] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.31892\teval-merror:0.32150\ttrain-Kappa:-0.27092\teval-Kappa:-0.26167\n",
      "Multiple eval metrics have been passed: 'eval-Kappa' will be used for early stopping.\n",
      "\n",
      "Will train until eval-Kappa hasn't improved in 200 rounds.\n",
      "[200]\ttrain-merror:0.28785\teval-merror:0.29821\ttrain-Kappa:-0.36145\teval-Kappa:-0.33490\n",
      "[400]\ttrain-merror:0.26642\teval-merror:0.28700\ttrain-Kappa:-0.42674\teval-Kappa:-0.37809\n",
      "[600]\ttrain-merror:0.25020\teval-merror:0.28352\ttrain-Kappa:-0.47071\teval-Kappa:-0.39328\n",
      "[800]\ttrain-merror:0.23432\teval-merror:0.28258\ttrain-Kappa:-0.50912\teval-Kappa:-0.40016\n",
      "[1000]\ttrain-merror:0.22105\teval-merror:0.28258\ttrain-Kappa:-0.54112\teval-Kappa:-0.40332\n",
      "[1200]\ttrain-merror:0.20984\teval-merror:0.28179\ttrain-Kappa:-0.56727\teval-Kappa:-0.40716\n",
      "[1400]\ttrain-merror:0.19958\teval-merror:0.28201\ttrain-Kappa:-0.59039\teval-Kappa:-0.40872\n",
      "[1600]\ttrain-merror:0.19025\teval-merror:0.28186\ttrain-Kappa:-0.61174\teval-Kappa:-0.41063\n",
      "Stopping. Best iteration:\n",
      "[1573]\ttrain-merror:0.19139\teval-merror:0.28135\ttrain-Kappa:-0.60914\teval-Kappa:-0.41170\n",
      "\n",
      "0.4116969905780974 [0.4116969905780974]\n",
      "************************************ 2 ************************************\n",
      "[02:40:24] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.31855\teval-merror:0.32571\ttrain-Kappa:-0.26702\teval-Kappa:-0.26082\n",
      "Multiple eval metrics have been passed: 'eval-Kappa' will be used for early stopping.\n",
      "\n",
      "Will train until eval-Kappa hasn't improved in 200 rounds.\n",
      "[200]\ttrain-merror:0.28535\teval-merror:0.30409\ttrain-Kappa:-0.36402\teval-Kappa:-0.32638\n",
      "[400]\ttrain-merror:0.26379\teval-merror:0.29338\ttrain-Kappa:-0.42953\teval-Kappa:-0.36823\n",
      "[600]\ttrain-merror:0.24750\teval-merror:0.29100\ttrain-Kappa:-0.47303\teval-Kappa:-0.38122\n",
      "[800]\ttrain-merror:0.23278\teval-merror:0.28716\ttrain-Kappa:-0.50981\teval-Kappa:-0.39430\n",
      "[1000]\ttrain-merror:0.22034\teval-merror:0.28571\ttrain-Kappa:-0.53982\teval-Kappa:-0.40105\n",
      "[1200]\ttrain-merror:0.20927\teval-merror:0.28456\ttrain-Kappa:-0.56561\teval-Kappa:-0.40571\n",
      "[1400]\ttrain-merror:0.20021\teval-merror:0.28369\ttrain-Kappa:-0.58676\teval-Kappa:-0.40984\n",
      "[1600]\ttrain-merror:0.19059\teval-merror:0.28506\ttrain-Kappa:-0.60867\teval-Kappa:-0.40854\n",
      "Stopping. Best iteration:\n",
      "[1416]\ttrain-merror:0.19889\teval-merror:0.28311\ttrain-Kappa:-0.58967\teval-Kappa:-0.41129\n",
      "\n",
      "0.41149093356899813 [0.4116969905780974, 0.41128487655989887]\n",
      "************************************ 3 ************************************\n",
      "[02:45:02] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.32095\teval-merror:0.31834\ttrain-Kappa:-0.25486\teval-Kappa:-0.25752\n",
      "Multiple eval metrics have been passed: 'eval-Kappa' will be used for early stopping.\n",
      "\n",
      "Will train until eval-Kappa hasn't improved in 200 rounds.\n",
      "[200]\ttrain-merror:0.28689\teval-merror:0.29490\ttrain-Kappa:-0.36318\teval-Kappa:-0.34175\n",
      "[400]\ttrain-merror:0.26471\teval-merror:0.28875\ttrain-Kappa:-0.42981\teval-Kappa:-0.37213\n",
      "[600]\ttrain-merror:0.24862\teval-merror:0.28579\ttrain-Kappa:-0.47252\teval-Kappa:-0.38603\n",
      "[800]\ttrain-merror:0.23459\teval-merror:0.28297\ttrain-Kappa:-0.50791\teval-Kappa:-0.39629\n",
      "[1000]\ttrain-merror:0.22141\teval-merror:0.28065\ttrain-Kappa:-0.53975\teval-Kappa:-0.40507\n",
      "[1200]\ttrain-merror:0.20985\teval-merror:0.27986\ttrain-Kappa:-0.56681\teval-Kappa:-0.40982\n",
      "[1400]\ttrain-merror:0.19924\teval-merror:0.27964\ttrain-Kappa:-0.59097\teval-Kappa:-0.41204\n",
      "[1600]\ttrain-merror:0.19034\teval-merror:0.28014\ttrain-Kappa:-0.61131\teval-Kappa:-0.41234\n",
      "[1800]\ttrain-merror:0.18215\teval-merror:0.28137\ttrain-Kappa:-0.62958\teval-Kappa:-0.41109\n",
      "Stopping. Best iteration:\n",
      "[1603]\ttrain-merror:0.19027\teval-merror:0.27920\ttrain-Kappa:-0.61139\teval-Kappa:-0.41445\n",
      "\n",
      "0.41247765441719836 [0.4116969905780974, 0.41128487655989887, 0.41445109611359876]\n",
      "************************************ 4 ************************************\n",
      "[02:50:12] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.32052\teval-merror:0.32405\ttrain-Kappa:-0.26116\teval-Kappa:-0.25147\n",
      "Multiple eval metrics have been passed: 'eval-Kappa' will be used for early stopping.\n",
      "\n",
      "Will train until eval-Kappa hasn't improved in 200 rounds.\n",
      "[200]\ttrain-merror:0.28745\teval-merror:0.30018\ttrain-Kappa:-0.36147\teval-Kappa:-0.32743\n",
      "[400]\ttrain-merror:0.26482\teval-merror:0.29100\ttrain-Kappa:-0.42826\teval-Kappa:-0.36530\n",
      "[600]\ttrain-merror:0.24862\teval-merror:0.28767\ttrain-Kappa:-0.47149\teval-Kappa:-0.38053\n",
      "[800]\ttrain-merror:0.23410\teval-merror:0.28427\ttrain-Kappa:-0.50743\teval-Kappa:-0.39227\n",
      "[1000]\ttrain-merror:0.22168\teval-merror:0.28376\ttrain-Kappa:-0.53773\teval-Kappa:-0.39770\n",
      "[1200]\ttrain-merror:0.20967\teval-merror:0.28311\ttrain-Kappa:-0.56547\teval-Kappa:-0.40069\n",
      "[1400]\ttrain-merror:0.19969\teval-merror:0.28340\ttrain-Kappa:-0.58871\teval-Kappa:-0.40301\n",
      "[1600]\ttrain-merror:0.19097\teval-merror:0.28419\ttrain-Kappa:-0.60869\teval-Kappa:-0.40332\n",
      "[1800]\ttrain-merror:0.18246\teval-merror:0.28333\ttrain-Kappa:-0.62791\teval-Kappa:-0.40681\n",
      "[2000]\ttrain-merror:0.17495\teval-merror:0.28325\ttrain-Kappa:-0.64464\teval-Kappa:-0.40786\n",
      "[2200]\ttrain-merror:0.16730\teval-merror:0.28354\ttrain-Kappa:-0.66143\teval-Kappa:-0.40837\n",
      "Stopping. Best iteration:\n",
      "[2136]\ttrain-merror:0.16947\teval-merror:0.28224\ttrain-Kappa:-0.65671\teval-Kappa:-0.41088\n",
      "\n",
      "0.4120789015887649 [0.4116969905780974, 0.41128487655989887, 0.41445109611359876, 0.4108826431034648]\n",
      "************************************ 5 ************************************\n",
      "[02:56:52] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.31927\teval-merror:0.31906\ttrain-Kappa:-0.27304\teval-Kappa:-0.27100\n",
      "Multiple eval metrics have been passed: 'eval-Kappa' will be used for early stopping.\n",
      "\n",
      "Will train until eval-Kappa hasn't improved in 200 rounds.\n",
      "[200]\ttrain-merror:0.28649\teval-merror:0.29671\ttrain-Kappa:-0.36617\teval-Kappa:-0.34128\n",
      "[400]\ttrain-merror:0.26314\teval-merror:0.28940\ttrain-Kappa:-0.43428\teval-Kappa:-0.37320\n",
      "[600]\ttrain-merror:0.24718\teval-merror:0.28774\ttrain-Kappa:-0.47664\teval-Kappa:-0.38579\n",
      "[800]\ttrain-merror:0.23325\teval-merror:0.28651\ttrain-Kappa:-0.51088\teval-Kappa:-0.39274\n",
      "[1000]\ttrain-merror:0.22041\teval-merror:0.28398\ttrain-Kappa:-0.54188\teval-Kappa:-0.40293\n",
      "[1200]\ttrain-merror:0.21009\teval-merror:0.28354\ttrain-Kappa:-0.56594\teval-Kappa:-0.40601\n",
      "[1400]\ttrain-merror:0.19978\teval-merror:0.28217\ttrain-Kappa:-0.58959\teval-Kappa:-0.41082\n",
      "[1600]\ttrain-merror:0.19012\teval-merror:0.28094\ttrain-Kappa:-0.61147\teval-Kappa:-0.41509\n",
      "[1800]\ttrain-merror:0.18143\teval-merror:0.28289\ttrain-Kappa:-0.63080\teval-Kappa:-0.41269\n",
      "Stopping. Best iteration:\n",
      "[1609]\ttrain-merror:0.18949\teval-merror:0.28072\ttrain-Kappa:-0.61289\teval-Kappa:-0.41557\n",
      "\n",
      "0.41277731396868267 [0.4116969905780974, 0.41128487655989887, 0.41445109611359876, 0.4108826431034648, 0.41557096348835354]\n",
      "xgb_scotrainre_list: [0.4116969905780974, 0.41128487655989887, 0.41445109611359876, 0.4108826431034648, 0.41557096348835354]\n",
      "xgb_score_mean: 0.41277731396868267\n",
      "xgb_score_std: 0.0018756476237441649\n",
      "what is kf.n_splits? 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41276082748603937\n"
     ]
    }
   ],
   "source": [
    "## 这个方法目前来看最好，但是最慢。\n",
    "xgb_train, xgb_test, xgb_meanPerf= xgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "RuRAmeNUmYuf"
   },
   "source": [
    "性能不赖。不过问题是怎么将结果进行组合。可能需要一点以前写的代码的技巧了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1607151907848,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "iGWG_YyN9pNO"
   },
   "outputs": [],
   "source": [
    "testA_result = pd.read_csv('originalDataset/submission_sample.csv')\n",
    "testA_result_pred = testA_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1607151925626,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "C-R_jyu49pNO"
   },
   "outputs": [],
   "source": [
    "testA_result_pred[\"label\"] = xgb_test.iloc[:,-1]\n",
    "### 注释掉的两行，酌情运行。\n",
    "testA_result_pred.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "testA_result_pred.fillna(0.0, inplace=True)\n",
    "testA_result_pred[\"label\"] = testA_result_pred[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1607151994123,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "dB11Zb7XtcbQ"
   },
   "outputs": [],
   "source": [
    "### 注意###############\n",
    "## 最后存成文件的时候，要把类别的标签改回-1，0，1.\n",
    "testA_result_pred[\"label\"] = testA_result_pred[\"label\"].map({0: -1, 1: 0, 2: 1})\n",
    "testA_result_pred.to_csv(\"submissionResults/KeepTheFeaturesAsTheyOriginallyWere_{:.4}.csv\".format(xgb_meanPerf), index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testA_result_pred[\"label\"] = xgb_test.iloc[:,-1]\n",
    "### 注释掉的两行，酌情运行。\n",
    "# testA_result_pred.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# testA_result_pred.fillna(0.0, inplace=True)\n",
    "testA_result_pred[\"label\"] = testA_result_pred[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### 注意###############\n",
    "## 最后存成文件的时候，要把类别的标签改回-1，0，1.\n",
    "testA_result_pred[\"label\"] = testA_result_pred[\"label\"].map({0: -1, 1: 0, 2: 1})\n",
    "testA_result_pred.to_csv(\"submissionResults/KeepTheFeaturesAsTheyOriginallyWere_{:.4}-1.csv\".format(xgb_meanPerf), index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "bDy3ssLVqIbF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 这个方法很快，可以用这个方法粗略看一下效果\n",
    "cat_train, cat_test, cat_meanPerf = cat_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tsPHHrnQa7co"
   },
   "outputs": [],
   "source": [
    "# ## 貌似有问题。特慢。而且性能指标看上去很奇怪。\n",
    "# lgb_train, lgb_test, lgb_meanPerf = lgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "B5GQcvPZa7cp"
   },
   "outputs": [],
   "source": [
    "# newStackingTrainingSet = pd.DataFrame(columns=[\"lgb\", \"cat\", \"xgb\"])\n",
    "# newStackingTrainingSet[\"lgb\"] = lgb_train\n",
    "# newStackingTrainingSet[\"cat\"] = cat_train\n",
    "# newStackingTrainingSet[\"xgb\"] = xgb_train\n",
    "\n",
    "# newStackingTestSet = pd.DataFrame(columns=[\"lgb\", \"cat\", \"xgb\"])\n",
    "# newStackingTestSet[\"lgb\"] = lgb_test\n",
    "# newStackingTestSet[\"cat\"] = cat_test\n",
    "# newStackingTestSet[\"xgb\"] = xgb_test\n",
    "\n",
    "# xgb_train_final, xgb_test_final = xgb_model(newStackingTrainingSet, y_train, newStackingTestSet)\n",
    "\n",
    "# testA_result_pred[\"isDefault\"] = xgb_test_final\n",
    "# testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-lgb_cat_xgb+xgb-????.csv\", index=False) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "z3Ze_bEoDbTG"
   },
   "outputs": [],
   "source": [
    "# testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-xgb-7385.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tLxObE6VbCD6"
   },
   "outputs": [],
   "source": [
    "# testA_result_pred.to_csv(\"submissionResults/xgboost-1128-A_A_A_B_A_A_E_A-7379.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6Y9Nl13yXHlc"
   },
   "outputs": [],
   "source": [
    "# testA_result_pred.to_csv(\"submissionResults/xgboost-1128-A_A_A_B_B_A_D_B-7383.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0QYhLwVi9pNO"
   },
   "outputs": [],
   "source": [
    "# testA_result_pred.to_csv(\"submissionResults/xgboost-1128-A_A_A_B_B_A_C_B-????.csv\", index=False) ## 理论上应该得分较高的。但是没训练完就给我停掉了。以后再试一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "i2vo5VbaJFak"
   },
   "source": [
    "### Scheme B\n",
    "\n",
    "多个模型的stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "RQsnDCIKJg8e"
   },
   "outputs": [],
   "source": [
    "## 使用A方案里面的函数. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eM0X37aKKWWS"
   },
   "outputs": [],
   "source": [
    "## 如果有必要, 可以保存一轮. \n",
    "testA_result_pred[\"isDefault\"] = lgb_test\n",
    "testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-lgb-7372.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1036593,
     "status": "ok",
     "timestamp": 1606674815616,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "RjJIILaoJErh",
    "outputId": "fd15e41c-8b15-4b66-cee7-d2cf886a796a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "0:\tlearn: 0.3985157\ttest: 0.3965959\tbest: 0.3965959 (0)\ttotal: 139ms\tremaining: 46m 25s\n",
      "500:\tlearn: 0.3756413\ttest: 0.3743346\tbest: 0.3743346 (500)\ttotal: 37.8s\tremaining: 24m 32s\n",
      "1000:\tlearn: 0.3741548\ttest: 0.3736793\tbest: 0.3736793 (1000)\ttotal: 1m 12s\tremaining: 22m 57s\n",
      "1500:\tlearn: 0.3730979\ttest: 0.3733782\tbest: 0.3733776 (1498)\ttotal: 1m 46s\tremaining: 21m 58s\n",
      "2000:\tlearn: 0.3722170\ttest: 0.3732208\tbest: 0.3732207 (1999)\ttotal: 2m 21s\tremaining: 21m 14s\n",
      "2500:\tlearn: 0.3714033\ttest: 0.3731051\tbest: 0.3731050 (2494)\ttotal: 2m 56s\tremaining: 20m 33s\n",
      "3000:\tlearn: 0.3706215\ttest: 0.3730281\tbest: 0.3730271 (2990)\ttotal: 3m 31s\tremaining: 19m 56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3730018737\n",
      "bestIteration = 3229\n",
      "\n",
      "Shrink model to first 3230 iterations.\n",
      "[0.7383488181966832]\n",
      "************************************ 2 ************************************\n",
      "0:\tlearn: 0.3979620\ttest: 0.3989038\tbest: 0.3989038 (0)\ttotal: 91.8ms\tremaining: 30m 36s\n",
      "500:\tlearn: 0.3749722\ttest: 0.3771181\tbest: 0.3771181 (500)\ttotal: 37.6s\tremaining: 24m 21s\n",
      "1000:\tlearn: 0.3734687\ttest: 0.3764046\tbest: 0.3764046 (1000)\ttotal: 1m 12s\tremaining: 22m 57s\n",
      "1500:\tlearn: 0.3724322\ttest: 0.3761237\tbest: 0.3761229 (1499)\ttotal: 1m 47s\tremaining: 22m 6s\n",
      "2000:\tlearn: 0.3715362\ttest: 0.3759640\tbest: 0.3759636 (1996)\ttotal: 2m 22s\tremaining: 21m 20s\n",
      "2500:\tlearn: 0.3707212\ttest: 0.3758562\tbest: 0.3758562 (2500)\ttotal: 2m 57s\tremaining: 20m 38s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3758079624\n",
      "bestIteration = 2856\n",
      "\n",
      "Shrink model to first 2857 iterations.\n",
      "[0.7383488181966832, 0.7345917025217683]\n",
      "************************************ 3 ************************************\n",
      "0:\tlearn: 0.3979996\ttest: 0.3987330\tbest: 0.3987330 (0)\ttotal: 87.1ms\tremaining: 29m 2s\n",
      "500:\tlearn: 0.3752396\ttest: 0.3762122\tbest: 0.3762122 (500)\ttotal: 37.5s\tremaining: 24m 20s\n",
      "1000:\tlearn: 0.3737321\ttest: 0.3754534\tbest: 0.3754534 (1000)\ttotal: 1m 12s\tremaining: 23m 3s\n",
      "1500:\tlearn: 0.3726812\ttest: 0.3751495\tbest: 0.3751495 (1500)\ttotal: 1m 47s\tremaining: 22m 6s\n",
      "2000:\tlearn: 0.3717900\ttest: 0.3750077\tbest: 0.3750076 (1999)\ttotal: 2m 22s\tremaining: 21m 18s\n",
      "2500:\tlearn: 0.3709752\ttest: 0.3749240\tbest: 0.3749210 (2486)\ttotal: 2m 56s\tremaining: 20m 38s\n",
      "3000:\tlearn: 0.3702161\ttest: 0.3748589\tbest: 0.3748589 (3000)\ttotal: 3m 32s\tremaining: 20m 1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3748327272\n",
      "bestIteration = 3302\n",
      "\n",
      "Shrink model to first 3303 iterations.\n",
      "[0.7383488181966832, 0.7345917025217683, 0.7382851077796634]\n",
      "************************************ 4 ************************************\n",
      "0:\tlearn: 0.3980822\ttest: 0.3983889\tbest: 0.3983889 (0)\ttotal: 81.5ms\tremaining: 27m 10s\n",
      "500:\tlearn: 0.3752547\ttest: 0.3762421\tbest: 0.3762421 (500)\ttotal: 37.5s\tremaining: 24m 21s\n",
      "1000:\tlearn: 0.3737581\ttest: 0.3754927\tbest: 0.3754927 (1000)\ttotal: 1m 13s\tremaining: 23m 7s\n",
      "1500:\tlearn: 0.3727055\ttest: 0.3751996\tbest: 0.3751996 (1500)\ttotal: 1m 48s\tremaining: 22m 15s\n",
      "2000:\tlearn: 0.3717955\ttest: 0.3750442\tbest: 0.3750442 (2000)\ttotal: 2m 23s\tremaining: 21m 28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3749754568\n",
      "bestIteration = 2335\n",
      "\n",
      "Shrink model to first 2336 iterations.\n",
      "[0.7383488181966832, 0.7345917025217683, 0.7382851077796634, 0.7371509966091883]\n",
      "************************************ 5 ************************************\n",
      "0:\tlearn: 0.3981558\ttest: 0.3981148\tbest: 0.3981148 (0)\ttotal: 81.3ms\tremaining: 27m 6s\n",
      "500:\tlearn: 0.3752660\ttest: 0.3761308\tbest: 0.3761308 (500)\ttotal: 37.8s\tremaining: 24m 29s\n",
      "1000:\tlearn: 0.3737822\ttest: 0.3754222\tbest: 0.3754222 (1000)\ttotal: 1m 14s\tremaining: 23m 24s\n",
      "1500:\tlearn: 0.3727141\ttest: 0.3750742\tbest: 0.3750738 (1498)\ttotal: 1m 50s\tremaining: 22m 39s\n",
      "2000:\tlearn: 0.3718256\ttest: 0.3748936\tbest: 0.3748927 (1998)\ttotal: 2m 26s\tremaining: 21m 53s\n",
      "2500:\tlearn: 0.3710026\ttest: 0.3747709\tbest: 0.3747688 (2485)\ttotal: 3m 1s\tremaining: 21m 10s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3747687552\n",
      "bestIteration = 2485\n",
      "\n",
      "Shrink model to first 2486 iterations.\n",
      "[0.7383488181966832, 0.7345917025217683, 0.7382851077796634, 0.7371509966091883, 0.7363740584782061]\n",
      "cat_scotrainre_list: [0.7383488181966832, 0.7345917025217683, 0.7382851077796634, 0.7371509966091883, 0.7363740584782061]\n",
      "cat_score_mean: 0.7369501367171019\n",
      "cat_score_std: 0.0013908903843579646\n",
      "what is kf.n_splits? 5\n"
     ]
    }
   ],
   "source": [
    "cat_train, cat_test = cat_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "dU0PR5_lJ31p"
   },
   "outputs": [],
   "source": [
    "## 如果有必要, 可以保存一轮. \n",
    "testA_result_pred[\"isDefault\"] = cat_test\n",
    "testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-cat-????.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "lvlJg0v4MiGE"
   },
   "source": [
    "三连"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98251,
     "status": "ok",
     "timestamp": 1606674915865,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "hkjnmRj0OaEq",
    "outputId": "95a67271-7394-48a7-d7a4-a2eb7196c2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.737118\teval-auc:0.738217\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739597\teval-auc:0.739911\n",
      "Stopping. Best iteration:\n",
      "[163]\ttrain-auc:0.739447\teval-auc:0.739924\n",
      "\n",
      "[0.7399235409121722]\n",
      "************************************ 2 ************************************\n",
      "[0]\ttrain-auc:0.737917\teval-auc:0.734741\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.740359\teval-auc:0.736625\n",
      "Stopping. Best iteration:\n",
      "[132]\ttrain-auc:0.740154\teval-auc:0.736661\n",
      "\n",
      "[0.7399235409121722, 0.7366608129717951]\n",
      "************************************ 3 ************************************\n",
      "[0]\ttrain-auc:0.73719\teval-auc:0.738161\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.73962\teval-auc:0.7397\n",
      "Stopping. Best iteration:\n",
      "[54]\ttrain-auc:0.739066\teval-auc:0.739778\n",
      "\n",
      "[0.7399235409121722, 0.7366608129717951, 0.7397780700726535]\n",
      "************************************ 4 ************************************\n",
      "[0]\ttrain-auc:0.737276\teval-auc:0.737762\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739714\teval-auc:0.739234\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-auc:0.739135\teval-auc:0.739325\n",
      "\n",
      "[0.7399235409121722, 0.7366608129717951, 0.7397780700726535, 0.7393248229133318]\n",
      "************************************ 5 ************************************\n",
      "[0]\ttrain-auc:0.737538\teval-auc:0.73682\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739855\teval-auc:0.738685\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-auc:0.739426\teval-auc:0.738721\n",
      "\n",
      "[0.7399235409121722, 0.7366608129717951, 0.7397780700726535, 0.7393248229133318, 0.7387213783845085]\n",
      "xgb_scotrainre_list: [0.7399235409121722, 0.7366608129717951, 0.7397780700726535, 0.7393248229133318, 0.7387213783845085]\n",
      "xgb_score_mean: 0.7388817250508923\n",
      "xgb_score_std: 0.0011868708370373884\n",
      "what is kf.n_splits? 5\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "RBnrDo3jTgcI"
   },
   "outputs": [],
   "source": [
    "# newStackingTrainingSet = pd.DataFrame(columns=[\"lgb\", \"cat\", \"xgb\"])\n",
    "# newStackingTrainingSet[\"lgb\"] = lgb_train\n",
    "# newStackingTrainingSet[\"cat\"] = cat_train\n",
    "# newStackingTrainingSet[\"xgb\"] = xgb_train\n",
    "# newStackingTrainingSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "jzRsNIEkVi56"
   },
   "outputs": [],
   "source": [
    "# newStackingTestSet = pd.DataFrame(columns=[\"lgb\", \"cat\", \"xgb\"])\n",
    "# newStackingTestSet[\"lgb\"] = lgb_test\n",
    "# newStackingTestSet[\"cat\"] = cat_test\n",
    "# newStackingTestSet[\"xgb\"] = xgb_test\n",
    "# newStackingTestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Tg7QO04IXO1f"
   },
   "outputs": [],
   "source": [
    "# xgb_train_final, xgb_test_final = xgb_model(newStackingTrainingSet, y_train, newStackingTestSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "c9tX2pWGMm0g"
   },
   "outputs": [],
   "source": [
    "# ## 如果有必要, 可以保存一轮. \n",
    "# testA_result_pred[\"isDefault\"] = xgb_test_final\n",
    "# testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-lgb_xgb_cat+xgb-????.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "VXamrWwlMu24"
   },
   "source": [
    "二连1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180944,
     "status": "ok",
     "timestamp": 1606674998581,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "uKx_0wYjMuSA",
    "outputId": "8d814eaf-a71b-4b72-c08c-e32b9684ad13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.735481\teval-auc:0.736854\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738361\teval-auc:0.739337\n",
      "Stopping. Best iteration:\n",
      "[72]\ttrain-auc:0.738177\teval-auc:0.739388\n",
      "\n",
      "[0.7393877295712593]\n",
      "************************************ 2 ************************************\n",
      "[0]\ttrain-auc:0.736401\teval-auc:0.733022\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739215\teval-auc:0.735753\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-auc:0.739088\teval-auc:0.735801\n",
      "\n",
      "[0.7393877295712593, 0.7358009060707756]\n",
      "************************************ 3 ************************************\n",
      "[0]\ttrain-auc:0.735582\teval-auc:0.737011\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738379\teval-auc:0.739177\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-auc:0.738173\teval-auc:0.739238\n",
      "\n",
      "[0.7393877295712593, 0.7358009060707756, 0.7392375463053734]\n",
      "************************************ 4 ************************************\n",
      "[0]\ttrain-auc:0.735666\teval-auc:0.735779\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738481\teval-auc:0.738772\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-auc:0.738332\teval-auc:0.738799\n",
      "\n",
      "[0.7393877295712593, 0.7358009060707756, 0.7392375463053734, 0.7387989296094711]\n",
      "************************************ 5 ************************************\n",
      "[0]\ttrain-auc:0.735895\teval-auc:0.73506\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738781\teval-auc:0.737558\n",
      "Stopping. Best iteration:\n",
      "[62]\ttrain-auc:0.738578\teval-auc:0.73768\n",
      "\n",
      "[0.7393877295712593, 0.7358009060707756, 0.7392375463053734, 0.7387989296094711, 0.7376795786550623]\n",
      "xgb_scotrainre_list: [0.7393877295712593, 0.7358009060707756, 0.7392375463053734, 0.7387989296094711, 0.7376795786550623]\n",
      "xgb_score_mean: 0.7381809380423883\n",
      "xgb_score_std: 0.0013319604959387585\n",
      "what is kf.n_splits? 5\n"
     ]
    }
   ],
   "source": [
    "newStackingTrainingSet = pd.DataFrame(columns=[\"lgb\", \"cat\"])\n",
    "newStackingTrainingSet[\"lgb\"] = lgb_train\n",
    "newStackingTrainingSet[\"cat\"] = cat_train\n",
    "# newStackingTrainingSet[\"xgb\"] = xgb_train\n",
    "\n",
    "newStackingTestSet = pd.DataFrame(columns=[\"lgb\", \"cat\"])\n",
    "newStackingTestSet[\"lgb\"] = lgb_test\n",
    "newStackingTestSet[\"cat\"] = cat_test\n",
    "# newStackingTestSet[\"xgb\"] = xgb_test\n",
    "\n",
    "xgb_train_final, xgb_test_final = xgb_model(newStackingTrainingSet, y_train, newStackingTestSet)\n",
    "\n",
    "testA_result_pred[\"isDefault\"] = xgb_test_final\n",
    "testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-lgb_cat+xgb-????.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Y9bJcOTlMxmL"
   },
   "source": [
    "二连2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252833,
     "status": "ok",
     "timestamp": 1606675070479,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "Pb6XSR8-M0s6",
    "outputId": "d3b73129-4ce4-46d0-9ce0-65fbf0e4d3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.737329\teval-auc:0.73841\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.73898\teval-auc:0.739619\n",
      "Stopping. Best iteration:\n",
      "[24]\ttrain-auc:0.738759\teval-auc:0.739758\n",
      "\n",
      "[0.7397576966719892]\n",
      "************************************ 2 ************************************\n",
      "[0]\ttrain-auc:0.738173\teval-auc:0.735127\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739764\teval-auc:0.73647\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-auc:0.739573\teval-auc:0.73659\n",
      "\n",
      "[0.7397576966719892, 0.7365901209883987]\n",
      "************************************ 3 ************************************\n",
      "[0]\ttrain-auc:0.737413\teval-auc:0.738178\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.73901\teval-auc:0.739455\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-auc:0.73878\teval-auc:0.739601\n",
      "\n",
      "[0.7397576966719892, 0.7365901209883987, 0.7396014087459107]\n",
      "************************************ 4 ************************************\n",
      "[0]\ttrain-auc:0.737406\teval-auc:0.737589\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739107\teval-auc:0.739075\n",
      "Stopping. Best iteration:\n",
      "[66]\ttrain-auc:0.7389\teval-auc:0.739209\n",
      "\n",
      "[0.7397576966719892, 0.7365901209883987, 0.7396014087459107, 0.7392085974461047]\n",
      "************************************ 5 ************************************\n",
      "[0]\ttrain-auc:0.73757\teval-auc:0.737475\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739248\teval-auc:0.738563\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-auc:0.738988\teval-auc:0.738688\n",
      "\n",
      "[0.7397576966719892, 0.7365901209883987, 0.7396014087459107, 0.7392085974461047, 0.7386882045540842]\n",
      "xgb_scotrainre_list: [0.7397576966719892, 0.7365901209883987, 0.7396014087459107, 0.7392085974461047, 0.7386882045540842]\n",
      "xgb_score_mean: 0.7387692056812976\n",
      "xgb_score_std: 0.0011504531962532268\n",
      "what is kf.n_splits? 5\n"
     ]
    }
   ],
   "source": [
    "newStackingTrainingSet = pd.DataFrame(columns=[\"lgb\", \"xgb\"])\n",
    "newStackingTrainingSet[\"lgb\"] = lgb_train\n",
    "# newStackingTrainingSet[\"cat\"] = cat_train\n",
    "newStackingTrainingSet[\"xgb\"] = xgb_train\n",
    "\n",
    "newStackingTestSet = pd.DataFrame(columns=[\"lgb\", \"xgb\"])\n",
    "newStackingTestSet[\"lgb\"] = lgb_test\n",
    "# newStackingTestSet[\"cat\"] = cat_test\n",
    "newStackingTestSet[\"xgb\"] = xgb_test\n",
    "\n",
    "xgb_train_final, xgb_test_final = xgb_model(newStackingTrainingSet, y_train, newStackingTestSet)\n",
    "\n",
    "testA_result_pred[\"isDefault\"] = xgb_test_final\n",
    "testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-lgb_xgb+xgb-????.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "kaIkI270MzL-"
   },
   "source": [
    "二连3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321225,
     "status": "ok",
     "timestamp": 1606675138880,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "scXtotjuM2Hs",
    "outputId": "b379d17f-e296-4ae8-bfb4-28612fc7a674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.737329\teval-auc:0.73841\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738783\teval-auc:0.739602\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-auc:0.7386\teval-auc:0.739739\n",
      "\n",
      "[0.7397392697121947]\n",
      "************************************ 2 ************************************\n",
      "[0]\ttrain-auc:0.738173\teval-auc:0.735127\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739618\teval-auc:0.73633\n",
      "Stopping. Best iteration:\n",
      "[24]\ttrain-auc:0.739422\teval-auc:0.736446\n",
      "\n",
      "[0.7397392697121947, 0.7364457435182439]\n",
      "************************************ 3 ************************************\n",
      "[0]\ttrain-auc:0.737413\teval-auc:0.738178\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.738792\teval-auc:0.739519\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-auc:0.738607\teval-auc:0.739657\n",
      "\n",
      "[0.7397392697121947, 0.7364457435182439, 0.739657298138128]\n",
      "************************************ 4 ************************************\n",
      "[0]\ttrain-auc:0.737406\teval-auc:0.737589\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739018\teval-auc:0.738665\n",
      "Stopping. Best iteration:\n",
      "[16]\ttrain-auc:0.738782\teval-auc:0.738847\n",
      "\n",
      "[0.7397392697121947, 0.7364457435182439, 0.739657298138128, 0.7388469677739288]\n",
      "************************************ 5 ************************************\n",
      "[0]\ttrain-auc:0.73757\teval-auc:0.737475\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.739079\teval-auc:0.738468\n",
      "Stopping. Best iteration:\n",
      "[16]\ttrain-auc:0.738864\teval-auc:0.738629\n",
      "\n",
      "[0.7397392697121947, 0.7364457435182439, 0.739657298138128, 0.7388469677739288, 0.7386292462933519]\n",
      "xgb_scotrainre_list: [0.7397392697121947, 0.7364457435182439, 0.739657298138128, 0.7388469677739288, 0.7386292462933519]\n",
      "xgb_score_mean: 0.7386637050871695\n",
      "xgb_score_std: 0.0011914858417605484\n",
      "what is kf.n_splits? 5\n"
     ]
    }
   ],
   "source": [
    "newStackingTrainingSet = pd.DataFrame(columns=[\"cat\", \"xgb\"])\n",
    "# newStackingTrainingSet[\"lgb\"] = lgb_train\n",
    "newStackingTrainingSet[\"cat\"] = cat_train\n",
    "newStackingTrainingSet[\"xgb\"] = xgb_train\n",
    "\n",
    "newStackingTestSet = pd.DataFrame(columns=[\"cat\", \"xgb\"])\n",
    "# newStackingTestSet[\"lgb\"] = lgb_test\n",
    "newStackingTestSet[\"cat\"] = cat_test\n",
    "newStackingTestSet[\"xgb\"] = xgb_test\n",
    "\n",
    "xgb_train_final, xgb_test_final = xgb_model(newStackingTrainingSet, y_train, newStackingTestSet)\n",
    "\n",
    "testA_result_pred[\"isDefault\"] = xgb_test_final\n",
    "testA_result_pred.to_csv(\"submissionResults/1129-a_a_a_b_b_a_f_b-cat_xgb+xgb-????.csv\", index=False) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "kmVWMMJwyzUO"
   },
   "source": [
    "# -------(Recycle bin)-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "imQT__-Mmnsb"
   },
   "outputs": [],
   "source": [
    "# new_cols = []\n",
    "\n",
    "# for col in numerical_category_manyValues: \n",
    "#     for numFea in object_serial + numerical_serial + [\"isDefault\"]: #half_serials + [\"isDefault\"]: # for numFea in [\"isDefault\"]: \n",
    "#         temp_dict = data_train.groupby([col])[numFea].agg(['mean']).reset_index().rename(columns={'mean': col + '_{}_mean'.format(numFea)})\n",
    "#         temp_dict.index = temp_dict[col].values\n",
    "#         temp_dict = temp_dict[col + '_{}_mean'.format(numFea)].to_dict()\n",
    "#         data_train[col + '_{}_mean'.format(numFea)] = data_train[col].map(temp_dict)\n",
    "#         data_test_a[col + '_{}_mean'.format(numFea)] = data_test_a[col].map(temp_dict)\n",
    "#         new_cols.append(col + '_{}_mean'.format(numFea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "HNM7fDoctckM"
   },
   "outputs": [],
   "source": [
    "# data_train[new_cols].isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "iYsLd6ZpqSNv"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from scipy.stats import pearsonr\n",
    "# #选择K个最好的特征，返回选择特征后的数据\n",
    "# #第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，\n",
    "# #输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数\n",
    "# #参数k为选择的特征个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YYggb1t_rU-c"
   },
   "outputs": [],
   "source": [
    "# def selectNFeatures(numSelectedFeatures, data_train, y_train):\n",
    "\n",
    "#     data_train = data_train.fillna(axis = 1, method = \"ffill\")\n",
    "\n",
    "#     selector = SelectKBest(k=numSelectedFeatures)\n",
    "#     selector.fit(data_train, y_train)\n",
    "#     colNums = selector.get_support(True)\n",
    "#     selectedFeatures = []\n",
    "#     deletedFeatures = []\n",
    "#     for i, col in enumerate(list(data_train.columns)):\n",
    "#         if i in colNums:\n",
    "#             selectedFeatures.append(col)\n",
    "#         else: \n",
    "#             deletedFeatures.append(col)\n",
    "#     # len(selectedFeatures)\n",
    "#     # data_train = data_train[selectedFeatures]\n",
    "#     # data_test_a = data_test_a[selectedFeatures]\n",
    "#     return selectedFeatures, deletedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Qz0ItDYisG66"
   },
   "outputs": [],
   "source": [
    "# selectedFeatures, deletedFeatures = selectNFeatures(5, data_train[new_cols], data_train[[\"isDefault\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "NYC0ZNgJuaRB"
   },
   "outputs": [],
   "source": [
    "# data_train.drop(deletedFeatures, axis = 1, inplace=True)\n",
    "# data_test_a.drop(deletedFeatures, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "FBFRzTgiujZC"
   },
   "outputs": [],
   "source": [
    "# data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "yVRPP-ssuwhN"
   },
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1606621317519,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "nLyaD_La75y8",
    "outputId": "d6eef3af-2153-4503-bd28-41422a3d2503"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>term</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>homeOwnership</th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>verificationStatus</th>\n",
       "      <th>purpose</th>\n",
       "      <th>postCode</th>\n",
       "      <th>regionCode</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinquency_2years</th>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <th>openAcc</th>\n",
       "      <th>pubRec</th>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <th>revolBal</th>\n",
       "      <th>revolUtil</th>\n",
       "      <th>totalAcc</th>\n",
       "      <th>initialListStatus</th>\n",
       "      <th>applicationType</th>\n",
       "      <th>title</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "      <th>issueYear</th>\n",
       "      <th>issueMonth</th>\n",
       "      <th>earliesCreditLineYear</th>\n",
       "      <th>earliesCreditLineMonth</th>\n",
       "      <th>issueDateDT</th>\n",
       "      <th>earliesCreditLineDT</th>\n",
       "      <th>grade_target_mean</th>\n",
       "      <th>subGrade_target_mean</th>\n",
       "      <th>grade_to_mean_n0</th>\n",
       "      <th>grade_to_std_n0</th>\n",
       "      <th>grade_to_mean_n1</th>\n",
       "      <th>grade_to_std_n1</th>\n",
       "      <th>grade_to_mean_n2</th>\n",
       "      <th>grade_to_std_n2</th>\n",
       "      <th>grade_to_mean_n3</th>\n",
       "      <th>grade_to_std_n3</th>\n",
       "      <th>grade_to_mean_n4</th>\n",
       "      <th>grade_to_std_n4</th>\n",
       "      <th>grade_to_mean_n5</th>\n",
       "      <th>grade_to_std_n5</th>\n",
       "      <th>grade_to_mean_n6</th>\n",
       "      <th>grade_to_std_n6</th>\n",
       "      <th>grade_to_mean_n7</th>\n",
       "      <th>grade_to_std_n7</th>\n",
       "      <th>grade_to_mean_n8</th>\n",
       "      <th>grade_to_std_n8</th>\n",
       "      <th>grade_to_mean_n9</th>\n",
       "      <th>grade_to_std_n9</th>\n",
       "      <th>grade_to_mean_n10</th>\n",
       "      <th>grade_to_std_n10</th>\n",
       "      <th>grade_to_mean_n11</th>\n",
       "      <th>grade_to_std_n11</th>\n",
       "      <th>grade_to_mean_n12</th>\n",
       "      <th>grade_to_std_n12</th>\n",
       "      <th>grade_to_mean_n13</th>\n",
       "      <th>grade_to_std_n13</th>\n",
       "      <th>grade_to_mean_n14</th>\n",
       "      <th>grade_to_std_n14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.52</td>\n",
       "      <td>917.97</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>32</td>\n",
       "      <td>17.05</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24178.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>2587</td>\n",
       "      <td>-2130</td>\n",
       "      <td>0.384291</td>\n",
       "      <td>0.376903</td>\n",
       "      <td>2.342075</td>\n",
       "      <td>3.088858</td>\n",
       "      <td>2.340208</td>\n",
       "      <td>3.132197</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.290512</td>\n",
       "      <td>3.122960</td>\n",
       "      <td>2.361338</td>\n",
       "      <td>3.124309</td>\n",
       "      <td>2.307407</td>\n",
       "      <td>3.131416</td>\n",
       "      <td>2.272681</td>\n",
       "      <td>3.148661</td>\n",
       "      <td>2.293558</td>\n",
       "      <td>3.124742</td>\n",
       "      <td>2.476104</td>\n",
       "      <td>3.091823</td>\n",
       "      <td>2.290444</td>\n",
       "      <td>3.184266</td>\n",
       "      <td>2.290364</td>\n",
       "      <td>3.092694</td>\n",
       "      <td>2.279907</td>\n",
       "      <td>3.100432</td>\n",
       "      <td>2.294389</td>\n",
       "      <td>3.094492</td>\n",
       "      <td>2.290853</td>\n",
       "      <td>3.168627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.49</td>\n",
       "      <td>461.90</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>219843.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>18</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15096.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>1888</td>\n",
       "      <td>-1857</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.297572</td>\n",
       "      <td>1.932132</td>\n",
       "      <td>2.218701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799617</td>\n",
       "      <td>2.244387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930988</td>\n",
       "      <td>2.218109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721298</td>\n",
       "      <td>2.303035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.99</td>\n",
       "      <td>298.17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>31698.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>14</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1</td>\n",
       "      <td>675.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4606.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>3044</td>\n",
       "      <td>-396</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.304015</td>\n",
       "      <td>1.756556</td>\n",
       "      <td>2.316643</td>\n",
       "      <td>1.529430</td>\n",
       "      <td>2.161567</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.366029</td>\n",
       "      <td>2.233178</td>\n",
       "      <td>1.197880</td>\n",
       "      <td>2.284330</td>\n",
       "      <td>1.678801</td>\n",
       "      <td>2.262293</td>\n",
       "      <td>1.704511</td>\n",
       "      <td>2.361495</td>\n",
       "      <td>1.577005</td>\n",
       "      <td>2.332637</td>\n",
       "      <td>1.813296</td>\n",
       "      <td>2.344317</td>\n",
       "      <td>1.707234</td>\n",
       "      <td>2.308753</td>\n",
       "      <td>1.717773</td>\n",
       "      <td>2.319520</td>\n",
       "      <td>1.709930</td>\n",
       "      <td>2.325324</td>\n",
       "      <td>1.720792</td>\n",
       "      <td>2.320869</td>\n",
       "      <td>1.444127</td>\n",
       "      <td>2.264665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.26</td>\n",
       "      <td>340.96</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>46854.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11</td>\n",
       "      <td>17.21</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9948.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>5</td>\n",
       "      <td>2983</td>\n",
       "      <td>-2953</td>\n",
       "      <td>0.060375</td>\n",
       "      <td>0.067221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.99</td>\n",
       "      <td>101.07</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>301.0</td>\n",
       "      <td>21</td>\n",
       "      <td>32.16</td>\n",
       "      <td>1</td>\n",
       "      <td>690.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1977</td>\n",
       "      <td>8</td>\n",
       "      <td>3196</td>\n",
       "      <td>-10896</td>\n",
       "      <td>0.225020</td>\n",
       "      <td>0.206892</td>\n",
       "      <td>1.054598</td>\n",
       "      <td>1.575441</td>\n",
       "      <td>1.170104</td>\n",
       "      <td>1.566099</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.096810</td>\n",
       "      <td>1.571810</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>1.566738</td>\n",
       "      <td>1.139659</td>\n",
       "      <td>1.525187</td>\n",
       "      <td>1.142249</td>\n",
       "      <td>1.541740</td>\n",
       "      <td>1.163517</td>\n",
       "      <td>1.554608</td>\n",
       "      <td>1.103551</td>\n",
       "      <td>1.566999</td>\n",
       "      <td>1.143978</td>\n",
       "      <td>1.543316</td>\n",
       "      <td>1.145182</td>\n",
       "      <td>1.546347</td>\n",
       "      <td>1.139954</td>\n",
       "      <td>1.550216</td>\n",
       "      <td>1.147194</td>\n",
       "      <td>1.547246</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>1.509776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loanAmnt  term  ...  grade_to_mean_n14  grade_to_std_n14\n",
       "0   35000.0     5  ...           2.290853          3.168627\n",
       "1   18000.0     5  ...                NaN               NaN\n",
       "2   12000.0     5  ...           1.444127          2.264665\n",
       "3   11000.0     3  ...           0.000000          0.000000\n",
       "4    3000.0     3  ...           0.962751          1.509776\n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1606623764354,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "Mt9UkyMj75y8",
    "outputId": "d1e8ae2d-3555-48dd-bf91-c17559ff057f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1606623765834,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "Je1lLn_r9b9J",
    "outputId": "4a26de47-0b34-48d8-f64a-ec2fd65be400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 80)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Bpow4Rnz75y9"
   },
   "outputs": [],
   "source": [
    "# x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Gtz0yVpc75y9"
   },
   "outputs": [],
   "source": [
    "# x_train = x_train.fillna(axis = 0, method = \"ffill\")\n",
    "# x_test = x_test.fillna(axis = 0, method = \"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UK76uXtb75y9"
   },
   "outputs": [],
   "source": [
    "x_train.to_csv(\"preprocessedData/x_train-1110-3.7-1.csv\", index=False)\n",
    "x_test.to_csv(\"preprocessedData/x_test-1110-3.7-1.csv\", index=False)\n",
    "y_train.to_csv(\"preprocessedData/y_train-1110-3.7-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "hwNUPMYNh6UC"
   },
   "source": [
    "## Optimize the memory size of the dataset\n",
    "\n",
    "No need to do this here. It is useless. \n",
    "\n",
    "You need to do it after you load the data for training model. So you have to use this method in other notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "c86XITW4h6UD"
   },
   "outputs": [],
   "source": [
    "# reduce_mem_usage 函数通过调整数据类型，帮助我们减少数据在内存中占用的空间\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "qCTRhPGEh6UE"
   },
   "outputs": [],
   "source": [
    "# x_train_small = reduce_mem_usage(x_train)\n",
    "# x_test_small = reduce_mem_usage(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6JyBck_410PY"
   },
   "source": [
    "## Change the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "o3sGaKAoEUr9"
   },
   "outputs": [],
   "source": [
    "x_train_cp1 = x_train.copy()\n",
    "x_test_cp1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "dCo67QQGIia4"
   },
   "outputs": [],
   "source": [
    "x_train = x_train_cp1.copy()\n",
    "x_test = x_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8ffAB5HC14Pf"
   },
   "source": [
    "### Log all of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "A0GUIDpG13wO"
   },
   "outputs": [],
   "source": [
    "for data in [x_train, x_test]:\n",
    "    for fea in numerical_serial_fea:\n",
    "        if fea in [\"id\", \"purpose\", \"regionCode\"]: ## 这几个, 没法进行log操作.\n",
    "            continue\n",
    "        data[fea] = data[fea].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1604608760419,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "6f5sWi8fHcF0",
    "outputId": "a0892e9e-2eb5-41eb-94fd-b142145f0fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>term</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>postCode</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinquency_2years</th>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <th>openAcc</th>\n",
       "      <th>pubRec</th>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <th>revolBal</th>\n",
       "      <th>revolUtil</th>\n",
       "      <th>totalAcc</th>\n",
       "      <th>initialListStatus</th>\n",
       "      <th>applicationType</th>\n",
       "      <th>title</th>\n",
       "      <th>policyCode</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "      <th>issueDateDT</th>\n",
       "      <th>...</th>\n",
       "      <th>regionCode_43</th>\n",
       "      <th>regionCode_44</th>\n",
       "      <th>regionCode_45</th>\n",
       "      <th>regionCode_46</th>\n",
       "      <th>regionCode_47</th>\n",
       "      <th>regionCode_48</th>\n",
       "      <th>regionCode_49</th>\n",
       "      <th>regionCode_50</th>\n",
       "      <th>grade_target_mean</th>\n",
       "      <th>subGrade_target_mean</th>\n",
       "      <th>grade_to_mean_n0</th>\n",
       "      <th>grade_to_std_n0</th>\n",
       "      <th>grade_to_mean_n1</th>\n",
       "      <th>grade_to_std_n1</th>\n",
       "      <th>grade_to_mean_n2</th>\n",
       "      <th>grade_to_std_n2</th>\n",
       "      <th>grade_to_mean_n3</th>\n",
       "      <th>grade_to_std_n3</th>\n",
       "      <th>grade_to_mean_n4</th>\n",
       "      <th>grade_to_std_n4</th>\n",
       "      <th>grade_to_mean_n5</th>\n",
       "      <th>grade_to_std_n5</th>\n",
       "      <th>grade_to_mean_n6</th>\n",
       "      <th>grade_to_std_n6</th>\n",
       "      <th>grade_to_mean_n7</th>\n",
       "      <th>grade_to_std_n7</th>\n",
       "      <th>grade_to_mean_n8</th>\n",
       "      <th>grade_to_std_n8</th>\n",
       "      <th>grade_to_mean_n9</th>\n",
       "      <th>grade_to_std_n9</th>\n",
       "      <th>grade_to_mean_n10</th>\n",
       "      <th>grade_to_std_n10</th>\n",
       "      <th>grade_to_mean_n11</th>\n",
       "      <th>grade_to_std_n11</th>\n",
       "      <th>grade_to_mean_n12</th>\n",
       "      <th>grade_to_std_n12</th>\n",
       "      <th>grade_to_mean_n13</th>\n",
       "      <th>grade_to_std_n13</th>\n",
       "      <th>grade_to_mean_n14</th>\n",
       "      <th>grade_to_std_n14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.463132</td>\n",
       "      <td>5</td>\n",
       "      <td>3.021400</td>\n",
       "      <td>6.823253</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12.165391</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>11.608245</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>2.893146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.594413</td>\n",
       "      <td>6.599870</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.093240</td>\n",
       "      <td>3.910021</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2587</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384291</td>\n",
       "      <td>0.376903</td>\n",
       "      <td>2.343157</td>\n",
       "      <td>3.087470</td>\n",
       "      <td>2.340208</td>\n",
       "      <td>3.132197</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.290512</td>\n",
       "      <td>3.122960</td>\n",
       "      <td>2.361338</td>\n",
       "      <td>3.124309</td>\n",
       "      <td>2.321539</td>\n",
       "      <td>3.098429</td>\n",
       "      <td>2.272681</td>\n",
       "      <td>3.148661</td>\n",
       "      <td>2.293558</td>\n",
       "      <td>3.124742</td>\n",
       "      <td>2.476104</td>\n",
       "      <td>3.091823</td>\n",
       "      <td>2.290444</td>\n",
       "      <td>3.184266</td>\n",
       "      <td>2.291804</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>2.292831</td>\n",
       "      <td>3.091214</td>\n",
       "      <td>2.302359</td>\n",
       "      <td>3.088676</td>\n",
       "      <td>2.290853</td>\n",
       "      <td>3.168627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.798183</td>\n",
       "      <td>5</td>\n",
       "      <td>2.969902</td>\n",
       "      <td>6.137511</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>11.559189</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>10.736418</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>3.361417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.552508</td>\n",
       "      <td>6.558198</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.622251</td>\n",
       "      <td>3.686376</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.752740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.575551</td>\n",
       "      <td>1.575551</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.803331</td>\n",
       "      <td>2.564964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.575551</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.171916e-16</td>\n",
       "      <td>2.917780</td>\n",
       "      <td>1888</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.297572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799617</td>\n",
       "      <td>2.244387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721298</td>\n",
       "      <td>2.303035</td>\n",
       "      <td>1.718853</td>\n",
       "      <td>2.317982</td>\n",
       "      <td>1.719624</td>\n",
       "      <td>2.318411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.392745</td>\n",
       "      <td>5</td>\n",
       "      <td>2.889816</td>\n",
       "      <td>5.701012</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12.152202</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>11.211834</td>\n",
       "      <td>5.587249</td>\n",
       "      <td>3.168424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.516193</td>\n",
       "      <td>6.522093</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.435332</td>\n",
       "      <td>3.966511</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3044</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.304015</td>\n",
       "      <td>1.757368</td>\n",
       "      <td>2.315603</td>\n",
       "      <td>1.531220</td>\n",
       "      <td>2.161958</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.369429</td>\n",
       "      <td>2.229075</td>\n",
       "      <td>1.217917</td>\n",
       "      <td>2.250570</td>\n",
       "      <td>1.660906</td>\n",
       "      <td>2.248760</td>\n",
       "      <td>1.704511</td>\n",
       "      <td>2.361495</td>\n",
       "      <td>1.577005</td>\n",
       "      <td>2.332637</td>\n",
       "      <td>1.813296</td>\n",
       "      <td>2.344317</td>\n",
       "      <td>1.707234</td>\n",
       "      <td>2.308753</td>\n",
       "      <td>1.718853</td>\n",
       "      <td>2.317982</td>\n",
       "      <td>1.719624</td>\n",
       "      <td>2.318411</td>\n",
       "      <td>1.726769</td>\n",
       "      <td>2.316507</td>\n",
       "      <td>1.444127</td>\n",
       "      <td>2.264665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.305741</td>\n",
       "      <td>3</td>\n",
       "      <td>2.111425</td>\n",
       "      <td>5.834694</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.427747</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>11.678448</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>2.901971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.530878</td>\n",
       "      <td>6.536692</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.205227</td>\n",
       "      <td>3.981549</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.173591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2983</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060375</td>\n",
       "      <td>0.067221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.006701</td>\n",
       "      <td>3</td>\n",
       "      <td>2.638343</td>\n",
       "      <td>4.625659</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12.453983</td>\n",
       "      <td>2.126529</td>\n",
       "      <td>10.275086</td>\n",
       "      <td>5.429346</td>\n",
       "      <td>3.501344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.538140</td>\n",
       "      <td>6.543912</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.987185</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.815640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3196</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225020</td>\n",
       "      <td>0.206892</td>\n",
       "      <td>1.054598</td>\n",
       "      <td>1.575441</td>\n",
       "      <td>1.170104</td>\n",
       "      <td>1.566099</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.096810</td>\n",
       "      <td>1.571810</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>1.566738</td>\n",
       "      <td>1.154910</td>\n",
       "      <td>1.534359</td>\n",
       "      <td>1.142249</td>\n",
       "      <td>1.541740</td>\n",
       "      <td>1.163517</td>\n",
       "      <td>1.554608</td>\n",
       "      <td>1.103551</td>\n",
       "      <td>1.566999</td>\n",
       "      <td>1.143978</td>\n",
       "      <td>1.543316</td>\n",
       "      <td>1.145902</td>\n",
       "      <td>1.545322</td>\n",
       "      <td>1.146416</td>\n",
       "      <td>1.545607</td>\n",
       "      <td>1.151179</td>\n",
       "      <td>1.544338</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>1.509776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loanAmnt  term  ...  grade_to_mean_n14  grade_to_std_n14\n",
       "0  10.463132     5  ...           2.290853          3.168627\n",
       "1   9.798183     5  ...           1.000000               NaN\n",
       "2   9.392745     5  ...           1.444127          2.264665\n",
       "3   9.305741     3  ...           0.000000          0.000000\n",
       "4   8.006701     3  ...           0.962751          1.509776\n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1604608766869,
     "user": {
      "displayName": "Minke Xiu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKrlSLM7H0tbRpIYdHPAKnVjaQdF6dZZWD9Jdd=s64",
      "userId": "01913327350585558279"
     },
     "user_tz": 300
    },
    "hidden": true,
    "id": "zbzhNIzkHeub",
    "outputId": "359d4980-62de-4928-8c1b-96ebb5de5056"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>term</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>postCode</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinquency_2years</th>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <th>openAcc</th>\n",
       "      <th>pubRec</th>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <th>revolBal</th>\n",
       "      <th>revolUtil</th>\n",
       "      <th>totalAcc</th>\n",
       "      <th>initialListStatus</th>\n",
       "      <th>applicationType</th>\n",
       "      <th>title</th>\n",
       "      <th>policyCode</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "      <th>issueDateDT</th>\n",
       "      <th>...</th>\n",
       "      <th>regionCode_43</th>\n",
       "      <th>regionCode_44</th>\n",
       "      <th>regionCode_45</th>\n",
       "      <th>regionCode_46</th>\n",
       "      <th>regionCode_47</th>\n",
       "      <th>regionCode_48</th>\n",
       "      <th>regionCode_49</th>\n",
       "      <th>regionCode_50</th>\n",
       "      <th>grade_target_mean</th>\n",
       "      <th>subGrade_target_mean</th>\n",
       "      <th>grade_to_mean_n0</th>\n",
       "      <th>grade_to_std_n0</th>\n",
       "      <th>grade_to_mean_n1</th>\n",
       "      <th>grade_to_std_n1</th>\n",
       "      <th>grade_to_mean_n2</th>\n",
       "      <th>grade_to_std_n2</th>\n",
       "      <th>grade_to_mean_n3</th>\n",
       "      <th>grade_to_std_n3</th>\n",
       "      <th>grade_to_mean_n4</th>\n",
       "      <th>grade_to_std_n4</th>\n",
       "      <th>grade_to_mean_n5</th>\n",
       "      <th>grade_to_std_n5</th>\n",
       "      <th>grade_to_mean_n6</th>\n",
       "      <th>grade_to_std_n6</th>\n",
       "      <th>grade_to_mean_n7</th>\n",
       "      <th>grade_to_std_n7</th>\n",
       "      <th>grade_to_mean_n8</th>\n",
       "      <th>grade_to_std_n8</th>\n",
       "      <th>grade_to_mean_n9</th>\n",
       "      <th>grade_to_std_n9</th>\n",
       "      <th>grade_to_mean_n10</th>\n",
       "      <th>grade_to_std_n10</th>\n",
       "      <th>grade_to_mean_n11</th>\n",
       "      <th>grade_to_std_n11</th>\n",
       "      <th>grade_to_mean_n12</th>\n",
       "      <th>grade_to_std_n12</th>\n",
       "      <th>grade_to_mean_n13</th>\n",
       "      <th>grade_to_std_n13</th>\n",
       "      <th>grade_to_mean_n14</th>\n",
       "      <th>grade_to_std_n14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.52</td>\n",
       "      <td>917.97</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>192026</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>44</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24178.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2587</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384291</td>\n",
       "      <td>0.376903</td>\n",
       "      <td>2.343157</td>\n",
       "      <td>3.087470</td>\n",
       "      <td>2.340208</td>\n",
       "      <td>3.132197</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.483341</td>\n",
       "      <td>3.090070</td>\n",
       "      <td>2.290512</td>\n",
       "      <td>3.122960</td>\n",
       "      <td>2.361338</td>\n",
       "      <td>3.124309</td>\n",
       "      <td>2.321539</td>\n",
       "      <td>3.098429</td>\n",
       "      <td>2.272681</td>\n",
       "      <td>3.148661</td>\n",
       "      <td>2.293558</td>\n",
       "      <td>3.124742</td>\n",
       "      <td>2.476104</td>\n",
       "      <td>3.091823</td>\n",
       "      <td>2.290444</td>\n",
       "      <td>3.184266</td>\n",
       "      <td>2.291804</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>2.292831</td>\n",
       "      <td>3.091214</td>\n",
       "      <td>2.302359</td>\n",
       "      <td>3.088676</td>\n",
       "      <td>2.290853</td>\n",
       "      <td>3.168627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.49</td>\n",
       "      <td>461.90</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>104734</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>65</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15096.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-29.500403</td>\n",
       "      <td>-8.833409</td>\n",
       "      <td>3.833404</td>\n",
       "      <td>3.833404</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-41.000365</td>\n",
       "      <td>15.499512</td>\n",
       "      <td>12.00019</td>\n",
       "      <td>-18.00007</td>\n",
       "      <td>3.833404</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.171916e-16</td>\n",
       "      <td>17.500178</td>\n",
       "      <td>1888</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.297572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799617</td>\n",
       "      <td>2.244387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721298</td>\n",
       "      <td>2.303035</td>\n",
       "      <td>1.718853</td>\n",
       "      <td>2.317982</td>\n",
       "      <td>1.719624</td>\n",
       "      <td>2.318411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.99</td>\n",
       "      <td>298.17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>189510</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>266</td>\n",
       "      <td>22.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4606.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3044</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.304015</td>\n",
       "      <td>1.757368</td>\n",
       "      <td>2.315603</td>\n",
       "      <td>1.531220</td>\n",
       "      <td>2.161958</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.816601</td>\n",
       "      <td>2.341786</td>\n",
       "      <td>1.369429</td>\n",
       "      <td>2.229075</td>\n",
       "      <td>1.217917</td>\n",
       "      <td>2.250570</td>\n",
       "      <td>1.660906</td>\n",
       "      <td>2.248760</td>\n",
       "      <td>1.704511</td>\n",
       "      <td>2.361495</td>\n",
       "      <td>1.577005</td>\n",
       "      <td>2.332637</td>\n",
       "      <td>1.813296</td>\n",
       "      <td>2.344317</td>\n",
       "      <td>1.707234</td>\n",
       "      <td>2.308753</td>\n",
       "      <td>1.718853</td>\n",
       "      <td>2.317982</td>\n",
       "      <td>1.719624</td>\n",
       "      <td>2.318411</td>\n",
       "      <td>1.726769</td>\n",
       "      <td>2.316507</td>\n",
       "      <td>1.444127</td>\n",
       "      <td>2.264665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.26</td>\n",
       "      <td>340.96</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>249632</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>56</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9948.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2983</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060375</td>\n",
       "      <td>0.067221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.99</td>\n",
       "      <td>101.07</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>256268</td>\n",
       "      <td>7.385708</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>227</td>\n",
       "      <td>32.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3196</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225020</td>\n",
       "      <td>0.206892</td>\n",
       "      <td>1.054598</td>\n",
       "      <td>1.575441</td>\n",
       "      <td>1.170104</td>\n",
       "      <td>1.566099</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>1.569043</td>\n",
       "      <td>1.096810</td>\n",
       "      <td>1.571810</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>1.566738</td>\n",
       "      <td>1.154910</td>\n",
       "      <td>1.534359</td>\n",
       "      <td>1.142249</td>\n",
       "      <td>1.541740</td>\n",
       "      <td>1.163517</td>\n",
       "      <td>1.554608</td>\n",
       "      <td>1.103551</td>\n",
       "      <td>1.566999</td>\n",
       "      <td>1.143978</td>\n",
       "      <td>1.543316</td>\n",
       "      <td>1.145902</td>\n",
       "      <td>1.545322</td>\n",
       "      <td>1.146416</td>\n",
       "      <td>1.545607</td>\n",
       "      <td>1.151179</td>\n",
       "      <td>1.544338</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>1.509776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loanAmnt  term  ...  grade_to_mean_n14  grade_to_std_n14\n",
       "0   35000.0     5  ...           2.290853          3.168627\n",
       "1   18000.0     5  ...           1.000000               NaN\n",
       "2   12000.0     5  ...           1.444127          2.264665\n",
       "3   11000.0     3  ...           0.000000          0.000000\n",
       "4    3000.0     3  ...           0.962751          1.509776\n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "B5NP4AX7knR2"
   },
   "source": [
    "### Log some of the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "N-aBCoL5kqJV"
   },
   "source": [
    "`interestRate`, `annualIncome`, `openAcc`, `revolBal`, `totalAcc`, `n1` to `n10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YbGQC5OQkpr3"
   },
   "outputs": [],
   "source": [
    "for data in [x_train, x_test]:\n",
    "    for fea in [\"interestRate\", \"annualIncome\", \"openAcc\", \"revolBal\", \"totalAcc\", \n",
    "                'n1','n2','n3','n4','n5','n6','n7','n8','n9','n10']:\n",
    "        data[fea] = data[fea].apply(np.log1p)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "d8wxvCVFmZ-_",
    "kmVWMMJwyzUO",
    "6JyBck_410PY",
    "8ffAB5HC14Pf"
   ],
   "machine_shape": "hm",
   "name": "3.1-FE-KeepTheFeaturesAsTheyOriginallyWere.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
